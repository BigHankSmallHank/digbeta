{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Trajectory Recommendation using RankSVM and Structured Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='toc'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Table of Contents](#toc)\n",
    "1. [Preprocess Dataset](#sec1)\n",
    "  1. [Load Data](#sec1.1)\n",
    "  1. [Utility Functions](#sec1.2)\n",
    "1. [POI Ranking](#sec2)\n",
    "  1. [POI Features for Ranking](#sec2.1)\n",
    "  1. [Training DataFrame](#sec2.2)\n",
    "  1. [Test DataFrame](#sec2.3)\n",
    "  1. [Ranking POIs using rankSVM](#sec2.4)\n",
    "1. [Structured Prediction](#sec3)\n",
    "  1. [Structured Predition using PyStruct](#sec3.1)\n",
    "  1. [Node Features](#sec3.2)\n",
    "  1. [Edge Features](#sec3.3)\n",
    "  1. [Leave-one-out Evaluation](#sec3.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sec1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preprocess Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "\n",
    "import os, sys, time, pickle, tempfile\n",
    "import math, random, itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import Parallel, delayed\n",
    "from scipy.misc import logsumexp\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.linalg import kron\n",
    "\n",
    "from pystruct.models import EdgeFeatureGraphCRF\n",
    "from pystruct.learners import OneSlackSSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.seed(987654321) # control random choice when splitting training/testing set\n",
    "np.random.seed(987654321)\n",
    "ranksvm_dir = '$HOME/work/ranksvm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = 'data/data-cikm16'\n",
    "dat_suffix = ['Osak', 'Glas', 'Edin', 'Toro', 'Melb']\n",
    "dat_types = ['all']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dat_ix = 1\n",
    "type_ix = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noloop = True  # trajectories dataset with loop or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uspecific = False  # user specific training/prediction or not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "KX = 100  # KX folds in user specific setting [100, 50, 20, 10, 8, 4, 2, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "C = 1  # regularization parameter of SSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BIN_CLUSTER = 5  # discritization parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method switches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run_crf = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate results filenames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_fname(dat_ix, type_ix, noloop, uspecific, C, KX):\n",
    "    assert(0 <= dat_ix < len(dat_suffix))\n",
    "    assert(0 <= type_ix < len(dat_types))\n",
    "    assert(isinstance(noloop, bool))\n",
    "    assert(isinstance(uspecific, bool))\n",
    "    C_str = 'C' + str(C) + '-'\n",
    "    KX_str = str(KX) + 'X-'\n",
    "    \n",
    "    if noloop == True:\n",
    "        loop_str = 'noloop-'\n",
    "    else:\n",
    "        loop_str = ''\n",
    "    \n",
    "    type_str = dat_types[type_ix] + '-'\n",
    "    \n",
    "    if uspecific == True:\n",
    "        user_str = 'specific-'\n",
    "        suffix = KX_str + dat_suffix[dat_ix] + '.pkl'\n",
    "    else:\n",
    "        user_str = 'agnostic-'\n",
    "        suffix = dat_suffix[dat_ix] + '.pkl'\n",
    "    \n",
    "    fname = loop_str + type_str + user_str\n",
    "    fcrf1 = os.path.join(data_dir, 'crf2-' + fname + C_str + suffix)\n",
    "    return fcrf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/data-cikm16/crf2-noloop-all-agnostic-C1-Glas.pkl'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frecdict_crf = gen_fname(dat_ix, type_ix, noloop, uspecific, C, KX)\n",
    "frecdict_crf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sec1.1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fpoi = os.path.join(data_dir, 'poi-' + dat_suffix[dat_ix] + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poiCat</th>\n",
       "      <th>poiLon</th>\n",
       "      <th>poiLat</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poiID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Transport</td>\n",
       "      <td>-4.258101</td>\n",
       "      <td>55.857920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Transport</td>\n",
       "      <td>-4.250728</td>\n",
       "      <td>55.861496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Transport</td>\n",
       "      <td>-4.595632</td>\n",
       "      <td>55.509388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Transport</td>\n",
       "      <td>-4.331517</td>\n",
       "      <td>55.868897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Transport</td>\n",
       "      <td>-4.269905</td>\n",
       "      <td>55.856135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          poiCat    poiLon     poiLat\n",
       "poiID                                \n",
       "1      Transport -4.258101  55.857920\n",
       "2      Transport -4.250728  55.861496\n",
       "4      Transport -4.595632  55.509388\n",
       "5      Transport -4.331517  55.868897\n",
       "6      Transport -4.269905  55.856135"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poi_all = pd.read_csv(fpoi)\n",
    "poi_all.set_index('poiID', inplace=True)\n",
    "poi_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if noloop == True:\n",
    "    ftraj = os.path.join(data_dir, 'traj-noloop-' + dat_types[type_ix] + '-' + dat_suffix[dat_ix] + '.csv')\n",
    "else:\n",
    "    ftraj = os.path.join(data_dir, 'traj-' + dat_types[type_ix] + '-' + dat_suffix[dat_ix] + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>trajID</th>\n",
       "      <th>poiID</th>\n",
       "      <th>startTime</th>\n",
       "      <th>endTime</th>\n",
       "      <th>#photo</th>\n",
       "      <th>trajLen</th>\n",
       "      <th>poiDuration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10063645@N00</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1160716026</td>\n",
       "      <td>1160716026</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10063645@N00</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1162247008</td>\n",
       "      <td>1162247008</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10063645@N00</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>1162333588</td>\n",
       "      <td>1162333588</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10063645@N00</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>1162693595</td>\n",
       "      <td>1162693595</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10063645@N00</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>1162693817</td>\n",
       "      <td>1162693829</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         userID  trajID  poiID   startTime     endTime  #photo  trajLen  \\\n",
       "0  10063645@N00       1     11  1160716026  1160716026       1        1   \n",
       "1  10063645@N00       2      2  1162247008  1162247008       1        1   \n",
       "2  10063645@N00       3     11  1162333588  1162333588       1        1   \n",
       "3  10063645@N00       4     16  1162693595  1162693595       1        2   \n",
       "4  10063645@N00       4     21  1162693817  1162693829       2        2   \n",
       "\n",
       "   poiDuration  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4           12  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traj_all = pd.read_csv(ftraj)\n",
    "traj_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#poi</th>\n",
       "      <th>#traj</th>\n",
       "      <th>#traj/user</th>\n",
       "      <th>#user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Glas</th>\n",
       "      <td>27</td>\n",
       "      <td>2227</td>\n",
       "      <td>3.705491</td>\n",
       "      <td>601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      #poi  #traj  #traj/user  #user\n",
       "Glas    27   2227    3.705491    601"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_user = traj_all['userID'].unique().shape[0]\n",
    "num_poi = traj_all['poiID'].unique().shape[0]\n",
    "num_traj = traj_all['trajID'].unique().shape[0]\n",
    "#assert(num_poi == poi_all.shape[0])\n",
    "pd.DataFrame({'#user': num_user, '#poi': num_poi, '#traj': num_traj, '#traj/user': num_traj/num_user}, \\\n",
    "             index=[str(dat_suffix[dat_ix])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAFYCAYAAABpkTT0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f96364072e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = traj_all['trajLen'].hist(bins=20)\n",
    "ax.set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mapping trajectory to user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trajID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10063645@N00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10063645@N00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10063645@N00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10063645@N00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10063645@N00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              userID\n",
       "trajID              \n",
       "1       10063645@N00\n",
       "2       10063645@N00\n",
       "3       10063645@N00\n",
       "4       10063645@N00\n",
       "5       10063645@N00"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traj_user = traj_all[['trajID', 'userID']].copy().groupby('trajID').first()\n",
    "traj_user.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sec1.2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Utility Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print computing progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_progress(cnt, total):\n",
    "    \"\"\"Display a progress bar\"\"\"\n",
    "    assert(cnt > 0 and total > 0 and cnt <= total)\n",
    "    length = 80\n",
    "    ratio = cnt / total\n",
    "    n = int(length * ratio)\n",
    "    sys.stdout.write('\\r[%-80s] %d%%' % ('-'*n, int(ratio*100)))\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract trajectory, i.e., a list of POIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_traj(tid, traj_all):\n",
    "    traj = traj_all[traj_all['trajID'] == tid].copy()\n",
    "    traj.sort_values(by=['startTime'], ascending=True, inplace=True)\n",
    "    return traj['poiID'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute POI properties, e.g., popularity, total number of visit, average visit duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_poi_info(trajid_list, traj_all, poi_all):\n",
    "    assert(len(trajid_list) > 0)\n",
    "    # to allow duplicated trajid\n",
    "    poi_info = traj_all[traj_all['trajID'] == trajid_list[0]][['poiID', 'poiDuration']].copy() \n",
    "    for i in range(1, len(trajid_list)):\n",
    "        traj = traj_all[traj_all['trajID'] == trajid_list[i]][['poiID', 'poiDuration']]\n",
    "        poi_info = poi_info.append(traj, ignore_index=True)\n",
    "    \n",
    "    poi_info = poi_info.groupby('poiID').agg([np.mean, np.size])\n",
    "    poi_info.columns = poi_info.columns.droplevel()\n",
    "    poi_info.reset_index(inplace=True)\n",
    "    poi_info.rename(columns={'mean':'avgDuration', 'size':'nVisit'}, inplace=True)\n",
    "    poi_info.set_index('poiID', inplace=True) \n",
    "    poi_info['poiCat'] = poi_all.loc[poi_info.index, 'poiCat']\n",
    "    poi_info['poiLon'] = poi_all.loc[poi_info.index, 'poiLon']\n",
    "    poi_info['poiLat'] = poi_all.loc[poi_info.index, 'poiLat']\n",
    "    \n",
    "    # POI popularity: the number of distinct users that visited the POI\n",
    "    pop_df = traj_all[traj_all['trajID'].isin(trajid_list)][['poiID', 'userID']].copy()\n",
    "    pop_df = pop_df.groupby('poiID').agg(pd.Series.nunique)\n",
    "    pop_df.rename(columns={'userID':'nunique'}, inplace=True)\n",
    "    poi_info['popularity'] = pop_df.loc[poi_info.index, 'nunique']\n",
    "    \n",
    "    return poi_info.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the F1 score for recommended trajectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_F1(traj_act, traj_rec, noloop=False):\n",
    "    '''Compute recall, precision and F1 for recommended trajectories'''\n",
    "    assert(isinstance(noloop, bool))\n",
    "    assert(len(traj_act) > 0)\n",
    "    assert(len(traj_rec) > 0)\n",
    "    \n",
    "    if noloop == True:\n",
    "        intersize = len(set(traj_act) & set(traj_rec))\n",
    "    else:\n",
    "        match_tags = np.zeros(len(traj_act), dtype=np.bool)\n",
    "        for poi in traj_rec:\n",
    "            for j in range(len(traj_act)):\n",
    "                if match_tags[j] == False and poi == traj_act[j]:\n",
    "                    match_tags[j] = True\n",
    "                    break\n",
    "        intersize = np.nonzero(match_tags)[0].shape[0]\n",
    "        \n",
    "    recall = intersize / len(traj_act)\n",
    "    precision = intersize / len(traj_rec)\n",
    "    F1 = 2 * precision * recall / (precision + recall)\n",
    "    return F1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute distance between two POIs using [Haversine formula](http://en.wikipedia.org/wiki/Great-circle_distance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_dist_vec(longitudes1, latitudes1, longitudes2, latitudes2):\n",
    "    \"\"\"Calculate the distance (unit: km) between two places on earth, vectorised\"\"\"\n",
    "    # convert degrees to radians\n",
    "    lng1 = np.radians(longitudes1)\n",
    "    lat1 = np.radians(latitudes1)\n",
    "    lng2 = np.radians(longitudes2)\n",
    "    lat2 = np.radians(latitudes2)\n",
    "    radius = 6371.0088 # mean earth radius, en.wikipedia.org/wiki/Earth_radius#Mean_radius\n",
    "\n",
    "    # The haversine formula, en.wikipedia.org/wiki/Great-circle_distance\n",
    "    dlng = np.fabs(lng1 - lng2)\n",
    "    dlat = np.fabs(lat1 - lat2)\n",
    "    dist =  2 * radius * np.arcsin( np.sqrt( \n",
    "                (np.sin(0.5*dlat))**2 + np.cos(lat1) * np.cos(lat2) * (np.sin(0.5*dlng))**2 ))\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distance between POIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "POI_DISTMAT = pd.DataFrame(data=np.zeros((poi_all.shape[0], poi_all.shape[0]), dtype=np.float), \\\n",
    "                           index=poi_all.index, columns=poi_all.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for ix in poi_all.index:\n",
    "    POI_DISTMAT.loc[ix] = calc_dist_vec(poi_all.loc[ix, 'poiLon'], \\\n",
    "                                        poi_all.loc[ix, 'poiLat'], \\\n",
    "                                        poi_all['poiLon'], \\\n",
    "                                        poi_all['poiLat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trajid_set_all = sorted(traj_all['trajID'].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "poi_info_all = calc_poi_info(trajid_set_all, traj_all, poi_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering out POI visits with 0 duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avgDuration</th>\n",
       "      <th>nVisit</th>\n",
       "      <th>poiCat</th>\n",
       "      <th>poiLon</th>\n",
       "      <th>poiLat</th>\n",
       "      <th>popularity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poiID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Transport</td>\n",
       "      <td>-4.595632</td>\n",
       "      <td>55.509388</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Transport</td>\n",
       "      <td>-4.331517</td>\n",
       "      <td>55.868897</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       avgDuration  nVisit     poiCat    poiLon     poiLat  popularity\n",
       "poiID                                                                 \n",
       "4              0.0       1  Transport -4.595632  55.509388           1\n",
       "5              0.0       2  Transport -4.331517  55.868897           2"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_duration = poi_info_all[poi_info_all['avgDuration'] < 1]\n",
    "zero_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2749, 8)\n",
      "(2746, 8)\n"
     ]
    }
   ],
   "source": [
    "print(traj_all.shape)\n",
    "traj_all = traj_all[traj_all['poiID'].isin(set(poi_info_all.index) - set(zero_duration.index))]\n",
    "print(traj_all.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dictionary maps every trajectory ID to the actual trajectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "traj_dict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for trajid in trajid_set_all:\n",
    "    traj = extract_traj(trajid, traj_all)\n",
    "    assert(trajid not in traj_dict)\n",
    "    traj_dict[trajid] = traj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a *query* (in IR terminology) using tuple (start POI, end POI, #POI) ~~user ID.~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "QUERY_ID_DICT = dict()  # (start, end, length) --> qid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keys = [(traj_dict[x][0], traj_dict[x][-1], len(traj_dict[x])) \\\n",
    "        for x in sorted(traj_dict.keys()) if len(traj_dict[x]) > 2]\n",
    "cnt = 0\n",
    "for key in keys:\n",
    "    if key not in QUERY_ID_DICT:   # (start, end, length) --> qid\n",
    "        QUERY_ID_DICT[key] = cnt\n",
    "        cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#traj in total: 2227\n",
      "#traj (length > 2): 112\n",
      "#query tuple: 97\n"
     ]
    }
   ],
   "source": [
    "print('#traj in total:', len(trajid_set_all))\n",
    "print('#traj (length > 2):', traj_all[traj_all['trajLen'] > 2]['trajID'].unique().shape[0])\n",
    "print('#query tuple:', len(QUERY_ID_DICT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sec2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. POI Ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sec2.1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 POI Features for Ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "POI Features used for ranking:\n",
    "1. `popularity`: POI popularity, i.e., the number of distinct users that visited the POI\n",
    "1. `nVisit`: the total number of visit by all users\n",
    "1. `avgDuration`: average POI visit duration\n",
    "1. `sameCatStart`: 1 if POI category is the same as that of `startPOI`, -1 otherwise\n",
    "1. `sameCatEnd`: 1 if POI category is the same as that of `endPOI`, -1 otherwise\n",
    "1. `distStart`: distance (haversine formula) from `startPOI`\n",
    "1. `distEnd`: distance from `endPOI`\n",
    "1. `seqLen`: trajectory length (copy from query)\n",
    "1. `diffPopStart`: difference in POI popularity from `startPOI`\n",
    "1. `diffPopEnd`: difference in POI popularity from `endPOI`\n",
    "1. `diffNVisitStart`: difference in the total number of visit from `startPOI`\n",
    "1. `diffNVisitEnd`: difference in the total number of visit from `endPOI`\n",
    "1. `diffDurationStart`: difference in average POI visit duration from the actual duration spent at `startPOI`\n",
    "1. `diffDurationEnd`: difference in average POI visit duration from the actual duration spent at `endPOI`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DF_COLUMNS = ['poiID', 'label', 'queryID', 'popularity', 'nVisit', 'avgDuration', 'sameCatStart', 'sameCatEnd', \\\n",
    "              'distStart', 'distEnd', 'trajLen', 'diffPopStart', 'diffPopEnd', 'diffNVisitStart', 'diffNVisitEnd', \\\n",
    "              'diffDurationStart', 'diffDurationEnd', 'sameClusterStart', 'sameClusterEnd']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~Features aggregated from a number of trajectories:~~\n",
    "~~1. Compute POI `popularity` and average visit `duration` using all trajectories from training and querying set,~~\n",
    "~~1. Use the same features that computed above for the test set, except the distance based features.~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sec2.2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Training DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training data are generated as follows:\n",
    "1. each input tuple $(\\text{startPOI}, \\text{endPOI}, \\text{#POI})$ form a `query` (in IR terminology).\n",
    "1. the label of a specific POI is the number of presence of that POI in a specific `query`, excluding the presence as $\\text{startPOI}$ or $\\text{endPOI}$.\n",
    "1. for each `query`, the label of all absence POIs from trajectories of that `query` in training set got a label 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dimension of training data matrix is `#(qid, poi)` by `#feature`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_train_subdf(poi_id, query_id_set, poi_info, poi_clusters, query_id_rdict):\n",
    "    columns = DF_COLUMNS\n",
    "    poi_distmat = POI_DISTMAT\n",
    "    df_ = pd.DataFrame(data=np.zeros((len(query_id_set), len(columns)), dtype=np.float), columns=columns)\n",
    "    \n",
    "    pop, nvisit = poi_info.loc[poi_id, 'popularity'], poi_info.loc[poi_id, 'nVisit']\n",
    "    cat, cluster = poi_info.loc[poi_id, 'poiCat'], poi_clusters.loc[poi_id, 'clusterID'] \n",
    "    duration = poi_info.loc[poi_id, 'avgDuration']\n",
    "    \n",
    "    for j in range(len(query_id_set)):\n",
    "        qid = query_id_set[j]\n",
    "        assert(qid in query_id_rdict) # qid --> (start, end, length)\n",
    "        (p0, pN, trajLen) = query_id_rdict[qid]\n",
    "        idx = df_.index[j]\n",
    "        df_.loc[idx, 'poiID'] = poi_id\n",
    "        df_.loc[idx, 'queryID'] = qid\n",
    "        df_.loc[idx, 'popularity'] = pop\n",
    "        df_.loc[idx, 'nVisit'] = nvisit\n",
    "        df_.loc[idx, 'avgDuration'] = duration\n",
    "        df_.loc[idx, 'sameCatStart'] = 1 if cat == poi_info.loc[p0, 'poiCat'] else -1\n",
    "        df_.loc[idx, 'sameCatEnd']   = 1 if cat == poi_info.loc[pN, 'poiCat'] else -1\n",
    "        df_.loc[idx, 'distStart'] = poi_distmat.loc[poi_id, p0]\n",
    "        df_.loc[idx, 'distEnd']   = poi_distmat.loc[poi_id, pN]\n",
    "        df_.loc[idx, 'trajLen'] = trajLen\n",
    "        df_.loc[idx, 'diffPopStart'] = pop - poi_info.loc[p0, 'popularity']\n",
    "        df_.loc[idx, 'diffPopEnd']   = pop - poi_info.loc[pN, 'popularity']\n",
    "        df_.loc[idx, 'diffNVisitStart'] = nvisit - poi_info.loc[p0, 'nVisit']\n",
    "        df_.loc[idx, 'diffNVisitEnd']   = nvisit - poi_info.loc[pN, 'nVisit']\n",
    "        df_.loc[idx, 'diffDurationStart'] = duration - poi_info.loc[p0, 'avgDuration']\n",
    "        df_.loc[idx, 'diffDurationEnd']   = duration - poi_info.loc[pN, 'avgDuration']\n",
    "        df_.loc[idx, 'sameClusterStart'] = 1 if cluster == poi_clusters.loc[p0, 'clusterID'] else -1\n",
    "        df_.loc[idx, 'sameClusterEnd']   = 1 if cluster == poi_clusters.loc[pN, 'clusterID'] else -1\n",
    "        \n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gen_train_df(trajid_list, traj_dict, poi_info, poi_clusters, n_jobs=-1):\n",
    "    columns = DF_COLUMNS\n",
    "    poi_distmat = POI_DISTMAT\n",
    "    query_id_dict = QUERY_ID_DICT\n",
    "    train_trajs = [traj_dict[x] for x in trajid_list if len(traj_dict[x]) > 2]\n",
    "    \n",
    "    qid_set = sorted(set([query_id_dict[(t[0], t[-1], len(t))] for t in train_trajs]))\n",
    "    poi_set = set()\n",
    "    for tr in train_trajs:\n",
    "        poi_set = poi_set | set(tr)\n",
    "    \n",
    "    #qid_poi_pair = list(itertools.product(qid_set, poi_set)) # Cartesian product of qid_set and poi_set\n",
    "    #df_ = pd.DataFrame(data=np.zeros((len(qid_poi_pair), len(columns)), dtype= np.float), columns=columns)\n",
    "    \n",
    "    query_id_rdict = dict()\n",
    "    for k, v in query_id_dict.items(): \n",
    "        query_id_rdict[v] = k  # qid --> (start, end, length)\n",
    "    \n",
    "    train_df_list = Parallel(n_jobs=n_jobs)\\\n",
    "                            (delayed(gen_train_subdf)(poi, qid_set, poi_info, poi_clusters, query_id_rdict) \\\n",
    "                             for poi in poi_set)\n",
    "                        \n",
    "    assert(len(train_df_list) > 0)\n",
    "    df_ = train_df_list[0]\n",
    "    for j in range(1, len(train_df_list)):\n",
    "        df_ = df_.append(train_df_list[j], ignore_index=True)            \n",
    "        \n",
    "    # set label\n",
    "    df_.set_index(['queryID', 'poiID'], inplace=True)\n",
    "    for t in train_trajs:\n",
    "        qid = query_id_dict[(t[0], t[-1], len(t))]\n",
    "        for poi in t[1:-1]:  # do NOT count if the POI is startPOI/endPOI\n",
    "            df_.loc[(qid, poi), 'label'] += 1\n",
    "\n",
    "    df_.reset_index(inplace=True)\n",
    "    return df_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check: \n",
    "- different POIs have different features for the same query trajectory\n",
    "- the same POI get different features for different query-id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sec2.3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Test DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test data are generated the same way as training data, except that the labels of testing data (unknown) could be arbitrary values as suggested in [libsvm FAQ](http://www.csie.ntu.edu.tw/~cjlin/libsvm/faq.html#f431).\n",
    "The reported accuracy (by `svm-predict` command) is meaningless as it is calculated based on these labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dimension of training data matrix is `#poi` by `#feature` with one specific `query`, i.e. tuple $(\\text{startPOI}, \\text{endPOI}, \\text{#POI})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_test_df(startPOI, endPOI, nPOI, poi_info, poi_clusters):\n",
    "    columns = DF_COLUMNS\n",
    "    poi_distmat = POI_DISTMAT\n",
    "    query_id_dict = QUERY_ID_DICT\n",
    "    key = (p0, pN, trajLen) = (startPOI, endPOI, nPOI)\n",
    "    assert(key in query_id_dict)\n",
    "    assert(p0 in poi_info.index)\n",
    "    assert(pN in poi_info.index)\n",
    "    \n",
    "    df_ = pd.DataFrame(data=np.zeros((poi_info.shape[0], len(columns)), dtype= np.float), columns=columns)\n",
    "    poi_list = sorted(poi_info.index)\n",
    "    \n",
    "    qid = query_id_dict[key]\n",
    "    df_['queryID'] = qid\n",
    "    df_['label'] = np.random.rand(df_.shape[0]) # label for test data is arbitrary according to libsvm FAQ\n",
    "\n",
    "    for i in range(df_.index.shape[0]):\n",
    "        poi = poi_list[i]\n",
    "        lon, lat = poi_info.loc[poi, 'poiLon'], poi_info.loc[poi, 'poiLat']\n",
    "        pop, nvisit = poi_info.loc[poi, 'popularity'], poi_info.loc[poi, 'nVisit']\n",
    "        cat, cluster = poi_info.loc[poi, 'poiCat'], poi_clusters.loc[poi, 'clusterID']\n",
    "        duration = poi_info.loc[poi, 'avgDuration']\n",
    "        idx = df_.index[i]\n",
    "        df_.loc[idx, 'poiID'] = poi \n",
    "        df_.loc[idx, 'popularity'] = pop\n",
    "        df_.loc[idx, 'nVisit'] = nvisit\n",
    "        df_.loc[idx, 'avgDuration'] = duration\n",
    "        df_.loc[idx, 'sameCatStart'] = 1 if cat == poi_all.loc[p0, 'poiCat'] else -1\n",
    "        df_.loc[idx, 'sameCatEnd']   = 1 if cat == poi_all.loc[pN, 'poiCat'] else -1\n",
    "        df_.loc[idx, 'distStart'] = poi_distmat.loc[poi, p0]\n",
    "        df_.loc[idx, 'distEnd']   = poi_distmat.loc[poi, pN]\n",
    "        df_.loc[idx, 'trajLen'] = trajLen\n",
    "        df_.loc[idx, 'diffPopStart'] = pop - poi_info.loc[p0, 'popularity']\n",
    "        df_.loc[idx, 'diffPopEnd']   = pop - poi_info.loc[pN, 'popularity']\n",
    "        df_.loc[idx, 'diffNVisitStart'] = nvisit - poi_info.loc[p0, 'nVisit']\n",
    "        df_.loc[idx, 'diffNVisitEnd']   = nvisit - poi_info.loc[pN, 'nVisit']\n",
    "        df_.loc[idx, 'diffDurationStart'] = duration - poi_info.loc[p0, 'avgDuration']\n",
    "        df_.loc[idx, 'diffDurationEnd']   = duration - poi_info.loc[pN, 'avgDuration']\n",
    "        df_.loc[idx, 'sameClusterStart'] = 1 if cluster == poi_clusters.loc[p0, 'clusterID'] else -1\n",
    "        df_.loc[idx, 'sameClusterEnd']   = 1 if cluster == poi_clusters.loc[pN, 'clusterID'] else -1\n",
    "        \n",
    "    return df_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check: \n",
    "- different POIs have different features for the same query trajectory\n",
    "- the same POI get different features for different query-id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a string for a training/test data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_data_str(df_, df_columns=DF_COLUMNS):\n",
    "    columns = df_columns[1:].copy()  # get rid of 'poiID'\n",
    "    for col in columns:\n",
    "        assert(col in df_.columns)\n",
    "        \n",
    "    lines = []\n",
    "    for idx in df_.index:\n",
    "        slist = [str(df_.loc[idx, 'label'])]\n",
    "        slist.append(' qid:')\n",
    "        slist.append(str(int(df_.loc[idx, 'queryID'])))\n",
    "        for j in range(2, len(columns)):\n",
    "            slist.append(' ')\n",
    "            slist.append(str(j-1))\n",
    "            slist.append(':')\n",
    "            slist.append(str(df_.loc[idx, columns[j]]))\n",
    "        slist.append('\\n')\n",
    "        lines.append(''.join(slist))\n",
    "    return ''.join(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sec2.4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Ranking POIs using rankSVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RankSVM implementation in [libsvm.zip](https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/ranksvm/libsvm-ranksvm-3.20.zip) or [liblinear.zip](https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/ranksvm/liblinear-ranksvm-1.95.zip), please read `README.ranksvm` in the zip file for installation instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use [softmax function](https://en.wikipedia.org/wiki/Softmax_function) to convert ranking scores to a probability distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    x1 = x.copy()\n",
    "    x1 -= np.max(x1)  # numerically more stable, REF: http://cs231n.github.io/linear-classify/#softmax\n",
    "    expx = np.exp(x1)\n",
    "    return expx / np.sum(expx, axis=0) # column-wise sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a python wrapper of the `svm-train` or `train` and `svm-predict` or `predict` commands of rankSVM with ranking probabilities $P(p_i \\lvert (p_s, p_e, len))$ computed using [softmax function](https://en.wikipedia.org/wiki/Softmax_function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# python wrapper of rankSVM\n",
    "class RankSVM:\n",
    "    def __init__(self, bin_dir, useLinear=True, debug=False):\n",
    "        dir_ = !echo $bin_dir  # deal with environmental variables in path\n",
    "        assert(os.path.exists(dir_[0]))\n",
    "        self.bin_dir = dir_[0]\n",
    "        \n",
    "        self.bin_train = 'svm-train'\n",
    "        self.bin_predict = 'svm-predict'\n",
    "        if useLinear:\n",
    "            self.bin_train = 'train'\n",
    "            self.bin_predict = 'predict'\n",
    "        \n",
    "        assert(isinstance(debug, bool))\n",
    "        self.debug = debug\n",
    "        \n",
    "        # create named tmp files for model and feature scaling parameters\n",
    "        self.fmodel = None\n",
    "        self.fscale = None\n",
    "        with tempfile.NamedTemporaryFile(delete=False) as fd: \n",
    "            self.fmodel = fd.name\n",
    "        with tempfile.NamedTemporaryFile(delete=False) as fd: \n",
    "            self.fscale = fd.name\n",
    "        \n",
    "        if self.debug:\n",
    "            print('model file:', self.fmodel)\n",
    "            print('feature scaling parameter file:', self.fscale)\n",
    "    \n",
    "    \n",
    "    def __del__(self):\n",
    "        # remove tmp files\n",
    "        if self.fmodel is not None and os.path.exists(self.fmodel):\n",
    "            os.unlink(self.fmodel)\n",
    "        if self.fscale is not None and os.path.exists(self.fscale):\n",
    "            os.unlink(self.fscale)\n",
    "    \n",
    "    \n",
    "    def train(self, train_df, cost=1):\n",
    "        # cost is parameter C in SVM\n",
    "        # write train data to file\n",
    "        ftrain = None\n",
    "        with tempfile.NamedTemporaryFile(mode='w+t', delete=False) as fd: \n",
    "            ftrain = fd.name\n",
    "            datastr = gen_data_str(train_df)\n",
    "            fd.write(datastr)\n",
    "        \n",
    "        # feature scaling\n",
    "        ftrain_scaled = None\n",
    "        with tempfile.NamedTemporaryFile(mode='w+t', delete=False) as fd: \n",
    "            ftrain_scaled = fd.name\n",
    "        result = !$self.bin_dir/svm-scale -s $self.fscale $ftrain > $ftrain_scaled\n",
    "        \n",
    "        if self.debug:\n",
    "            print('cost:', cost)\n",
    "            print('train data file:', ftrain)\n",
    "            print('feature scaled train data file:', ftrain_scaled)\n",
    "        \n",
    "        # train rank svm and generate model file, if the model file exists, rewrite it\n",
    "        #n_cv = 10  # parameter k for k-fold cross-validation, NO model file will be generated in CV mode\n",
    "        #result = !$self.bin_dir/svm-train -c $cost -v $n_cv $ftrain $self.fmodel\n",
    "        result = !$self.bin_dir/$self.bin_train -c $cost $ftrain_scaled $self.fmodel\n",
    "        if self.debug:\n",
    "            print('Training finished.')\n",
    "            for i in range(len(result)): print(result[i])\n",
    "\n",
    "        # remove train data file\n",
    "        os.unlink(ftrain)\n",
    "        os.unlink(ftrain_scaled)        \n",
    "        \n",
    "    \n",
    "    def predict(self, test_df):\n",
    "        # predict ranking scores for the given feature matrix\n",
    "        if self.fmodel is None or not os.path.exists(self.fmodel):\n",
    "            print('Model should be trained before predicting')\n",
    "            return\n",
    "        \n",
    "        # write test data to file\n",
    "        ftest = None\n",
    "        with tempfile.NamedTemporaryFile(mode='w+t', delete=False) as fd: \n",
    "            ftest = fd.name\n",
    "            datastr = gen_data_str(test_df)\n",
    "            fd.write(datastr)\n",
    "                \n",
    "        # feature scaling\n",
    "        ftest_scaled = None\n",
    "        with tempfile.NamedTemporaryFile(delete=False) as fd: \n",
    "            ftest_scaled = fd.name\n",
    "        result = !$self.bin_dir/svm-scale -r $self.fscale $ftest > $ftest_scaled\n",
    "            \n",
    "        # generate prediction file\n",
    "        fpredict = None\n",
    "        with tempfile.NamedTemporaryFile(delete=False) as fd: \n",
    "            fpredict = fd.name\n",
    "            \n",
    "        if self.debug:\n",
    "            print('test data file:', ftest)\n",
    "            print('feature scaled test data file:', ftest_scaled)\n",
    "            print('predict result file:', fpredict)\n",
    "            \n",
    "        # predict using trained model and write prediction to file\n",
    "        result = !$self.bin_dir/$self.bin_predict $ftest_scaled $self.fmodel $fpredict\n",
    "        if self.debug:\n",
    "            print('Predict result: %-30s  %s' % (result[0], result[1]))\n",
    "        \n",
    "        # generate prediction DataFrame from prediction file\n",
    "        poi_rank_df = pd.read_csv(fpredict, header=None)\n",
    "        poi_rank_df.rename(columns={0:'rank'}, inplace=True)\n",
    "        poi_rank_df['poiID'] = test_df['poiID'].astype(np.int)\n",
    "        poi_rank_df.set_index('poiID', inplace=True) # duplicated 'poiID' when evaluating training data\n",
    "        #poi_rank_df['probability'] = softmax(poi_rank_df['rank'])  # softmax\n",
    "        \n",
    "        # remove test file and prediction file\n",
    "        os.unlink(ftest)\n",
    "        os.unlink(ftest_scaled)\n",
    "        os.unlink(fpredict)\n",
    "        \n",
    "        return poi_rank_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sec3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Structured Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[PyStruct](https://pystruct.github.io/) assumes that [label `y` is a discrete vector](https://pystruct.github.io/intro.html) and [pystruct.learners assume labels `y` are integers starting with `0`](https://github.com/pystruct/pystruct/issues/114), concretely,\n",
    "- values in label vector $y$ should satisfy $y_i \\in Y$, \n",
    "  where $Y$ is the **index** of a discrete value space, and the index starts at 0.\n",
    "- label vector $y$ will be [transformed to one hot encoding (see function `joint_feature()`)](https://github.com/pystruct/pystruct/blob/master/pystruct/models/graph_crf.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, if labels in training set is `[[1, 2], [0, 4, 9]]`, \n",
    "then it will cause an index out of bounds error as pystruct did something like this,\n",
    "1. construct an discrete value space: \n",
    "   - `set([1, 2] + [0, 4, 9]) -> {0, 1, 2, 4, 9}`\n",
    "   - `size({0, 1, 2, 4, 9}) = 5`\n",
    "1. convert labels using one hot encoding: \n",
    "   - label vector `[1, 2]` will be converted to a matrix of shape $2 \\times 5$,\n",
    "     with cells at `(0, 1), (1, 2)` set to `1` and others set to `0`.\n",
    "   - label vector `[0, 4, 9]` will be converted to a matrix of shape $3 \\times 5$,\n",
    "     with cells at `(0, 0)`, `(1, 4)`, **`(2, 9)` INDEX_OUT_OF_BOUNDS** set to `1` and others set to `0`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sec3.1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Structured Predition using PyStruct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will analyse the process of using structured SVM to training a CRF and make preditions on new instances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the 1-slack formulation (with margin rescaling) of structured SVM is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\min_{\\mathbf{w}, \\xi \\ge 0} & \\frac{1}{2} \\mathbf{w}^T \\mathbf{w} + C \\xi \\\\\n",
    "s.t. \\forall(\\bar{y}_1, \\dots, \\bar{y}_n) \\in \\mathcal{Y}^n: & \n",
    "\\frac{1}{n} \\mathbf{w}^T \\sum_{i=1}^n \\left( \\Psi(x_i, y_i) - \\Psi(x_i, \\bar{y}_i) \\right) \\ge \n",
    "\\frac{1}{n} \\sum_{i=1}^n \\Delta(y_i, \\bar{y}_i) - \\xi\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where \n",
    "- $\\mathbf{w}$ is the parameter vector\n",
    "- $\\Psi(x_i, y_i)$ is the joint feature (vector) related to example $x_i$ and its label $y_i$\n",
    "- The size of $\\mathbf{w}$ is the same as $\\Psi(x_i, y_i)$\n",
    "- $\\Delta(\\centerdot)$ is the loss function, here we use Hamming loss, i.e., per-variable 0-1 loss, as indicated by function [loss()](https://github.com/pystruct/pystruct/blob/master/pystruct/models/base.py) and [fit()](https://github.com/pystruct/pystruct/blob/master/pystruct/learners/one_slack_ssvm.py).\n",
    "- $n$ is the total number of training examples, $C$ is the regularisation parameter, $\\xi$ is the slack variable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before introducing the training and prediction procedure, we define some concepts that will be used later.\n",
    "- `n_states`: #states for all variables, (this is the total number of unique POIs in training set here).\n",
    "- `n_features`: #features per node, (this is the number of POI features, i.e., the ranking probabilities of all POIs).\n",
    "- `n_edges`: #edges in each training/test example, (this is the number of POIs in a trajectory).\n",
    "- `n_edge_features`: #features per edge, (this is the number of features for each transition, \n",
    "   i.e., the out-going transition probabilities to all POIs).\n",
    "- $x$ is made up of three parts: (`node_features`, `edges`, `edge_features`).\n",
    "- `node_features`: `n_nodes` $\\times$ `n_features`\n",
    "- `edge_features`: `n_edges` $\\times$ `n_edge_features`\n",
    "- `edges`: `n_edges` $\\times$ $2$, e.g. for trajectory `[3, 1, 2]` and `[5, 9, 6]`, their `edges` are the same matrix\n",
    "   `[[0, 1], [1, 2]]`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For [EdgeFeatureGraphCRF](https://pystruct.github.io/generated/pystruct.models.EdgeFeatureGraphCRF.html), the pairwise potentials are asymmetric and shared over all edges, and the size of \n",
    "- **Parameter vector $\\mathbf{w}$: `n_states` $\\times$ `n_features` $+$ `n_edge_features` $\\times$ `(n_states)`$^2$**\n",
    "- The first part of $\\mathbf{w}$, let's call it **`unary_params`**: `n_states` $\\times$ `n_features`, is the parameters \n",
    "  used to compute unary potentials.\n",
    "- The second part of $\\mathbf{w}$, let's call it **`pairwise_params`**: `n_edge_features` $\\times$ `(n_states)`$^2$, \n",
    "  is the parameters used to compute pairwise potentials. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute the joint feature vector $\\Psi(x, y)$\n",
    "\n",
    "When training a CRF using [OneSlackSSVM](https://pystruct.github.io/generated/pystruct.learners.OneSlackSSVM.html), we need to compute the joint feature vector $\\Psi(x, y)$ for each training example, it is computed \n",
    "(for EdgeFeatureGraphCRF in PyStruct) as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unary part of $\\Psi(x, y)$**:\n",
    "- make one-hot encoding of $y$, its size: `n_nodes` $\\times$ `n_states`\n",
    "- *value*: $y^T \\times$ `node_features`\n",
    "- *dimension*: `(n_nodes` $\\times$ `n_states)`$^T$ $\\times$ `(n_nodes` $\\times$ `n_features)` \n",
    "  $\\to$ `(n_states` $\\times$ `n_features)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pairwise Part of $\\Psi(x, y)$**:\n",
    "- make one-hot encoding of `edges`, its size: `n_edges` $\\times$ `(n_states)`$^2$\n",
    "- *value*: `edge_features` $\\times$ `edges`\n",
    "- *dimension*: `(n_edges` $\\times$ `n_edge_features)`$^T$ $\\times$ `(n_edges` $\\times$ `(n_states)`$^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then for each training example, $\\Psi(x_i, y_i)$ = `[unary part, pairwise part]`, solve the above QP problem (1-slack formulation) to get a parameter vector $\\mathbf{w}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a trajectory is chain structured, so we use `max-product` belief propagation (Viterbi algorithm in this case) to do inference in the trained CRF.  \n",
    "To predict the label of a new instance $x$, we need to compute the unary potential and pairwise potential of $x$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unary potential:** \n",
    "- *value*: `node_features` $\\times$ `(unary_params)`$^T$ (first part of $\\mathbf{w}$)\n",
    "- *dimension*: `(n_nodes` $\\times$ `n_features)` $\\times$ `(n_states` $\\times$ `n_features)`$^T$ $\\to$ \n",
    "  `(n_nodes` $\\times$ `n_states)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pairwise potential:**\n",
    "- *value*: `edge_features` $\\times$ `pairwise_params` (second part of $\\mathbf{w}$)\n",
    "- *dimension*: `(n_edges` $\\times$ `n_edge_features)` $\\times$ `(n_edge_features` $\\times$ `n_states`$^2$ `)`, \n",
    "  reshape to `(n_edges` $\\times$ `n_states` $\\times$ `n_states)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With unary potential and pairwise potential computed, as we could know from `edges` that our example $x$ is chain structured, so we do inference using Viterbi algorithm to compute the most likely label of $x$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sec3.2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Node Features -- POI Ranking Probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a trajectory `[start, ..., end]`, the features used to train/test are \n",
    "1. feature for POI `start` is a binary vector of size `total_number_of_POIs`, \n",
    "   with `1` at the location corresponds to POI `start` and `0` anywhere else, e.g. one hot encoding.\n",
    "1. feature for POI `end` is simliar, with `1` at the location corresponds to POI `end`.\n",
    "1. features for other POIs in the trajectory are the ranking probabilities \n",
    "   (produced by rankSVM, transformed by softmax) of all POIs,\n",
    "   i.e. features of different POIs in the middle (i.e. not the `start` or `end`) are the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to build a mapping for POIs: *POI_ID $\\to$ POI_INDEX* with POIs in trajectories in training set, also a map of the reverse direction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sec3.3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Edge Features -- Factorised Transition Probabilities between POIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimate a transition matrix for each feature of POI, transition probabilities (matrix) between different POI features (vector) is obtrained by the Kronecker product of the individual transition matrix corresponding to each feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1 POI Features for Factorisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "POI features used to factorise transition matrix of Markov Chain with POI features (vector) as states:\n",
    "- Category of POI\n",
    "- Popularity of POI (discritize with uniform log-scale bins, #bins <=5 )\n",
    "- The number of POI visits (discritize with uniform log-scale bins, #bins <=5 )\n",
    "- The average visit duration of POI (discritise with uniform log-scale bins, #bins <= 5)\n",
    "- The neighborhood relationship between POIs (clustering POI(lat, lon) using k-means, #clusters <= 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We count the number of transition first, then normalise each row while taking care of zero by adding each cell a number $k=1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalise_transmat(transmat_cnt):\n",
    "    transmat = transmat_cnt.copy()\n",
    "    assert(isinstance(transmat, pd.DataFrame))\n",
    "    for row in range(transmat.index.shape[0]):\n",
    "        rowsum = np.sum(transmat.iloc[row] + 1)\n",
    "        assert(rowsum > 0)\n",
    "        transmat.iloc[row] = (transmat.iloc[row] + 1) / rowsum\n",
    "    return transmat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "POIs in training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "poi_train = sorted(poi_info_all.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 Transition Matrix between POI Cateogries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Education',\n",
       " 'Museum',\n",
       " 'Park',\n",
       " 'Religion',\n",
       " 'Shopping',\n",
       " 'Structure',\n",
       " 'Transport']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poi_cats = poi_all.loc[poi_train, 'poiCat'].unique().tolist()\n",
    "poi_cats.sort()\n",
    "poi_cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_transmat_cat(trajid_list, traj_dict, poi_info, poi_cats=poi_cats):\n",
    "    transmat_cat_cnt = pd.DataFrame(data=np.zeros((len(poi_cats), len(poi_cats)), dtype=np.float), \\\n",
    "                                    columns=poi_cats, index=poi_cats)\n",
    "    for tid in trajid_list:\n",
    "        t = traj_dict[tid]\n",
    "        if len(t) > 1:\n",
    "            for pi in range(len(t)-1):\n",
    "                p1 = t[pi]\n",
    "                p2 = t[pi+1]\n",
    "                assert(p1 in poi_info.index and p2 in poi_info.index)\n",
    "                cat1 = poi_info.loc[p1, 'poiCat']\n",
    "                cat2 = poi_info.loc[p2, 'poiCat']\n",
    "                transmat_cat_cnt.loc[cat1, cat2] += 1\n",
    "    return normalise_transmat(transmat_cat_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Education</th>\n",
       "      <th>Museum</th>\n",
       "      <th>Park</th>\n",
       "      <th>Religion</th>\n",
       "      <th>Shopping</th>\n",
       "      <th>Structure</th>\n",
       "      <th>Transport</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Education</th>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.107143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Museum</th>\n",
       "      <td>0.097561</td>\n",
       "      <td>0.227642</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.040650</td>\n",
       "      <td>0.195122</td>\n",
       "      <td>0.162602</td>\n",
       "      <td>0.252033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Park</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Religion</th>\n",
       "      <td>0.151515</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.212121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shopping</th>\n",
       "      <td>0.254902</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>0.049020</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>0.127451</td>\n",
       "      <td>0.294118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Structure</th>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.098765</td>\n",
       "      <td>0.012346</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.086420</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.246914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Transport</th>\n",
       "      <td>0.137615</td>\n",
       "      <td>0.357798</td>\n",
       "      <td>0.009174</td>\n",
       "      <td>0.073394</td>\n",
       "      <td>0.238532</td>\n",
       "      <td>0.128440</td>\n",
       "      <td>0.055046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Education    Museum      Park  Religion  Shopping  Structure  \\\n",
       "Education   0.285714  0.178571  0.008929  0.062500  0.178571   0.178571   \n",
       "Museum      0.097561  0.227642  0.024390  0.040650  0.195122   0.162602   \n",
       "Park        0.100000  0.200000  0.100000  0.100000  0.100000   0.200000   \n",
       "Religion    0.151515  0.121212  0.060606  0.090909  0.060606   0.303030   \n",
       "Shopping    0.254902  0.235294  0.019608  0.049020  0.019608   0.127451   \n",
       "Structure   0.296296  0.098765  0.012346  0.037037  0.086420   0.222222   \n",
       "Transport   0.137615  0.357798  0.009174  0.073394  0.238532   0.128440   \n",
       "\n",
       "           Transport  \n",
       "Education   0.107143  \n",
       "Museum      0.252033  \n",
       "Park        0.200000  \n",
       "Religion    0.212121  \n",
       "Shopping    0.294118  \n",
       "Structure   0.246914  \n",
       "Transport   0.055046  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_transmat_cat(trajid_set_all, traj_dict, poi_info_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.3 Transition Matrix between POI Popularity Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "poi_pops = poi_info_all.loc[poi_train, 'popularity']\n",
    "#sorted(poi_pops.unique().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discretize POI popularity with uniform log-scale bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 2.25767857487\n"
     ]
    }
   ],
   "source": [
    "expo_pop1 = np.log10(max(1, min(poi_pops)))\n",
    "expo_pop2 = np.log10(max(poi_pops))\n",
    "print(expo_pop1, expo_pop2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0.        ,     3.98107171,    15.84893192,    63.09573445,\n",
       "         251.18864315,  1000.        ])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbins_pop = BIN_CLUSTER\n",
    "logbins_pop = np.logspace(np.floor(expo_pop1), np.ceil(expo_pop2), nbins_pop+1)\n",
    "logbins_pop[0] = 0  # deal with underflow\n",
    "if uspecific == True:\n",
    "    logbins_pop[-1] = KX * logbins_pop[-1]  # deal with overflow\n",
    "if logbins_pop[-1] < poi_info_all['popularity'].max():\n",
    "    logbins_pop[-1] = poi_info_all['popularity'].max() + 1\n",
    "logbins_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUAAAADOCAYAAABPXdu2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1v8A50p+VmvHoi0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f96340c14e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = pd.Series(poi_pops).hist(figsize=(5, 3), bins=logbins_pop)\n",
    "ax.set_xlim(xmin=0.1)\n",
    "ax.set_xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_transmat_pop(trajid_list, traj_dict, poi_info, logbins_pop=logbins_pop):\n",
    "    nbins = len(logbins_pop) - 1\n",
    "    transmat_pop_cnt = pd.DataFrame(data=np.zeros((nbins, nbins), dtype=np.float), \\\n",
    "                                    columns=np.arange(1, nbins+1), index=np.arange(1, nbins+1))\n",
    "    for tid in trajid_list:\n",
    "        t = traj_dict[tid]\n",
    "        if len(t) > 1:\n",
    "            for pi in range(len(t)-1):\n",
    "                p1 = t[pi]\n",
    "                p2 = t[pi+1]\n",
    "                assert(p1 in poi_info.index and p2 in poi_info.index)\n",
    "                pop1 = poi_info.loc[p1, 'popularity']\n",
    "                pop2 = poi_info.loc[p2, 'popularity']\n",
    "                pc1, pc2 = np.digitize([pop1, pop2], logbins_pop)\n",
    "                transmat_pop_cnt.loc[pc1, pc2] += 1\n",
    "    return normalise_transmat(transmat_pop_cnt), logbins_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.014925</td>\n",
       "      <td>0.029851</td>\n",
       "      <td>0.089552</td>\n",
       "      <td>0.850746</td>\n",
       "      <td>0.014925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002217</td>\n",
       "      <td>0.019956</td>\n",
       "      <td>0.119734</td>\n",
       "      <td>0.855876</td>\n",
       "      <td>0.002217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          1         2         3         4         5\n",
       "1  0.200000  0.200000  0.200000  0.200000  0.200000\n",
       "2  0.055556  0.333333  0.055556  0.500000  0.055556\n",
       "3  0.014925  0.029851  0.089552  0.850746  0.014925\n",
       "4  0.002217  0.019956  0.119734  0.855876  0.002217\n",
       "5  0.200000  0.200000  0.200000  0.200000  0.200000"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_transmat_pop(trajid_set_all, traj_dict, poi_info_all)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.4 Transition Matrix between the Number of POI Visit Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "poi_visits = poi_info_all.loc[poi_train, 'nVisit']\n",
    "#sorted(poi_visits.unique().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discretize the number of POI visit with uniform log-scale bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 2.44560420327\n"
     ]
    }
   ],
   "source": [
    "expo_visit1 = np.log10(max(1, min(poi_visits)))\n",
    "expo_visit2 = np.log10(max(poi_visits))\n",
    "print(expo_visit1, expo_visit2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0.        ,     3.98107171,    15.84893192,    63.09573445,\n",
       "         251.18864315,  1000.        ])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbins_visit = BIN_CLUSTER\n",
    "logbins_visit = np.logspace(np.floor(expo_visit1), np.ceil(expo_visit2), nbins_visit+1)\n",
    "logbins_visit[0] = 0  # deal with underflow\n",
    "if uspecific == True:\n",
    "    logbins_visit[-1] = KX * logbins_visit[-1]  # deal with overflow\n",
    "if logbins_visit[-1] < poi_info_all['nVisit'].max():\n",
    "    logbins_visit[-1] = poi_info_all['nVisit'].max() + 1\n",
    "logbins_visit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUAAAADOCAYAAABPXdu2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f96342807f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = pd.Series(poi_visits).hist(figsize=(5, 3), bins=logbins_visit)\n",
    "ax.set_xlim(xmin=0.1)\n",
    "ax.set_xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_transmat_visit(trajid_list, traj_dict, poi_info, logbins_visit=logbins_visit):\n",
    "    nbins = len(logbins_visit) - 1\n",
    "    transmat_visit_cnt = pd.DataFrame(data=np.zeros((nbins, nbins), dtype=np.float), \\\n",
    "                                      columns=np.arange(1, nbins+1), index=np.arange(1, nbins+1))\n",
    "    for tid in trajid_list:\n",
    "        t = traj_dict[tid]\n",
    "        if len(t) > 1:\n",
    "            for pi in range(len(t)-1):\n",
    "                p1 = t[pi]\n",
    "                p2 = t[pi+1]\n",
    "                assert(p1 in poi_info.index and p2 in poi_info.index)\n",
    "                visit1 = poi_info.loc[p1, 'nVisit']\n",
    "                visit2 = poi_info.loc[p2, 'nVisit']\n",
    "                vc1, vc2 = np.digitize([visit1, visit2], logbins_visit)\n",
    "                transmat_visit_cnt.loc[vc1, vc2] += 1\n",
    "    return normalise_transmat(transmat_visit_cnt), logbins_visit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.743590</td>\n",
       "      <td>0.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002387</td>\n",
       "      <td>0.011933</td>\n",
       "      <td>0.085919</td>\n",
       "      <td>0.744630</td>\n",
       "      <td>0.155131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.926471</td>\n",
       "      <td>0.014706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          1         2         3         4         5\n",
       "1  0.200000  0.200000  0.200000  0.200000  0.200000\n",
       "2  0.066667  0.066667  0.266667  0.533333  0.066667\n",
       "3  0.025641  0.076923  0.076923  0.743590  0.076923\n",
       "4  0.002387  0.011933  0.085919  0.744630  0.155131\n",
       "5  0.014706  0.014706  0.029412  0.926471  0.014706"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_transmat_visit(trajid_set_all, traj_dict, poi_info_all)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.5 Transition Matrix between POI Average Visit Duration Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "poi_durations = poi_info_all.loc[poi_train, 'avgDuration']\n",
    "#sorted(poi_durations.unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 3.44236216438\n"
     ]
    }
   ],
   "source": [
    "expo_duration1 = np.log10(max(1, min(poi_durations)))\n",
    "expo_duration2 = np.log10(max(poi_durations))\n",
    "print(expo_duration1, expo_duration2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.00000000e+00,   6.30957344e+00,   3.98107171e+01,\n",
       "         2.51188643e+02,   1.58489319e+03,   2.76925000e+05])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbins_duration = BIN_CLUSTER\n",
    "logbins_duration = np.logspace(np.floor(expo_duration1), np.ceil(expo_duration2), nbins_duration+1)\n",
    "logbins_duration[0] = 0  # deal with underflow\n",
    "if uspecific == True:\n",
    "    logbins_duration[-1] = KX * logbins_duration[-1]  # deal with overflow\n",
    "else:\n",
    "    logbins_duration[-1] = np.power(10, expo_duration2+2)\n",
    "logbins_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATcAAADOCAYAAABbyEVXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBXrpRZfbZYaQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9634039c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = pd.Series(poi_durations).hist(figsize=(5, 3), bins=logbins_duration)\n",
    "ax.set_xlim(xmin=0.1)\n",
    "ax.set_xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_transmat_duration(trajid_list, traj_dict, poi_info, logbins_duration=logbins_duration):\n",
    "    nbins = len(logbins_duration) - 1\n",
    "    transmat_duration_cnt = pd.DataFrame(data=np.zeros((nbins, nbins), dtype=np.float), \\\n",
    "                                         columns=np.arange(1, nbins+1), index=np.arange(1, nbins+1))\n",
    "    for tid in trajid_list:\n",
    "        t = traj_dict[tid]\n",
    "        if len(t) > 1:\n",
    "            for pi in range(len(t)-1):\n",
    "                p1 = t[pi]\n",
    "                p2 = t[pi+1]\n",
    "                assert(p1 in poi_info.index and p2 in poi_info.index)\n",
    "                d1 = poi_info.loc[p1, 'avgDuration']\n",
    "                d2 = poi_info.loc[p2, 'avgDuration']\n",
    "                dc1, dc2 = np.digitize([d1, d2], logbins_duration)\n",
    "                transmat_duration_cnt.loc[dc1, dc2] += 1\n",
    "    return normalise_transmat(transmat_duration_cnt), logbins_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002591</td>\n",
       "      <td>0.002591</td>\n",
       "      <td>0.002591</td>\n",
       "      <td>0.735751</td>\n",
       "      <td>0.256477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.006897</td>\n",
       "      <td>0.006897</td>\n",
       "      <td>0.006897</td>\n",
       "      <td>0.710345</td>\n",
       "      <td>0.268966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          1         2         3         4         5\n",
       "1  0.200000  0.200000  0.200000  0.200000  0.200000\n",
       "2  0.200000  0.200000  0.200000  0.200000  0.200000\n",
       "3  0.200000  0.200000  0.200000  0.200000  0.200000\n",
       "4  0.002591  0.002591  0.002591  0.735751  0.256477\n",
       "5  0.006897  0.006897  0.006897  0.710345  0.268966"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_transmat_duration(trajid_set_all, traj_dict, poi_info_all)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.6 Transition Matrix between POI Neighborhood Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KMeans in scikit-learn seems unable to use custom distance metric and no implementation of [Haversine formula](http://en.wikipedia.org/wiki/Great-circle_distance), use Euclidean distance to approximate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = poi_all.loc[poi_train, ['poiLon', 'poiLat']]\n",
    "nclusters = BIN_CLUSTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(copy_x=True, init='k-means++', max_iter=300, n_clusters=5, n_init=10,\n",
       "    n_jobs=1, precompute_distances='auto', random_state=None, tol=0.0001,\n",
       "    verbose=0)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=nclusters)\n",
    "kmeans.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clusters = kmeans.predict(X)\n",
    "#clusters\n",
    "POI_CLUSTERS = pd.DataFrame(data=clusters, index=poi_train)\n",
    "POI_CLUSTERS.index.name = 'poiID'\n",
    "POI_CLUSTERS.rename(columns={0:'clusterID'}, inplace=True)\n",
    "POI_CLUSTERS['clusterID'] = POI_CLUSTERS['clusterID'].astype(np.int)\n",
    "#POI_CLUSTERS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scatter plot of POI coordinates with clustering results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f9634091cc0>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAFzCAYAAADYA7U2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f96342f5748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "diff = poi_all.loc[poi_train, ['poiLon', 'poiLat']].max() - poi_all.loc[poi_train, ['poiLon', 'poiLat']].min()\n",
    "ratio = diff['poiLon'] / diff['poiLat']\n",
    "#ratio\n",
    "height = 6; width = int(round(ratio)*height)\n",
    "plt.figure(figsize=[width, height])\n",
    "plt.scatter(poi_all.loc[poi_train, 'poiLon'], poi_all.loc[poi_train, 'poiLat'], c=clusters, s=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_transmat_neighbor(trajid_list, traj_dict, poi_info, poi_clusters=POI_CLUSTERS):\n",
    "    nclusters = len(poi_clusters['clusterID'].unique())\n",
    "    transmat_neighbor_cnt = pd.DataFrame(data=np.zeros((nclusters, nclusters), dtype=np.float), \\\n",
    "                                         columns=np.arange(nclusters), index=np.arange(nclusters))\n",
    "    for tid in trajid_list:\n",
    "        t = traj_dict[tid]\n",
    "        if len(t) > 1:\n",
    "            for pi in range(len(t)-1):\n",
    "                p1 = t[pi]\n",
    "                p2 = t[pi+1]\n",
    "                assert(p1 in poi_info.index and p2 in poi_info.index)\n",
    "                c1 = poi_clusters.loc[p1, 'clusterID']\n",
    "                c2 = poi_clusters.loc[p2, 'clusterID']\n",
    "                transmat_neighbor_cnt.loc[c1, c2] += 1\n",
    "    return normalise_transmat(transmat_neighbor_cnt), poi_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.673469</td>\n",
       "      <td>0.006803</td>\n",
       "      <td>0.251701</td>\n",
       "      <td>0.034014</td>\n",
       "      <td>0.034014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.084302</td>\n",
       "      <td>0.002907</td>\n",
       "      <td>0.848837</td>\n",
       "      <td>0.005814</td>\n",
       "      <td>0.058140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.071429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.138889</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4\n",
       "0  0.673469  0.006803  0.251701  0.034014  0.034014\n",
       "1  0.200000  0.200000  0.200000  0.200000  0.200000\n",
       "2  0.084302  0.002907  0.848837  0.005814  0.058140\n",
       "3  0.285714  0.071429  0.142857  0.428571  0.071429\n",
       "4  0.138889  0.027778  0.638889  0.027778  0.166667"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_transmat_neighbor(trajid_set_all, traj_dict, poi_info_all)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.7 Transition Matrix between POIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approximate transition probabilities (matrix) between different POI features (vector) using the [Kronecker product](https://en.wikipedia.org/wiki/Kronecker_product) of individual transition matrix corresponding to each feature, i.e., POI category, POI popularity (discritized), POI average visit duration (discritized) and POI neighborhoods (clusters)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deal with features without corresponding POIs and feature with more than one corresponding POIs. (*Before Normalisation*)\n",
    "- For features without corresponding POIs, just remove the rows and columns from the matrix obtained by Kronecker product.\n",
    "- For different POIs with the exact same feature, \n",
    "  - Let POIs with the same feature as a POI group,\n",
    "  - The *incoming* **transition value (i.e., unnormalised transition probability)** of this POI group \n",
    "    should be divided uniformly among the group members, \n",
    "    *which corresponds to choose a group member uniformly at random in the incoming case*.\n",
    "  - The *outgoing* transition value should be duplicated (i.e., the same) among all group members, \n",
    "    **as we were already in that group in the outgoing case**.\n",
    "  - For each POI in the group, the allocation transition value of the *self-loop of the POI group* is similar to \n",
    "    that in the *outgoing* case, **as we were already in that group**, so just duplicate and then divide uniformly among \n",
    "    the transitions from this POI to other POIs in the same group, \n",
    "    *which corresponds to choose a outgoing transition uniformly at random from all outgoing transitions\n",
    "    excluding the self-loop of this POI*.\n",
    "- **Concretely**, for a POI group with $n$ POIs, \n",
    "    1. If the *incoming* transition value of POI group is $m_1$,\n",
    "       then the corresponding *incoming* transition value for each group member is $\\frac{m_1}{n}$.\n",
    "    1. If the *outgoing* transition value of POI group is $m_2$,\n",
    "       then the corresponding *outgoing* transition value for each group member is also $m_2$.\n",
    "    1. If the transition value of *self-loop of the POI group* is $m_3$,\n",
    "       then transition value of *self-loop of individual POIs* should be $0$,  \n",
    "       and *other in-group transitions* with value $\\frac{m_3}{n-1}$\n",
    "       as the total number of outgoing transitions to other POIs in the same group is $n-1$ (excluding the self-loop),\n",
    "       i.e. $n-1$ choose $1$.\n",
    "       \n",
    "**NOTE**: execute the above division before or after row normalisation will lead to the same result, *as the division itself does NOT change the normalising constant of each row (i.e., the sum of each row before normalising)*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_poi_transmat(trajid_list, poi_set, traj_dict, poi_info, debug=False):\n",
    "    transmat_cat                        = gen_transmat_cat(trajid_list, traj_dict, poi_info)\n",
    "    transmat_pop,      logbins_pop      = gen_transmat_pop(trajid_list, traj_dict, poi_info)\n",
    "    transmat_visit,    logbins_visit    = gen_transmat_visit(trajid_list, traj_dict, poi_info)\n",
    "    transmat_duration, logbins_duration = gen_transmat_duration(trajid_list, traj_dict, poi_info)\n",
    "    transmat_neighbor, poi_clusters     = gen_transmat_neighbor(trajid_list, traj_dict, poi_info)\n",
    "\n",
    "    # Kronecker product\n",
    "    transmat_ix = list(itertools.product(transmat_cat.index, transmat_pop.index, transmat_visit.index, \\\n",
    "                                         transmat_duration.index, transmat_neighbor.index))\n",
    "    transmat_value = transmat_cat.values\n",
    "    for transmat in [transmat_pop, transmat_visit, transmat_duration, transmat_neighbor]:\n",
    "        transmat_value = kron(transmat_value, transmat.values)\n",
    "    transmat_feature = pd.DataFrame(data=transmat_value, index=transmat_ix, columns=transmat_ix)\n",
    "    \n",
    "    poi_train = sorted(poi_set)\n",
    "    feature_names = ['poiCat', 'popularity', 'nVisit', 'avgDuration', 'clusterID']\n",
    "    poi_features = pd.DataFrame(data=np.zeros((len(poi_train), len(feature_names))), \\\n",
    "                                columns=feature_names, index=poi_train)\n",
    "    poi_features.index.name = 'poiID'\n",
    "    poi_features['poiCat'] = poi_info.loc[poi_train, 'poiCat']\n",
    "    poi_features['popularity'] = np.digitize(poi_info.loc[poi_train, 'popularity'], logbins_pop)\n",
    "    poi_features['nVisit'] = np.digitize(poi_info.loc[poi_train, 'nVisit'], logbins_visit)\n",
    "    poi_features['avgDuration'] = np.digitize(poi_info.loc[poi_train, 'avgDuration'], logbins_duration)\n",
    "    poi_features['clusterID'] = poi_clusters.loc[poi_train, 'clusterID']\n",
    "    \n",
    "    # shrink the result of Kronecker product and deal with POIs with the same features\n",
    "    poi_logtransmat = pd.DataFrame(data=np.zeros((len(poi_train), len(poi_train)), dtype=np.float), \\\n",
    "                                   columns=poi_train, index=poi_train)\n",
    "    for p1 in poi_logtransmat.index:\n",
    "        rix = tuple(poi_features.loc[p1])\n",
    "        for p2 in poi_logtransmat.columns:\n",
    "            cix = tuple(poi_features.loc[p2])\n",
    "            value_ = transmat_feature.loc[(rix,), (cix,)]\n",
    "            poi_logtransmat.loc[p1, p2] = value_.values[0, 0]\n",
    "    \n",
    "    # group POIs with the same features\n",
    "    features_dup = dict()\n",
    "    for poi in poi_features.index:\n",
    "        key = tuple(poi_features.loc[poi])\n",
    "        if key in features_dup:\n",
    "            features_dup[key].append(poi)\n",
    "        else:\n",
    "            features_dup[key] = [poi]\n",
    "    if debug == True:\n",
    "        for key in sorted(features_dup.keys()):\n",
    "            print(key, '->', features_dup[key])\n",
    "            \n",
    "    # deal with POIs with the same features\n",
    "    for feature in sorted(features_dup.keys()):\n",
    "        n = len(features_dup[feature])\n",
    "        if n > 1:\n",
    "            group = features_dup[feature]\n",
    "            v1 = poi_logtransmat.loc[group[0], group[0]]  # transition value of self-loop of POI group\n",
    "            \n",
    "            # divide incoming transition value (i.e. unnormalised transition probability) uniformly among group members\n",
    "            for poi in group:\n",
    "                poi_logtransmat[poi] /= n\n",
    "                \n",
    "            # outgoing transition value has already been duplicated (value copied above)\n",
    "            \n",
    "            # duplicate & divide transition value of self-loop of POI group uniformly among all outgoing transitions,\n",
    "            # from a POI to all other POIs in the same group (excluding POI self-loop)\n",
    "            v2 = v1 / (n - 1)\n",
    "            for pair in itertools.permutations(group, 2):\n",
    "                poi_logtransmat.loc[pair[0], pair[1]] = v2\n",
    "                            \n",
    "    # normalise each row\n",
    "    for p1 in poi_logtransmat.index:\n",
    "        poi_logtransmat.loc[p1, p1] = 0\n",
    "        rowsum = poi_logtransmat.loc[p1].sum()\n",
    "        assert(rowsum > 0)\n",
    "        logrowsum = np.log10(rowsum)\n",
    "        for p2 in poi_logtransmat.columns:\n",
    "            if p1 == p2:\n",
    "                poi_logtransmat.loc[p1, p2] = -np.inf  # deal with log(0) explicitly\n",
    "            else:\n",
    "                poi_logtransmat.loc[p1, p2] = np.log10(poi_logtransmat.loc[p1, p2]) - logrowsum\n",
    "    \n",
    "    poi_transmat = np.power(10, poi_logtransmat)\n",
    "    return poi_transmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Education', 2, 2, 4, 2) -> [8]\n",
      "('Education', 3, 3, 5, 4) -> [7]\n",
      "('Education', 3, 4, 4, 0) -> [9]\n",
      "('Education', 4, 4, 4, 0) -> [10]\n",
      "('Education', 4, 4, 4, 2) -> [12]\n",
      "('Education', 4, 4, 5, 2) -> [11]\n",
      "('Museum', 2, 2, 5, 3) -> [17]\n",
      "('Museum', 3, 3, 4, 0) -> [25]\n",
      "('Museum', 4, 4, 4, 2) -> [21]\n",
      "('Museum', 4, 4, 5, 0) -> [26]\n",
      "('Park', 2, 2, 4, 4) -> [18]\n",
      "('Park', 3, 3, 4, 4) -> [22]\n",
      "('Religion', 2, 2, 4, 2) -> [14]\n",
      "('Religion', 4, 4, 5, 4) -> [13]\n",
      "('Shopping', 4, 4, 4, 0) -> [15]\n",
      "('Shopping', 4, 4, 4, 2) -> [16]\n",
      "('Structure', 2, 3, 5, 3) -> [24, 27]\n",
      "('Structure', 3, 3, 4, 2) -> [29]\n",
      "('Structure', 3, 4, 5, 0) -> [19]\n",
      "('Structure', 4, 4, 4, 2) -> [20, 28]\n",
      "('Transport', 1, 1, 1, 1) -> [4]\n",
      "('Transport', 1, 1, 1, 3) -> [5]\n",
      "('Transport', 3, 3, 4, 2) -> [6]\n",
      "('Transport', 4, 4, 5, 2) -> [1]\n",
      "('Transport', 4, 5, 4, 2) -> [2]\n"
     ]
    }
   ],
   "source": [
    "transmat_ = gen_poi_transmat(trajid_set_all, set(poi_info_all.index), traj_dict, poi_info_all, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sec3.4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Leave-one-out Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train an [EdgeFeatureGraphCRF](https://pystruct.github.io/generated/pystruct.models.EdgeFeatureGraphCRF.html) using [OneSlackSSVM](https://pystruct.github.io/generated/pystruct.learners.OneSlackSSVM.html#pystruct.learners.OneSlackSSVM):\n",
    "- Node features: POI ranking probabilities\n",
    "- Edge features: Outgoing POI transition probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gen_features(startPOI, endPOI, nPOI, rank_df, transmat_mapped, poi_ix, poi_id_dict):\n",
    "    assert(len(poi_ix) == transmat_mapped.shape[0] == transmat_mapped.shape[1])\n",
    "    assert(startPOI in poi_id_dict and startPOI in poi_ix)\n",
    "    assert(endPOI   in poi_id_dict and endPOI   in poi_ix)\n",
    "    assert(nPOI > 2)\n",
    "    p0, pN, L = startPOI, endPOI, nPOI\n",
    "    \n",
    "    # node features\n",
    "    # (traj_length - 2) x (total number of POIs in trajectories with length >= 3)\n",
    "    featuremat = np.tile(softmax(rank_df.loc[poi_ix, 'rank']), (L-2, 1)) # without start/end\n",
    "    node_s = np.zeros(len(poi_ix), dtype=np.float)\n",
    "    node_e = np.zeros(len(poi_ix), dtype=np.float)\n",
    "    node_s[poi_id_dict[p0]] = 1\n",
    "    node_e[poi_id_dict[pN]] = 1\n",
    "    node_features = np.vstack([node_s, featuremat, node_e])\n",
    "    \n",
    "    # edge features\n",
    "    #s_ix = np.argmax(p0 == np.array(poi_ix))\n",
    "    #e_ix = np.argmax(pN == np.array(poi_ix))\n",
    "    #edge_s = np.zeros_like(transmat_mapped) \n",
    "    #edge_e = np.zeros_like(transmat_mapped)\n",
    "    #edge_s[s_ix] = transmat_mapped[s_ix];    edge_s = edge_s.flatten()\n",
    "    #edge_e[e_ix] = transmat_mapped[:, e_ix]; edge_e = edge_e.flatten()\n",
    "    #edge_features = np.vstack([edge_s, np.tile(transmat_mapped.flatten(), (len(tr)-3, 1)), edge_e])\n",
    "    s0 = np.zeros(transmat_mapped.shape[0])\n",
    "    sN = np.zeros(transmat_mapped.shape[0])\n",
    "    s0[poi_id_dict[p0]] = 1\n",
    "    sN[poi_id_dict[pN]] = 1\n",
    "    MC_forward  = [s0]   # states of nodes\n",
    "    #MC_backward = [sN]\n",
    "    for ei in range(L-3):\n",
    "        # walk the MC forward, result is a normalised vector as both arguments of np.dot() are normalised (easy to prove)\n",
    "        MC_forward.append(np.dot(MC_forward[-1], transmat_mapped))\n",
    "        #MC_backward = [softmax(np.dot(MC_backward[0], transmat_inv))] + MC_backward  # walk the MC backward\n",
    "    edge_features = np.dot(np.vstack(MC_forward), transmat_mapped)\n",
    "    #edge_features = np.vstack([edge_features, sN])\n",
    "    #edge_last = np.log(transmat_mapped[:, poi_id_dict[pN]])\n",
    "    #edge_last = np.exp(edge_last - logsumexp(edge_last))  # renormalise\n",
    "    large_prob = 0.6\n",
    "    small_prob = (1 - large_prob) / (sN.shape[0] - 1)\n",
    "    edge_last = sN * small_prob; edge_last[poi_id_dict[pN]] = large_prob\n",
    "    edge_features = np.vstack([edge_features, edge_last])\n",
    "    #edge_features = np.dot(np.vstack(MC_backward[:-1]), transmat_mapped)       \n",
    "    #ss = 0.5 * (np.vstack(MC_forward[:-1]) + np.vstack(MC_backward[:-1]))  # remove the last state when computing edges\n",
    "    #edge_features = np.dot(ss, transmat_mapped)\n",
    "    \n",
    "    #r1 = [0.5**x for x in range(L-1)]  # ratios forward\n",
    "    #r2 = r1.copy(); r2.reverse()       # ratios backward\n",
    "    #sums = np.array(r1) + np.array(r2)\n",
    "    #r1 = np.array(r1) / sums           # normalise ratios\n",
    "    #r2 = np.array(r2) / sums\n",
    "    #forward  = np.multiply(np.tile(r1, (s0.shape[0], 1)).T, np.vstack(MC_forward[:-1]))\n",
    "    #backward = np.multiply(np.tile(r2, (sN.shape[0], 1)).T, np.vstack(MC_backward[:-1]))\n",
    "    #edge_features = np.dot(forward + backward, transmat_mapped)\n",
    "    \n",
    "    #edge_features = np.hstack([np.dot(np.vstack(MC_forward[:-1]), transmat_mapped), \\\n",
    "    #                           np.dot(np.vstack(MC_backward[:-1]), transmat_mapped)])\n",
    "    \n",
    "    # edges\n",
    "    edges = np.vstack([np.arange(L-1), np.arange(1, L)]).T  # shape: (n_edges, 2)\n",
    "    return (node_features, edges, edge_features)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "F1_train_list = []\n",
    "F1_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20, 16, 21, 2] #1 ->\n",
      "           [20, 2, 21, 2]\n",
      "           rank: 7.8 sec, transition: 2.7 sec, train_data: 15.6 sec, train: 5.4 sec, total: 33.7 sec\n",
      "           Test F1: 0.750\n",
      "[13, 21, 2] #2 ->\n",
      "           [13, 21, 2]\n",
      "           rank: 7.7 sec, transition: 2.6 sec, train_data: 16.3 sec, train: 4.8 sec, total: 33.7 sec\n",
      "           Test F1: 1.000\n",
      "[2, 21, 16] #3 ->\n",
      "           [2, 21, 16]\n",
      "           rank: 7.6 sec, transition: 2.7 sec, train_data: 16.6 sec, train: 5.0 sec, total: 34.2 sec\n",
      "           Test F1: 1.000\n",
      "[2, 10, 21, 26] #4 ->\n",
      "           [2, 26, 25, 26]\n",
      "           rank: 7.4 sec, transition: 2.6 sec, train_data: 15.5 sec, train: 4.8 sec, total: 32.7 sec\n",
      "           Test F1: 0.500\n",
      "[28, 2, 13] #5 ->\n",
      "           [28, 12, 13]\n",
      "           rank: 7.7 sec, transition: 2.6 sec, train_data: 16.7 sec, train: 4.9 sec, total: 34.3 sec\n",
      "           Test F1: 0.667\n",
      "[11, 26, 25, 20, 28] #6 ->\n",
      "           [11, 28, 11, 12, 28]\n",
      "           rank: 7.4 sec, transition: 2.6 sec, train_data: 15.4 sec, train: 4.8 sec, total: 32.6 sec\n",
      "           Test F1: 0.400\n",
      "[2, 16, 1, 12, 21, 14] #7 ->\n",
      "           [2, 21, 16, 21, 16, 10]\n",
      "           rank: 7.8 sec, transition: 2.6 sec, train_data: 15.8 sec, train: 4.6 sec, total: 33.2 sec\n",
      "           Test F1: 0.667\n",
      "[9, 10, 15] #8 ->\n",
      "           [9, 10, 15]\n",
      "           rank: 8.4 sec, transition: 2.8 sec, train_data: 15.8 sec, train: 5.1 sec, total: 34.5 sec\n",
      "           Test F1: 1.000\n",
      "[12, 20, 16, 21, 1] #9 ->\n",
      "           [12, 1, 20, 16, 1]\n",
      "           rank: 7.6 sec, transition: 2.6 sec, train_data: 15.7 sec, train: 5.4 sec, total: 33.8 sec\n",
      "           Test F1: 0.800\n",
      "[19, 11, 28] #10 ->\n",
      "           [19, 25, 28]\n",
      "           rank: 7.5 sec, transition: 2.7 sec, train_data: 15.6 sec, train: 5.6 sec, total: 33.8 sec\n",
      "           Test F1: 0.667\n",
      "[12, 1, 16, 21, 2] #11 ->\n",
      "           [12, 20, 16, 21, 2]\n",
      "           rank: 7.8 sec, transition: 2.6 sec, train_data: 15.7 sec, train: 5.4 sec, total: 33.9 sec\n",
      "           Test F1: 0.800\n",
      "[28, 11, 16] #12 ->\n",
      "           [28, 21, 16]\n",
      "           rank: 7.8 sec, transition: 2.6 sec, train_data: 15.9 sec, train: 5.2 sec, total: 33.9 sec\n",
      "           Test F1: 0.667\n",
      "[1, 2, 21] #13 ->\n",
      "           [1, 16, 21]\n",
      "           rank: 8.5 sec, transition: 2.6 sec, train_data: 15.9 sec, train: 5.3 sec, total: 34.7 sec\n",
      "           Test F1: 0.667\n",
      "[13, 2, 21, 16] #14 ->\n",
      "           [13, 1, 21, 16]\n",
      "           rank: 7.8 sec, transition: 2.6 sec, train_data: 15.8 sec, train: 5.6 sec, total: 34.2 sec\n",
      "           Test F1: 0.750\n",
      "[9, 26, 2] #15 ->\n",
      "           [9, 10, 2]\n",
      "           rank: 7.4 sec, transition: 2.6 sec, train_data: 15.5 sec, train: 4.9 sec, total: 32.9 sec\n",
      "           Test F1: 0.667\n",
      "[1, 16, 2] #16 ->\n",
      "           [1, 21, 2]\n",
      "           rank: 8.1 sec, transition: 2.6 sec, train_data: 15.7 sec, train: 5.1 sec, total: 33.9 sec\n",
      "           Test F1: 0.667\n",
      "[2, 9, 10, 21] #17 ->\n",
      "           [2, 21, 16, 21]\n",
      "           rank: 8.0 sec, transition: 2.6 sec, train_data: 16.0 sec, train: 5.1 sec, total: 34.0 sec\n",
      "           Test F1: 0.500\n",
      "[16, 21, 26] #18 ->\n",
      "           [16, 2, 26]\n",
      "           rank: 7.7 sec, transition: 2.6 sec, train_data: 15.8 sec, train: 5.1 sec, total: 33.5 sec\n",
      "           Test F1: 0.667\n",
      "[17, 26, 27] #19 ->\n",
      "           [9, 10, 27]\n",
      "           rank: 7.5 sec, transition: 2.6 sec, train_data: 15.6 sec, train: 5.0 sec, total: 33.0 sec\n",
      "           Test F1: 0.667\n",
      "[15, 25, 26] #20 ->\n",
      "           [15, 10, 26]\n",
      "           rank: 7.5 sec, transition: 2.7 sec, train_data: 15.6 sec, train: 5.2 sec, total: 33.4 sec\n",
      "           Test F1: 0.667\n",
      "[1, 21, 2] #21 ->\n",
      "           [1, 16, 2]\n",
      "           rank: 7.9 sec, transition: 2.7 sec, train_data: 16.1 sec, train: 5.2 sec, total: 34.3 sec\n",
      "           Test F1: 0.667\n",
      "[26, 19, 2] #22 ->\n",
      "           [26, 9, 2]\n",
      "           rank: 7.6 sec, transition: 2.7 sec, train_data: 16.5 sec, train: 4.8 sec, total: 34.0 sec\n",
      "           Test F1: 0.667\n",
      "[13, 2, 20] #23 ->\n",
      "           [13, 28, 20]\n",
      "           rank: 7.5 sec, transition: 2.7 sec, train_data: 15.9 sec, train: 5.4 sec, total: 33.9 sec\n",
      "           Test F1: 0.667\n",
      "[21, 2, 11] #24 ->\n",
      "           [21, 16, 11]\n",
      "           rank: 7.7 sec, transition: 2.7 sec, train_data: 16.1 sec, train: 5.1 sec, total: 34.0 sec\n",
      "           Test F1: 0.667\n",
      "[21, 2, 7, 13, 28, 11, 12, 16] #25 ->\n",
      "           [21, 16, 21, 16, 1, 16, 21, 16]\n",
      "           rank: 7.3 sec, transition: 2.5 sec, train_data: 16.0 sec, train: 5.1 sec, total: 33.2 sec\n",
      "           Test F1: 0.250\n",
      "[1, 11, 26, 25, 29, 28, 12] #26 ->\n",
      "           [1, 16, 1, 16, 13, 28, 12]\n",
      "           rank: 7.6 sec, transition: 2.8 sec, train_data: 16.2 sec, train: 5.2 sec, total: 34.0 sec\n",
      "           Test F1: 0.429\n",
      "[25, 10, 12] #27 ->\n",
      "           [25, 28, 12]\n",
      "           rank: 7.7 sec, transition: 2.7 sec, train_data: 16.0 sec, train: 5.0 sec, total: 33.7 sec\n",
      "           Test F1: 0.667\n",
      "[11, 12, 26] #28 ->\n",
      "           [11, 20, 26]\n",
      "           rank: 7.9 sec, transition: 2.6 sec, train_data: 15.9 sec, train: 5.1 sec, total: 33.9 sec\n",
      "           Test F1: 0.667\n",
      "[28, 12, 20] #29 ->\n",
      "           [28, 2, 20]\n",
      "           rank: 7.6 sec, transition: 2.7 sec, train_data: 15.9 sec, train: 5.4 sec, total: 33.8 sec\n",
      "           Test F1: 0.667\n",
      "[20, 2, 12] #30 ->\n",
      "           [20, 28, 12]\n",
      "           rank: 7.9 sec, transition: 2.6 sec, train_data: 15.4 sec, train: 5.0 sec, total: 33.3 sec\n",
      "           Test F1: 0.667\n",
      "[2, 13, 11] #31 ->\n",
      "           [2, 20, 11]\n",
      "           rank: 7.6 sec, transition: 2.6 sec, train_data: 16.1 sec, train: 5.4 sec, total: 34.0 sec\n",
      "           Test F1: 0.667\n",
      "[2, 16, 1] #32 ->\n",
      "           [2, 21, 1]\n",
      "           rank: 8.0 sec, transition: 2.7 sec, train_data: 16.0 sec, train: 5.2 sec, total: 34.2 sec\n",
      "           Test F1: 0.667\n",
      "[2, 26, 20] #33 ->\n",
      "           [2, 13, 20]\n",
      "           rank: 7.5 sec, transition: 2.8 sec, train_data: 16.4 sec, train: 5.0 sec, total: 34.0 sec\n",
      "           Test F1: 0.667\n",
      "[21, 2, 16] #34 ->\n",
      "           [21, 21, 16]\n",
      "           rank: 7.9 sec, transition: 2.6 sec, train_data: 15.8 sec, train: 5.4 sec, total: 34.1 sec\n",
      "           Test F1: 0.667\n",
      "[21, 16, 2] #35 ->\n",
      "           [21, 16, 2]\n",
      "           rank: 7.8 sec, transition: 2.6 sec, train_data: 16.7 sec, train: 5.7 sec, total: 35.1 sec\n",
      "           Test F1: 1.000\n",
      "[1, 16, 2] #36 ->\n",
      "           [1, 21, 2]\n",
      "           rank: 7.9 sec, transition: 2.8 sec, train_data: 15.9 sec, train: 5.6 sec, total: 34.5 sec\n",
      "           Test F1: 0.667\n",
      "[16, 14, 13] #37 ->\n",
      "           [16, 21, 13]\n",
      "           rank: 7.9 sec, transition: 2.7 sec, train_data: 15.7 sec, train: 5.2 sec, total: 33.7 sec\n",
      "           Test F1: 0.667\n",
      "[1, 21, 16, 6] #38 ->\n",
      "           [1, 16, 26, 6]\n",
      "           rank: 7.5 sec, transition: 2.7 sec, train_data: 15.5 sec, train: 5.6 sec, total: 33.5 sec\n",
      "           Test F1: 0.750\n",
      "[13, 20, 28] #39 ->\n",
      "           [13, 2, 28]\n",
      "           rank: 7.7 sec, transition: 2.7 sec, train_data: 15.5 sec, train: 4.8 sec, total: 33.0 sec\n",
      "           Test F1: 0.667\n",
      "[1, 16, 28] #40 ->\n",
      "           [1, 11, 28]\n",
      "           rank: 7.6 sec, transition: 2.6 sec, train_data: 16.2 sec, train: 6.3 sec, total: 35.1 sec\n",
      "           Test F1: 0.667\n",
      "[1, 28, 20, 9] #41 ->\n",
      "           [1, 16, 10, 9]\n",
      "           rank: 8.2 sec, transition: 2.7 sec, train_data: 15.8 sec, train: 5.2 sec, total: 34.1 sec\n",
      "           Test F1: 0.500\n",
      "[29, 28, 12] #42 ->\n",
      "           [29, 28, 12]\n",
      "           rank: 7.5 sec, transition: 2.8 sec, train_data: 17.1 sec, train: 5.6 sec, total: 35.3 sec\n",
      "           Test F1: 1.000\n",
      "[10, 25, 26] #43 ->\n",
      "           [10, 9, 26]\n",
      "           rank: 7.7 sec, transition: 2.7 sec, train_data: 16.7 sec, train: 5.3 sec, total: 34.7 sec\n",
      "           Test F1: 0.667\n",
      "[15, 10, 26, 25] #44 ->\n",
      "           [15, 10, 15, 25]\n",
      "           rank: 7.8 sec, transition: 2.6 sec, train_data: 16.3 sec, train: 5.3 sec, total: 34.4 sec\n",
      "           Test F1: 0.750\n",
      "[10, 15, 25] #45 ->\n",
      "           [10, 26, 25]\n",
      "           rank: 7.9 sec, transition: 2.6 sec, train_data: 15.9 sec, train: 5.3 sec, total: 34.1 sec\n",
      "           Test F1: 0.667\n",
      "[2, 21, 16, 1] #46 ->\n",
      "           [2, 16, 21, 1]\n",
      "           rank: 8.1 sec, transition: 2.7 sec, train_data: 16.9 sec, train: 5.4 sec, total: 35.4 sec\n",
      "           Test F1: 1.000\n",
      "[25, 10, 9, 2] #47 ->\n",
      "           [25, 10, 21, 2]\n",
      "           rank: 7.6 sec, transition: 2.8 sec, train_data: 15.6 sec, train: 5.3 sec, total: 33.7 sec\n",
      "           Test F1: 0.750\n",
      "[15, 10, 19] #48 ->\n",
      "           [15, 10, 19]\n",
      "           rank: 7.6 sec, transition: 2.6 sec, train_data: 15.9 sec, train: 5.0 sec, total: 33.4 sec\n",
      "           Test F1: 1.000\n",
      "[21, 16, 1, 26, 9, 10, 15] #49 ->\n",
      "           [21, 16, 2, 13, 9, 10, 15]\n",
      "           rank: 7.5 sec, transition: 2.6 sec, train_data: 15.7 sec, train: 4.6 sec, total: 32.8 sec\n",
      "           Test F1: 0.714\n",
      "[29, 16, 2] #50 ->\n",
      "           [29, 21, 2]\n",
      "           rank: 8.1 sec, transition: 2.6 sec, train_data: 16.0 sec, train: 5.3 sec, total: 34.4 sec\n",
      "           Test F1: 0.667\n",
      "[10, 9, 26] #51 ->\n",
      "           [10, 25, 26]\n",
      "           rank: 7.9 sec, transition: 2.6 sec, train_data: 15.7 sec, train: 4.9 sec, total: 33.4 sec\n",
      "           Test F1: 0.667\n",
      "[26, 13, 20] #52 ->\n",
      "           [26, 10, 20]\n",
      "           rank: 7.5 sec, transition: 2.6 sec, train_data: 15.4 sec, train: 5.0 sec, total: 32.8 sec\n",
      "           Test F1: 0.667\n",
      "[11, 1, 16, 9] #53 ->\n",
      "           [11, 26, 10, 9]\n",
      "           rank: 7.8 sec, transition: 2.6 sec, train_data: 15.3 sec, train: 5.0 sec, total: 33.0 sec\n",
      "           Test F1: 0.500\n",
      "[16, 2, 21] #54 ->\n",
      "           [16, 2, 21]\n",
      "           rank: 8.2 sec, transition: 2.9 sec, train_data: 16.5 sec, train: 5.2 sec, total: 35.0 sec\n",
      "           Test F1: 1.000\n",
      "[1, 21, 2] #55 ->\n",
      "           [1, 16, 2]\n",
      "           rank: 7.8 sec, transition: 2.6 sec, train_data: 15.6 sec, train: 5.0 sec, total: 33.3 sec\n",
      "           Test F1: 0.667\n",
      "[26, 10, 9] #56 ->\n",
      "           [26, 10, 9]\n",
      "           rank: 7.4 sec, transition: 2.6 sec, train_data: 16.4 sec, train: 5.2 sec, total: 34.0 sec\n",
      "           Test F1: 1.000\n",
      "[13, 28, 2, 26] #57 ->\n",
      "           [13, 28, 12, 26]\n",
      "           rank: 7.6 sec, transition: 2.6 sec, train_data: 15.3 sec, train: 4.9 sec, total: 32.8 sec\n",
      "           Test F1: 0.750\n",
      "[1, 2, 20] #58 ->\n",
      "           [1, 16, 20]\n",
      "           rank: 8.3 sec, transition: 2.6 sec, train_data: 15.9 sec, train: 4.9 sec, total: 33.9 sec\n",
      "           Test F1: 0.667\n",
      "[2, 13, 9, 16, 21] #59 ->\n",
      "           [2, 16, 1, 2, 21]\n",
      "           rank: 7.7 sec, transition: 2.6 sec, train_data: 16.7 sec, train: 4.8 sec, total: 34.2 sec\n",
      "           Test F1: 0.600\n",
      "[2, 20, 26] #60 ->\n",
      "           [2, 21, 26]\n",
      "           rank: 7.8 sec, transition: 2.6 sec, train_data: 15.9 sec, train: 4.9 sec, total: 33.6 sec\n",
      "           Test F1: 0.667\n",
      "[11, 12, 28] #61 ->\n",
      "           [11, 20, 28]\n",
      "           rank: 7.8 sec, transition: 2.7 sec, train_data: 16.0 sec, train: 5.3 sec, total: 34.0 sec\n",
      "           Test F1: 0.667\n",
      "[13, 28, 12] #62 ->\n",
      "           [13, 28, 12]\n",
      "           rank: 8.1 sec, transition: 2.6 sec, train_data: 16.7 sec, train: 5.4 sec, total: 35.0 sec\n",
      "           Test F1: 1.000\n",
      "[11, 28, 20, 2] #63 ->\n",
      "           [11, 16, 21, 2]\n",
      "           rank: 7.6 sec, transition: 2.6 sec, train_data: 15.9 sec, train: 5.2 sec, total: 33.7 sec\n",
      "           Test F1: 0.500\n",
      "[2, 21, 16, 13, 10] #64 ->\n",
      "           [2, 13, 28, 20, 10]\n",
      "           rank: 7.7 sec, transition: 2.6 sec, train_data: 15.5 sec, train: 5.1 sec, total: 33.2 sec\n",
      "           Test F1: 0.600\n",
      "[16, 2, 21] #65 ->\n",
      "           [16, 2, 21]\n",
      "           rank: 7.7 sec, transition: 2.6 sec, train_data: 16.3 sec, train: 4.8 sec, total: 33.8 sec\n",
      "           Test F1: 1.000\n",
      "[12, 20, 2] #66 ->\n",
      "           [12, 21, 2]\n",
      "           rank: 7.8 sec, transition: 2.6 sec, train_data: 16.0 sec, train: 5.2 sec, total: 33.9 sec\n",
      "           Test F1: 0.667\n",
      "[20, 28, 12, 16, 1] #67 ->\n",
      "           [20, 2, 9, 10, 1]\n",
      "           rank: 7.6 sec, transition: 2.6 sec, train_data: 16.7 sec, train: 5.1 sec, total: 34.3 sec\n",
      "           Test F1: 0.400\n",
      "[9, 10, 15] #68 ->\n",
      "           [9, 10, 15]\n",
      "           rank: 7.5 sec, transition: 2.6 sec, train_data: 15.4 sec, train: 5.1 sec, total: 32.9 sec\n",
      "           Test F1: 1.000\n",
      "[9, 10, 1] #69 ->\n",
      "           [9, 10, 1]\n",
      "           rank: 7.9 sec, transition: 2.7 sec, train_data: 17.7 sec, train: 5.0 sec, total: 35.7 sec\n",
      "           Test F1: 1.000\n",
      "[1, 16, 2, 26, 6] #70 ->\n",
      "           [1, 16, 1, 16, 6]\n",
      "           rank: 8.0 sec, transition: 2.6 sec, train_data: 16.7 sec, train: 5.1 sec, total: 34.7 sec\n",
      "           Test F1: 0.600\n",
      "[10, 15, 11, 16, 21] #71 ->\n",
      "           [10, 15, 10, 2, 21]\n",
      "           rank: 7.8 sec, transition: 2.6 sec, train_data: 15.9 sec, train: 5.0 sec, total: 33.6 sec\n",
      "           Test F1: 0.600\n",
      "[2, 28, 12] #72 ->\n",
      "           [2, 28, 12]\n",
      "           rank: 7.7 sec, transition: 2.6 sec, train_data: 15.4 sec, train: 4.9 sec, total: 32.9 sec\n",
      "           Test F1: 1.000\n",
      "[21, 2, 19, 20] #73 ->\n",
      "           [21, 16, 21, 20]\n",
      "           rank: 7.8 sec, transition: 2.6 sec, train_data: 15.4 sec, train: 5.0 sec, total: 33.2 sec\n",
      "           Test F1: 0.500\n",
      "[2, 16, 21, 28] #74 ->\n",
      "           [2, 21, 16, 28]\n",
      "           rank: 7.8 sec, transition: 2.7 sec, train_data: 15.7 sec, train: 4.7 sec, total: 33.2 sec\n",
      "           Test F1: 1.000\n",
      "[16, 8, 12] #75 ->\n",
      "           [16, 28, 12]\n",
      "           rank: 8.1 sec, transition: 2.6 sec, train_data: 16.3 sec, train: 4.8 sec, total: 34.2 sec\n",
      "           Test F1: 0.667\n",
      "[13, 1, 11] #76 ->\n",
      "           [13, 2, 11]\n",
      "           rank: 7.9 sec, transition: 2.7 sec, train_data: 15.3 sec, train: 5.0 sec, total: 33.1 sec\n",
      "           Test F1: 0.667\n",
      "[19, 25, 26] #77 ->\n",
      "           [19, 11, 26]\n",
      "           rank: 7.4 sec, transition: 2.6 sec, train_data: 15.7 sec, train: 5.3 sec, total: 33.3 sec\n",
      "           Test F1: 0.667\n",
      "[8, 21, 16] #78 ->\n",
      "           [10, 21, 16]\n",
      "           rank: 9.0 sec, transition: 2.6 sec, train_data: 15.7 sec, train: 5.2 sec, total: 34.7 sec\n",
      "           Test F1: 1.000\n",
      "[15, 21, 12] #79 ->\n",
      "           [15, 28, 12]\n",
      "           rank: 7.7 sec, transition: 2.6 sec, train_data: 16.6 sec, train: 4.8 sec, total: 34.0 sec\n",
      "           Test F1: 0.667\n",
      "[20, 16, 2] #80 ->\n",
      "           [20, 16, 2]\n",
      "           rank: 8.5 sec, transition: 2.6 sec, train_data: 16.6 sec, train: 5.2 sec, total: 35.2 sec\n",
      "           Test F1: 1.000\n",
      "[20, 2, 16] #81 ->\n",
      "           [20, 21, 16]\n",
      "           rank: 7.7 sec, transition: 2.6 sec, train_data: 15.9 sec, train: 5.3 sec, total: 33.9 sec\n",
      "           Test F1: 0.667\n",
      "[21, 16, 20, 11] #82 ->\n",
      "           [21, 16, 13, 11]\n",
      "           rank: 8.3 sec, transition: 2.6 sec, train_data: 16.6 sec, train: 5.3 sec, total: 35.1 sec\n",
      "           Test F1: 0.750\n",
      "[11, 20, 10] #83 ->\n",
      "           [11, 13, 10]\n",
      "           rank: 7.8 sec, transition: 2.6 sec, train_data: 15.8 sec, train: 5.0 sec, total: 33.5 sec\n",
      "           Test F1: 0.667\n",
      "[1, 16, 13] #84 ->\n",
      "           [1, 2, 13]\n",
      "           rank: 7.4 sec, transition: 2.6 sec, train_data: 15.6 sec, train: 5.1 sec, total: 33.1 sec\n",
      "           Test F1: 0.667\n",
      "[1, 16, 20] #85 ->\n",
      "           [1, 21, 20]\n",
      "           rank: 7.4 sec, transition: 2.6 sec, train_data: 15.3 sec, train: 5.0 sec, total: 32.6 sec\n",
      "           Test F1: 0.667\n",
      "[20, 2, 21, 16] #86 ->\n",
      "           [20, 16, 21, 16]\n",
      "           rank: 8.1 sec, transition: 2.6 sec, train_data: 15.7 sec, train: 5.3 sec, total: 34.0 sec\n",
      "           Test F1: 0.750\n",
      "[21, 16, 12, 20, 2] #87 ->\n",
      "           [21, 16, 21, 16, 2]\n",
      "           rank: 7.7 sec, transition: 2.6 sec, train_data: 16.0 sec, train: 5.1 sec, total: 33.7 sec\n",
      "           Test F1: 0.600\n",
      "[1, 16, 11] #88 ->\n",
      "           [1, 1, 11]\n",
      "           rank: 7.7 sec, transition: 2.6 sec, train_data: 15.7 sec, train: 5.0 sec, total: 33.3 sec\n",
      "           Test F1: 0.667\n",
      "[1, 21, 2] #89 ->\n",
      "           [1, 16, 2]\n",
      "           rank: 7.6 sec, transition: 2.6 sec, train_data: 15.4 sec, train: 5.3 sec, total: 33.2 sec\n",
      "           Test F1: 0.667\n",
      "[26, 10, 20] #90 ->\n",
      "           [26, 19, 20]\n",
      "           rank: 8.2 sec, transition: 2.6 sec, train_data: 15.4 sec, train: 4.7 sec, total: 33.3 sec\n",
      "           Test F1: 0.667\n",
      "[13, 2, 28] #91 ->\n",
      "           [13, 20, 28]\n",
      "           rank: 7.9 sec, transition: 2.6 sec, train_data: 15.6 sec, train: 5.2 sec, total: 33.7 sec\n",
      "           Test F1: 0.667\n",
      "[2, 21, 13] #92 ->\n",
      "           [2, 10, 13]\n",
      "           rank: 7.5 sec, transition: 2.6 sec, train_data: 16.7 sec, train: 5.2 sec, total: 34.4 sec\n",
      "           Test F1: 0.667\n",
      "[21, 16, 2] #93 ->\n",
      "           [21, 16, 2]\n",
      "           rank: 8.2 sec, transition: 2.6 sec, train_data: 15.4 sec, train: 5.3 sec, total: 33.8 sec\n",
      "           Test F1: 1.000\n",
      "[16, 21, 20] #94 ->\n",
      "           [16, 21, 20]\n",
      "           rank: 7.5 sec, transition: 2.6 sec, train_data: 15.3 sec, train: 5.0 sec, total: 32.8 sec\n",
      "           Test F1: 1.000\n",
      "[16, 21, 20] #95 ->\n",
      "           [16, 21, 20]\n",
      "           rank: 8.3 sec, transition: 2.6 sec, train_data: 15.3 sec, train: 5.0 sec, total: 33.5 sec\n",
      "           Test F1: 1.000\n",
      "[2, 16, 1, 21] #96 ->\n",
      "           [2, 13, 2, 21]\n",
      "           rank: 7.5 sec, transition: 2.6 sec, train_data: 15.7 sec, train: 5.1 sec, total: 33.2 sec\n",
      "           Test F1: 0.500\n",
      "[10, 12, 2] #97 ->\n",
      "           [10, 15, 2]\n",
      "           rank: 8.1 sec, transition: 2.6 sec, train_data: 16.6 sec, train: 5.1 sec, total: 34.8 sec\n",
      "           Test F1: 0.667\n",
      "[10, 9, 26, 15] #98 ->\n",
      "           [10, 15, 10, 15]\n",
      "           rank: 8.0 sec, transition: 2.6 sec, train_data: 16.0 sec, train: 5.1 sec, total: 34.0 sec\n",
      "           Test F1: 0.500\n",
      "[2, 10, 13] #99 ->\n",
      "           [2, 16, 13]\n",
      "           rank: 8.1 sec, transition: 2.6 sec, train_data: 15.9 sec, train: 4.7 sec, total: 33.7 sec\n",
      "           Test F1: 0.667\n",
      "[2, 16, 21] #100 ->\n",
      "           [2, 16, 21]\n",
      "           rank: 8.1 sec, transition: 2.6 sec, train_data: 16.7 sec, train: 4.9 sec, total: 34.7 sec\n",
      "           Test F1: 1.000\n",
      "[26, 9, 10, 1, 2] #101 ->\n",
      "           [26, 10, 9, 26, 2]\n",
      "           rank: 7.8 sec, transition: 2.6 sec, train_data: 16.6 sec, train: 5.2 sec, total: 34.6 sec\n",
      "           Test F1: 0.800\n",
      "[21, 16, 27, 11, 13, 2] #102 ->\n",
      "           [21, 16, 21, 16, 21, 2]\n",
      "           rank: 8.1 sec, transition: 2.6 sec, train_data: 15.2 sec, train: 4.4 sec, total: 32.6 sec\n",
      "           Test F1: 0.500\n",
      "[16, 20, 29, 1] #103 ->\n",
      "           [16, 21, 16, 1]\n",
      "           rank: 7.4 sec, transition: 2.6 sec, train_data: 16.3 sec, train: 5.2 sec, total: 33.9 sec\n",
      "           Test F1: 0.500\n",
      "[15, 10, 9] #104 ->\n",
      "           [15, 10, 9]\n",
      "           rank: 7.6 sec, transition: 2.6 sec, train_data: 15.7 sec, train: 5.2 sec, total: 33.5 sec\n",
      "           Test F1: 1.000\n",
      "[16, 21, 2] #105 ->\n",
      "           [16, 21, 2]\n",
      "           rank: 7.9 sec, transition: 2.6 sec, train_data: 15.9 sec, train: 5.0 sec, total: 33.7 sec\n",
      "           Test F1: 1.000\n",
      "[27, 17, 26] #106 ->\n",
      "           [27, 25, 26]\n",
      "           rank: 7.5 sec, transition: 2.6 sec, train_data: 15.7 sec, train: 5.1 sec, total: 33.2 sec\n",
      "           Test F1: 0.667\n",
      "[2, 21, 1, 13] #107 ->\n",
      "           [2, 16, 14, 13]\n",
      "           rank: 7.8 sec, transition: 2.7 sec, train_data: 16.8 sec, train: 5.3 sec, total: 35.2 sec\n",
      "           Test F1: 0.500\n",
      "[16, 21, 1] #108 ->\n",
      "           [16, 21, 1]\n",
      "           rank: 8.2 sec, transition: 2.7 sec, train_data: 16.8 sec, train: 5.2 sec, total: 35.2 sec\n",
      "           Test F1: 1.000\n",
      "[26, 11, 28] #109 ->\n",
      "           [26, 11, 28]\n",
      "           rank: 8.2 sec, transition: 2.6 sec, train_data: 16.4 sec, train: 5.3 sec, total: 34.8 sec\n",
      "           Test F1: 1.000\n",
      "[13, 2, 21] #110 ->\n",
      "           [13, 2, 21]\n",
      "           rank: 8.0 sec, transition: 2.6 sec, train_data: 15.9 sec, train: 5.6 sec, total: 34.5 sec\n",
      "           Test F1: 1.000\n"
     ]
    }
   ],
   "source": [
    "if run_crf == True:\n",
    "    recdict_crf = dict()\n",
    "    cost = 10\n",
    "    n_jobs = 4\n",
    "    cnt = 1\n",
    "    for i in range(len(trajid_set_all)):\n",
    "        t0 = time.time()\n",
    "        tid_ = trajid_set_all[i]\n",
    "        te = traj_dict[tid_]\n",
    "        \n",
    "        # trajectory too short\n",
    "        if len(te) < 3: continue\n",
    "            \n",
    "        trajid_list_train = trajid_set_all[:i] + trajid_set_all[i+1:]\n",
    "        poi_info = calc_poi_info(trajid_list_train, traj_all, poi_all)\n",
    "        \n",
    "        assert(len(te) <= poi_info.shape[0])\n",
    "            \n",
    "        # build POI_ID <--> POI__INDEX mapping for POIs used to train CRF\n",
    "        # which means only POIs in traj such that len(traj) >= 3 are included\n",
    "        poi_set = set()\n",
    "        for x in trajid_list_train:\n",
    "            if len(traj_dict[x]) >= 3:\n",
    "                poi_set = poi_set | set(traj_dict[x])                \n",
    "        poi_ix = sorted(poi_set)\n",
    "        poi_id_dict, poi_id_rdict = dict(), dict()\n",
    "        for idx, poi in enumerate(poi_ix):\n",
    "            poi_id_dict[poi] = idx\n",
    "            poi_id_rdict[idx] = poi\n",
    "            \n",
    "        # start/end is not in training set\n",
    "        if not (te[0] in poi_set and te[-1] in poi_set): continue\n",
    "            \n",
    "        print(te, '#%d ->' % cnt); cnt += 1; sys.stdout.flush()\n",
    "        \n",
    "        t1 = time.time()\n",
    "        \n",
    "        # POI feature based ranking\n",
    "        train_df = gen_train_df(trajid_list_train, traj_dict, poi_info, POI_CLUSTERS, n_jobs)\n",
    "        ranksvm = RankSVM(ranksvm_dir, useLinear=True)\n",
    "        ranksvm.train(train_df, cost=cost)\n",
    "        \n",
    "        t2 = time.time()\n",
    "               \n",
    "        poi_transmat = gen_poi_transmat(trajid_list_train, set(poi_ix), traj_dict, poi_info) \n",
    "        assert(poi_transmat.shape[0] == poi_transmat.shape[1] == len(poi_ix))\n",
    "        transmat_mapped = np.zeros_like(poi_transmat)\n",
    "        for ix in range(len(poi_ix)):  # reorder the transition probabilites according to the order of mapped POIs\n",
    "            pi = poi_ix[ix]\n",
    "            for jx in range(len(poi_ix)):\n",
    "                pj = poi_ix[jx]\n",
    "                transmat_mapped[ix, jx] = poi_transmat.loc[pi, pj]\n",
    "        \n",
    "        t3 = time.time()\n",
    "            \n",
    "        # generate training data\n",
    "        X_train = []\n",
    "        y_train = []\n",
    "        train_traj_list = [traj_dict[x] for x in trajid_list_train if len(traj_dict[x]) > 2]\n",
    "        train_df_list = Parallel(n_jobs=n_jobs)(delayed(gen_test_df)(tr[0], tr[-1], len(tr), poi_info, POI_CLUSTERS) \\\n",
    "                                                for tr in train_traj_list)\n",
    "        rank_df_list = [ranksvm.predict(tr_df) for tr_df in train_df_list]\n",
    "        assert(len(train_traj_list) == len(rank_df_list))\n",
    "        X_train = Parallel(n_jobs=n_jobs)\\\n",
    "                          (delayed(gen_features)\\\n",
    "                           (train_traj_list[x][0], train_traj_list[x][-1], len(train_traj_list[x]), rank_df_list[x], \\\n",
    "                            transmat_mapped, poi_ix, poi_id_dict) for x in range(len(rank_df_list)))\n",
    "        y_train = [np.array([poi_id_dict[x] for x in tr]) for tr in train_traj_list]\n",
    "        assert(len(train_traj_list) == len(X_train) == len(y_train))\n",
    "        #for ix in range(len(X_train)):\n",
    "        #    print('edge features of', train_traj_list[ix])\n",
    "        #    print(X_train[ix][2])\n",
    "        \n",
    "        #for j in range(len(train_set)):\n",
    "        #    tr = traj_dict[train_set[j]]\n",
    "        #    assert(len(tr) >= 3)\n",
    "        #    tr_df = train_df_list[j]\n",
    "        #    tr_rank_df = ranksvm.predict(tr_df)\n",
    "        #    X_train.append(gen_features(tr[0], tr[-1], len(tr), tr_rank_df, transmat_mapped, poi_ix, poi_id_dict))\n",
    "        #    y_train.append(np.array([poi_id_dict[x] for x in tr]))\n",
    "        \n",
    "        t4 = time.time()        \n",
    "                \n",
    "        # train\n",
    "        crf = EdgeFeatureGraphCRF(inference_method='max-product')  # use belief propagation as it is essentially a chain\n",
    "        #ssvm = OneSlackSSVM(model=crf, C=C, max_iter=maxIter, n_jobs=4) # default: C=1, max_iter=10000, n_jobs=1\n",
    "        ssvm = OneSlackSSVM(model=crf, C=C) # optimized BLAS libraries, e.g. OpenBLAS/MKL will use all available threads \n",
    "        ssvm.fit(X_train, y_train)\n",
    "        \n",
    "        t5 = time.time()\n",
    "        \n",
    "        # generate test data\n",
    "        X_test = []\n",
    "        te_df = gen_test_df(te[0], te[-1], len(te), poi_info, poi_clusters=POI_CLUSTERS)\n",
    "        te_rank_df = ranksvm.predict(te_df)\n",
    "        #te_rank_df.set_index('poiID', inplace=True)\n",
    "        X_test.append(gen_features(te[0], te[-1], len(te), te_rank_df, transmat_mapped, \\\n",
    "                                   poi_ix, poi_id_dict))\n",
    "        \n",
    "        # test\n",
    "        y_pred = ssvm.predict(X_test)\n",
    "        rec = [poi_id_rdict[x] for x in y_pred[0]] # map POIs back\n",
    "        rec1 = [te[0]] + rec[1:-1] + [te[-1]]\n",
    "        F1_test.append(calc_F1(te, rec1))\n",
    "        \n",
    "        # test on training set\n",
    "        #y_pred_train = ssvm.predict(X_train)\n",
    "        #F1_train = []\n",
    "        #assert(len(train_set) == len(y_pred_train))\n",
    "        #for j in range(len(train_set)):\n",
    "        #    tr = traj_dict[train_set[j]]\n",
    "        #    F1_train.append(calc_F1(tr, [tr[0]] + [poi_id_rdict[x] for x in y_pred_train[j][1:-1]] + [tr[-1]]))\n",
    "        #F1_train_list.append(F1_train)\n",
    "        \n",
    "        recdict_crf[tid_] = {'REAL':te, 'REC_CRF':rec1} \n",
    "        \n",
    "        t6 = time.time()\n",
    "        \n",
    "        print(' '*10, rec)\n",
    "        print(' '*10, 'rank: %.1f sec, transition: %.1f sec, train_data: %.1f sec, train: %.1f sec, total: %.1f sec' % \\\n",
    "              (t2 - t1, t3 - t2, t4 - t3, t5 - t4, t6 - t0))\n",
    "        #print(' '*10, 'Train F1: %.3f %.3f, Test F1: %.3f' % (np.mean(F1_train), np.std(F1_train), F1_test[-1]))\n",
    "        print(' '*10, 'Test F1: %.3f' % F1_test[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: 0.725, 0.174\n"
     ]
    }
   ],
   "source": [
    "print('Test: %.3f, %.3f' % (np.mean(F1_test), np.std(F1_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/data-cikm16/crf2-noloop-all-agnostic-C1-Glas.pkl\n"
     ]
    }
   ],
   "source": [
    "if run_crf == True:\n",
    "    print(frecdict_crf)\n",
    "    pickle.dump(recdict_crf, open(frecdict_crf, 'bw'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print('Train: %.3f, %.3f' % (np.mean([x for y in F1_train_list for x in y]), \\\n",
    "#                             np.std([x for y in F1_train_list for x in y])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 1.0, Glas\n"
     ]
    }
   ],
   "source": [
    "print('C = %.1f,' % C, dat_suffix[dat_ix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "F1 = [calc_F1(recdict_crf[key]['REAL'], recdict_crf[key]['REC_CRF'], noloop=True) for key in sorted(recdict_crf.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.725086580087 0.173858048517\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(F1), np.std(F1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
