{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse Experimental Results & Generate Latex Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, pickle\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = 'data/data-recsys16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "suffix = ['Osak', 'Glas', 'Edin', 'Toro', 'Melb']\n",
    "datnames = ['Osaka', 'Glasgow', 'Edinburgh', 'Toronto', 'Melbourne']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datasettypes = ['all', 'noshort', 'perfect']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dstype = datasettypes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "KX = 100  # 100 folds in user specific setting\n",
    "kxstr = str(KX) + 'X-'\n",
    "ALPHA = 0.5\n",
    "alphastr = str(ALPHA).replace('.', '_') + '-'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the F1 score for recommended trajectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_F1(seq_act, seq_rec):\n",
    "    '''Compute recall, precision and F1 when trajectories contain sub-tours'''\n",
    "    assert(len(seq_act) > 0)\n",
    "    assert(len(seq_rec) > 0)\n",
    "    match_tags = np.zeros(len(seq_act), dtype=np.bool)\n",
    "    for poi in seq_rec:\n",
    "        for j in range(len(seq_act)):\n",
    "            if match_tags[j] == False and poi == seq_act[j]:\n",
    "                match_tags[j] = True\n",
    "                break\n",
    "    intersize = np.nonzero(match_tags)[0].shape[0]\n",
    "    recall = intersize / len(seq_act)\n",
    "    precision = intersize / len(seq_rec)\n",
    "    F1 = 2 * precision * recall / (precision + recall)\n",
    "    return F1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load results data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_results(datnames, suffix, dat_ix, dstype, kxstr, alphastr):\n",
    "    assert(0 <= dat_ix <= len(suffix))\n",
    "    assert(len(datnames) == len(suffix))\n",
    "    # user specific results\n",
    "    frecdict_rank_spec = os.path.join(data_dir, 'rank-' + dstype + '-specific-' + kxstr + suffix[dat_ix] + '.pkl')\n",
    "    frecdict_tran_spec = os.path.join(data_dir, 'tran-' + dstype + '-specific-' + kxstr + suffix[dat_ix] + '.pkl')\n",
    "    frecdict_comb_spec = os.path.join(data_dir, 'comb-' + dstype + '-specific-' +alphastr+kxstr + suffix[dat_ix]+'.pkl')\n",
    "\n",
    "    # user agnostic results\n",
    "    frecdict_rank_agno = os.path.join(data_dir, 'rank-' + dstype + '-agnostic-' + suffix[dat_ix] + '.pkl')\n",
    "    frecdict_tran_agno = os.path.join(data_dir, 'tran-' + dstype + '-agnostic-' + suffix[dat_ix] + '.pkl')\n",
    "    frecdict_comb_agno = os.path.join(data_dir, 'comb-' + dstype + '-agnostic-' + alphastr + suffix[dat_ix] + '.pkl')\n",
    "    \n",
    "    # load results data\n",
    "    recdict_rank_spec = pickle.load(open(frecdict_rank_spec, 'rb'))\n",
    "    recdict_rank_agno = pickle.load(open(frecdict_rank_agno, 'rb'))\n",
    "    recdict_tran_spec = pickle.load(open(frecdict_tran_spec, 'rb'))\n",
    "    recdict_tran_agno = pickle.load(open(frecdict_tran_agno, 'rb'))\n",
    "    recdict_comb_spec = pickle.load(open(frecdict_comb_spec, 'rb'))\n",
    "    recdict_comb_agno = pickle.load(open(frecdict_comb_agno, 'rb'))\n",
    "    \n",
    "    # compute F1\n",
    "    F1_rank1_spec = []  # rank pop\n",
    "    F1_rank1_agno = []  # rank pop\n",
    "    F1_rank2_spec = []  # rank feature\n",
    "    F1_rank2_agno = []  # rank feature\n",
    "    for key in sorted(recdict_rank_spec.keys()):\n",
    "        F1_rank1_spec.append(calc_F1(recdict_rank_spec[key]['REAL'], recdict_rank_spec[key]['REC_POP']))\n",
    "        F1_rank2_spec.append(calc_F1(recdict_rank_spec[key]['REAL'], recdict_rank_spec[key]['REC_FEATURE']))\n",
    "    for key in sorted(recdict_rank_agno.keys()):\n",
    "        F1_rank1_agno.append(calc_F1(recdict_rank_agno[key]['REAL'], recdict_rank_agno[key]['REC_POP']))\n",
    "        F1_rank2_agno.append(calc_F1(recdict_rank_agno[key]['REAL'], recdict_rank_agno[key]['REC_FEATURE']))\n",
    "        \n",
    "    F1_tran1_spec = []  # transition DP\n",
    "    F1_tran1_agno = []  # transition DP\n",
    "    F1_tran2_spec = []  # transition ILP\n",
    "    F1_tran2_agno = []  # transition ILP\n",
    "    for key in sorted(recdict_tran_spec.keys()):\n",
    "        F1_tran1_spec.append(calc_F1(recdict_tran_spec[key]['REAL'], recdict_tran_spec[key]['REC_DP']))\n",
    "        F1_tran2_spec.append(calc_F1(recdict_tran_spec[key]['REAL'], recdict_tran_spec[key]['REC_ILP']))\n",
    "    for key in sorted(recdict_tran_agno.keys()):\n",
    "        F1_tran1_agno.append(calc_F1(recdict_tran_agno[key]['REAL'], recdict_tran_agno[key]['REC_DP']))\n",
    "        F1_tran2_agno.append(calc_F1(recdict_tran_agno[key]['REAL'], recdict_tran_agno[key]['REC_ILP']))\n",
    "\n",
    "    F1_comb1_spec = []  # combine rank and transition DP\n",
    "    F1_comb1_agno = []  # combine rank and transition DP\n",
    "    F1_comb2_spec = []  # combine rank and transition ILP\n",
    "    F1_comb2_agno = []  # combine rank and transition ILP\n",
    "    for key in sorted(recdict_comb_spec.keys()):\n",
    "        F1_comb1_spec.append(calc_F1(recdict_comb_spec[key]['REAL'], recdict_comb_spec[key]['REC_DP']))\n",
    "        F1_comb2_spec.append(calc_F1(recdict_comb_spec[key]['REAL'], recdict_comb_spec[key]['REC_ILP']))\n",
    "    for key in sorted(recdict_comb_agno.keys()):\n",
    "        F1_comb1_agno.append(calc_F1(recdict_comb_agno[key]['REAL'], recdict_comb_agno[key]['REC_DP']))\n",
    "        F1_comb2_agno.append(calc_F1(recdict_comb_agno[key]['REAL'], recdict_comb_agno[key]['REC_ILP']))\n",
    "    \n",
    "    # compute mean and std of F1\n",
    "    F1dat_agno = [F1_rank1_agno, F1_rank2_agno, F1_tran1_agno, F1_tran2_agno, F1_comb1_agno, F1_comb2_agno]\n",
    "    F1dat_spec = [F1_rank1_spec, F1_rank2_spec, F1_tran1_spec, F1_tran2_spec, F1_comb1_spec, F1_comb2_spec]\n",
    "    F1mean_agno = [np.mean(x) for x in F1dat_agno]\n",
    "    F1mean_spec = [np.mean(x) for x in F1dat_spec]\n",
    "    F1std_agno  = [np.std(x) for x in F1dat_agno]\n",
    "    F1std_spec  = [np.std(x) for x in F1dat_spec]\n",
    "    \n",
    "    return F1mean_agno, F1std_agno, F1mean_spec, F1std_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "methods = ['RankP', 'RankF', 'MC-DP', 'MC-ILP', 'Prop-DP', 'Prop-ILP']\n",
    "F1mean_agno_df = pd.DataFrame(data=np.zeros((len(methods), len(datnames)), dtype=np.float), \\\n",
    "                              columns=datnames, index=methods)\n",
    "F1std_agno_df  = pd.DataFrame(data=np.zeros((len(methods), len(datnames)), dtype=np.float), \\\n",
    "                              columns=datnames, index=methods)\n",
    "F1mean_spec_df = pd.DataFrame(data=np.zeros((len(methods), len(datnames)), dtype=np.float), \\\n",
    "                              columns=datnames, index=methods)\n",
    "F1std_spec_df  = pd.DataFrame(data=np.zeros((len(methods), len(datnames)), dtype=np.float), \\\n",
    "                              columns=datnames, index=methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for dat_ix in range(len(suffix)):\n",
    "    F1mean_agno, F1std_agno, F1mean_spec, F1std_spec = load_results(datnames, suffix, dat_ix, dstype, kxstr, alphastr)\n",
    "    assert(len(F1mean_agno) == len(F1std_agno) == len(methods))\n",
    "    assert(len(F1mean_spec) == len(F1std_spec) == len(methods))\n",
    "    F1mean_agno_df[datnames[dat_ix]] = F1mean_agno\n",
    "    F1mean_spec_df[datnames[dat_ix]] = F1mean_spec\n",
    "    F1std_agno_df[datnames[dat_ix]] = F1std_agno\n",
    "    F1std_spec_df[datnames[dat_ix]] = F1std_spec    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Osaka</th>\n",
       "      <th>Glasgow</th>\n",
       "      <th>Edinburgh</th>\n",
       "      <th>Toronto</th>\n",
       "      <th>Melbourne</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RankP</th>\n",
       "      <td>0.629865</td>\n",
       "      <td>0.704722</td>\n",
       "      <td>0.641277</td>\n",
       "      <td>0.652807</td>\n",
       "      <td>0.569735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RankF</th>\n",
       "      <td>0.639312</td>\n",
       "      <td>0.748766</td>\n",
       "      <td>0.644364</td>\n",
       "      <td>0.712965</td>\n",
       "      <td>0.572559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MC-DP</th>\n",
       "      <td>0.689855</td>\n",
       "      <td>0.717810</td>\n",
       "      <td>0.563657</td>\n",
       "      <td>0.687220</td>\n",
       "      <td>0.524709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MC-ILP</th>\n",
       "      <td>0.651475</td>\n",
       "      <td>0.715778</td>\n",
       "      <td>0.594995</td>\n",
       "      <td>0.686599</td>\n",
       "      <td>0.547168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prop-DP</th>\n",
       "      <td>0.716848</td>\n",
       "      <td>0.734321</td>\n",
       "      <td>0.615323</td>\n",
       "      <td>0.681341</td>\n",
       "      <td>0.547798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prop-ILP</th>\n",
       "      <td>0.691175</td>\n",
       "      <td>0.736266</td>\n",
       "      <td>0.625476</td>\n",
       "      <td>0.702569</td>\n",
       "      <td>0.575671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Osaka   Glasgow  Edinburgh   Toronto  Melbourne\n",
       "RankP     0.629865  0.704722   0.641277  0.652807   0.569735\n",
       "RankF     0.639312  0.748766   0.644364  0.712965   0.572559\n",
       "MC-DP     0.689855  0.717810   0.563657  0.687220   0.524709\n",
       "MC-ILP    0.651475  0.715778   0.594995  0.686599   0.547168\n",
       "Prop-DP   0.716848  0.734321   0.615323  0.681341   0.547798\n",
       "Prop-ILP  0.691175  0.736266   0.625476  0.702569   0.575671"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F1mean_agno_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#F1std_agno_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Osaka</th>\n",
       "      <th>Glasgow</th>\n",
       "      <th>Edinburgh</th>\n",
       "      <th>Toronto</th>\n",
       "      <th>Melbourne</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RankP</th>\n",
       "      <td>0.629865</td>\n",
       "      <td>0.704722</td>\n",
       "      <td>0.641277</td>\n",
       "      <td>0.652807</td>\n",
       "      <td>0.569735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RankF</th>\n",
       "      <td>0.647981</td>\n",
       "      <td>0.742099</td>\n",
       "      <td>0.643294</td>\n",
       "      <td>0.715186</td>\n",
       "      <td>0.570049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MC-DP</th>\n",
       "      <td>0.673551</td>\n",
       "      <td>0.707310</td>\n",
       "      <td>0.574936</td>\n",
       "      <td>0.685142</td>\n",
       "      <td>0.535321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MC-ILP</th>\n",
       "      <td>0.629736</td>\n",
       "      <td>0.712278</td>\n",
       "      <td>0.602385</td>\n",
       "      <td>0.689600</td>\n",
       "      <td>0.554588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prop-DP</th>\n",
       "      <td>0.713949</td>\n",
       "      <td>0.728488</td>\n",
       "      <td>0.616486</td>\n",
       "      <td>0.693217</td>\n",
       "      <td>0.560325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prop-ILP</th>\n",
       "      <td>0.681211</td>\n",
       "      <td>0.735433</td>\n",
       "      <td>0.625471</td>\n",
       "      <td>0.705316</td>\n",
       "      <td>0.575341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Osaka   Glasgow  Edinburgh   Toronto  Melbourne\n",
       "RankP     0.629865  0.704722   0.641277  0.652807   0.569735\n",
       "RankF     0.647981  0.742099   0.643294  0.715186   0.570049\n",
       "MC-DP     0.673551  0.707310   0.574936  0.685142   0.535321\n",
       "MC-ILP    0.629736  0.712278   0.602385  0.689600   0.554588\n",
       "Prop-DP   0.713949  0.728488   0.616486  0.693217   0.560325\n",
       "Prop-ILP  0.681211  0.735433   0.625471  0.705316   0.575341"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F1mean_spec_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#F1std_spec_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ismax_agno_df = pd.DataFrame(data=np.zeros(F1mean_agno_df.shape, dtype=np.bool), \\\n",
    "                             columns=F1mean_agno_df.columns, index=F1mean_agno_df.index)\n",
    "ismax_spec_df = pd.DataFrame(data=np.zeros(F1mean_spec_df.shape, dtype=np.bool), \\\n",
    "                             columns=F1mean_spec_df.columns, index=F1mean_spec_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in ismax_agno_df.columns:\n",
    "    maxix = F1mean_agno_df[col].argmax()\n",
    "    ismax_agno_df.loc[maxix, col] = True\n",
    "for col in ismax_spec_df.columns:\n",
    "    maxix = F1mean_spec_df[col].argmax()\n",
    "    ismax_spec_df.loc[maxix, col] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ismax_agno_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ismax_spec_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_latex_table(F1mean_df, F1std_df, ismax_df, uspecific, dstype):\n",
    "    assert(isinstance(uspecific, bool))\n",
    "    ustr = 'user specific setting' if uspecific else 'user agnostic setting'\n",
    "    if dstype == 'all': dstr = 'with all trajectories'\n",
    "    if dstype == 'noshort': dstr = 'without short trajectories'\n",
    "    if dstype == 'perfect': dstr = 'without trajectories that are short or with sub-tours'\n",
    "\n",
    "    strs = []\n",
    "    strs.append('\\\\begin{table*}\\n')\n",
    "    strs.append('\\\\centering\\n')\n",
    "    strs.append('\\\\caption{Experimental Results: ' + ustr + ' ' + dstr + '}\\n')\n",
    "    #strs.append('\\\\small\\n')\n",
    "    strs.append('\\\\begin{tabular}{l|' + (F1mean_df.shape[1])*'c' + '} \\\\hline\\n')\n",
    "    for col in F1mean_df.columns:\n",
    "        strs.append(' & ' + col)\n",
    "    strs.append(' \\\\\\\\ \\\\hline\\n')\n",
    "    for ix in F1mean_df.index:\n",
    "        for j in range(F1mean_df.shape[1]):\n",
    "            if j == 0: strs.append(ix + ' ')\n",
    "            jx = F1mean_df.columns[j]\n",
    "            strs.append('& $')\n",
    "            if ismax_df.loc[ix, jx] == True: strs.append('\\\\mathbf{')\n",
    "            strs.append('%.3f' % F1mean_df.loc[ix, jx] + '\\\\pm' + '%.3f' % F1std_df.loc[ix, jx])\n",
    "            if ismax_df.loc[ix, jx] == True: strs.append('}')\n",
    "            strs.append('$ ')\n",
    "        strs.append('\\\\\\\\\\n')\n",
    "    strs.append('\\\\hline\\n')\n",
    "    strs.append('\\\\end{tabular}\\n')\n",
    "    strs.append('\\\\end{table*}\\n')\n",
    "    return ''.join(strs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "str1 = gen_latex_table(F1mean_agno_df, F1std_agno_df, ismax_agno_df, uspecific=False, dstype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table*}\n",
      "\\centering\n",
      "\\caption{Experimental Results: user agnostic setting without short trajectories}\n",
      "\\begin{tabular}{l|ccccc} \\hline\n",
      " & Osaka & Glasgow & Edinburgh & Toronto & Melbourne \\\\ \\hline\n",
      "RankP & $0.630\\pm0.175$ & $0.705\\pm0.171$ & $0.641\\pm0.163$ & $0.653\\pm0.145$ & $0.570\\pm0.141$ \\\\\n",
      "RankF & $0.639\\pm0.182$ & $\\mathbf{0.749\\pm0.174}$ & $\\mathbf{0.644\\pm0.162}$ & $\\mathbf{0.713\\pm0.178}$ & $0.573\\pm0.138$ \\\\\n",
      "MC-DP & $0.690\\pm0.205$ & $0.718\\pm0.188$ & $0.564\\pm0.191$ & $0.687\\pm0.185$ & $0.525\\pm0.173$ \\\\\n",
      "MC-ILP & $0.651\\pm0.194$ & $0.716\\pm0.186$ & $0.595\\pm0.157$ & $0.687\\pm0.167$ & $0.547\\pm0.150$ \\\\\n",
      "Prop-DP & $\\mathbf{0.717\\pm0.215}$ & $0.734\\pm0.183$ & $0.615\\pm0.196$ & $0.681\\pm0.197$ & $0.548\\pm0.175$ \\\\\n",
      "Prop-ILP & $0.691\\pm0.196$ & $0.736\\pm0.175$ & $0.625\\pm0.161$ & $0.703\\pm0.166$ & $\\mathbf{0.576\\pm0.157}$ \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "\\end{table*}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(str1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "str2 = gen_latex_table(F1mean_spec_df, F1std_spec_df, ismax_spec_df, uspecific=True, dstype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table*}\n",
      "\\centering\n",
      "\\caption{Experimental Results: user specific setting without short trajectories}\n",
      "\\begin{tabular}{l|ccccc} \\hline\n",
      " & Osaka & Glasgow & Edinburgh & Toronto & Melbourne \\\\ \\hline\n",
      "RankP & $0.630\\pm0.175$ & $0.705\\pm0.171$ & $0.641\\pm0.163$ & $0.653\\pm0.145$ & $0.570\\pm0.141$ \\\\\n",
      "RankF & $0.648\\pm0.202$ & $\\mathbf{0.742\\pm0.171}$ & $\\mathbf{0.643\\pm0.162}$ & $\\mathbf{0.715\\pm0.178}$ & $0.570\\pm0.137$ \\\\\n",
      "MC-DP & $0.674\\pm0.179$ & $0.707\\pm0.179$ & $0.575\\pm0.196$ & $0.685\\pm0.181$ & $0.535\\pm0.170$ \\\\\n",
      "MC-ILP & $0.630\\pm0.171$ & $0.712\\pm0.173$ & $0.602\\pm0.164$ & $0.690\\pm0.164$ & $0.555\\pm0.152$ \\\\\n",
      "Prop-DP & $\\mathbf{0.714\\pm0.207}$ & $0.728\\pm0.179$ & $0.616\\pm0.196$ & $0.693\\pm0.186$ & $0.560\\pm0.174$ \\\\\n",
      "Prop-ILP & $0.681\\pm0.194$ & $0.735\\pm0.172$ & $0.625\\pm0.162$ & $0.705\\pm0.169$ & $\\mathbf{0.575\\pm0.160}$ \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "\\end{table*}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(str2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Latex table for dataset statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\centering\n",
      "\\caption{Dataset with all trajectories}\n",
      "\\label{table:data:all}\n",
      "\\small\n",
      "\\begin{tabular}{lrrrr} \\hline\n",
      "\\textbf{City} & \\textbf{\\#POIs} & \\textbf{\\#Users} & \\textbf{\\#POI Visits} & \\textbf{\\#Trajectories} \\\\ \\hline\n",
      "Osaka & 27 & 450 & 7,747 & 1,115 \\\\ \n",
      "Glasgow & 27 & 601 & 11,434 & 2,227 \\\\ \n",
      "Edinburgh & 28 & 1,454 & 33,944 & 5,028 \\\\ \n",
      "Toronto & 29 & 1,395 & 39,419 & 6,057 \\\\ \n",
      "Melbourne & 85 & 832 & 23,794 & 4,918 \\\\ \n",
      "\\hline\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n",
      "\\begin{table}\n",
      "\\centering\n",
      "\\caption{Dataset without short trajectories}\n",
      "\\label{table:data:noshort}\n",
      "\\small\n",
      "\\begin{tabular}{lrrrr} \\hline\n",
      "\\textbf{City} & \\textbf{\\#POIs} & \\textbf{\\#Users} & \\textbf{\\#POI Visits} & \\textbf{\\#Trajectories} \\\\ \\hline\n",
      "Osaka & 21 & 51 & 1,595 & 64 \\\\ \n",
      "Glasgow & 24 & 102 & 1,862 & 131 \\\\ \n",
      "Edinburgh & 26 & 423 & 13,136 & 710 \\\\ \n",
      "Toronto & 26 & 232 & 7,415 & 417 \\\\ \n",
      "Melbourne & 81 & 248 & 6,510 & 395 \\\\ \n",
      "\\hline\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n",
      "\\begin{table}\n",
      "\\centering\n",
      "\\caption{Dataset without trajectories that are short or with sub-tours}\n",
      "\\label{table:data:perfect}\n",
      "\\small\n",
      "\\begin{tabular}{lrrrr} \\hline\n",
      "\\textbf{City} & \\textbf{\\#POIs} & \\textbf{\\#Users} & \\textbf{\\#POI Visits} & \\textbf{\\#Trajectories} \\\\ \\hline\n",
      "Osaka & 18 & 29 & 801 & 35 \\\\ \n",
      "Glasgow & 23 & 66 & 844 & 75 \\\\ \n",
      "Edinburgh & 26 & 249 & 4,570 & 365 \\\\ \n",
      "Toronto & 26 & 149 & 4,003 & 239 \\\\ \n",
      "Melbourne & 78 & 188 & 3,312 & 266 \\\\ \n",
      "\\hline\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "strs = []\n",
    "for dset in ['all', 'noshort', 'perfect']:\n",
    "    if dset == 'all':     title = 'with all trajectories'\n",
    "    if dset == 'noshort': title = 'without short trajectories'\n",
    "    if dset == 'perfect': title = 'without trajectories that are short or with sub-tours'\n",
    "    strs.append('\\\\begin{table}\\n')\n",
    "    strs.append('\\\\centering\\n')\n",
    "    strs.append('\\\\caption{Dataset ' + title + '}\\n')\n",
    "    strs.append('\\\\label{table:data:' + dset + '}\\n')\n",
    "    strs.append('\\\\small\\n')\n",
    "    strs.append('\\\\begin{tabular}{' + 'l' + 4*'r' + '} \\\\hline\\n')\n",
    "    strs.append('\\\\textbf{City} & \\\\textbf{\\\\#POIs} & \\\\textbf{\\\\#Users} & ')\n",
    "    strs.append('\\\\textbf{\\\\#POI Visits} & \\\\textbf{\\\\#Trajectories} \\\\\\\\ \\\\hline\\n')\n",
    "    \n",
    "    for dat_ix in range(len(datnames)):\n",
    "        if dset == 'all':     ftraj = os.path.join(data_dir, 'traj-all-' + suffix[dat_ix] + '.csv')\n",
    "        if dset == 'noshort': ftraj = os.path.join(data_dir, 'traj-noshort-' + suffix[dat_ix] + '.csv')\n",
    "        if dset == 'perfect': ftraj = os.path.join(data_dir, 'traj-perfect-' + suffix[dat_ix] + '.csv')\n",
    "        traj_all = pd.read_csv(ftraj)\n",
    "        strs.append(datnames[dat_ix])\n",
    "        strs.append(' & ' + '{:,}'.format(traj_all['poiID'].unique().shape[0]))\n",
    "        strs.append(' & ' + '{:,}'.format(traj_all['userID'].unique().shape[0]))\n",
    "        strs.append(' & ' + '{:,}'.format(traj_all['#photo'].sum()))\n",
    "        strs.append(' & ' + '{:,}'.format(traj_all['trajID'].unique().shape[0]))\n",
    "        strs.append(' \\\\\\\\ \\n')\n",
    "    strs.append('\\\\hline\\n')\n",
    "    strs.append('\\\\end{tabular}\\n')\n",
    "    strs.append('\\\\end{table}\\n\\n')\n",
    "print(''.join(strs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discretization parameters for each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "discretization_all_df = pd.DataFrame(data=np.zeros((5, 4), dtype=np.int), \\\n",
    "                                     columns=['Pop', 'Visit', 'Duration', 'Cluster'], \\\n",
    "                                     index=['Osak', 'Glas', 'Edin', 'Toro', 'Melb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "discretization_noshort_df = pd.DataFrame(data=np.zeros((5, 4), dtype=np.int), \\\n",
    "                                         columns=['Pop', 'Visit', 'Duration', 'Cluster'], \\\n",
    "                                         index=['Osak', 'Glas', 'Edin', 'Toro', 'Melb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "discretization_perfect_df = pd.DataFrame(data=np.zeros((5, 4), dtype=np.int), \\\n",
    "                                         columns=['Pop', 'Visit', 'Duration', 'Cluster'], \\\n",
    "                                         index=['Osak', 'Glas', 'Edin', 'Toro', 'Melb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "discretization_all_df.loc['Osak'] = [2, 2, 3, 4]\n",
    "discretization_all_df.loc['Glas'] = [4, 4, 3, 3]\n",
    "discretization_all_df.loc['Edin'] = [4, 3, 3, 3]\n",
    "discretization_all_df.loc['Toro'] = [3, 3, 3, 3]\n",
    "discretization_all_df.loc['Melb'] = [5, 4, 3, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "discretization_noshort_df.loc['Osak'] = [3, 3, 5, 4]\n",
    "discretization_noshort_df.loc['Glas'] = [3, 4, 5, 4]\n",
    "discretization_noshort_df.loc['Edin'] = [4, 4, 3, 3]\n",
    "discretization_noshort_df.loc['Toro'] = [2, 4, 3, 3]\n",
    "discretization_noshort_df.loc['Melb'] = [3, 2, 5, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "discretization_perfect_df.loc['Osak'] = [2, 2, 3, 4]\n",
    "discretization_perfect_df.loc['Glas'] = [2, 2, 3, 4]\n",
    "discretization_perfect_df.loc['Edin'] = [4, 2, 3, 4]\n",
    "discretization_perfect_df.loc['Toro'] = [3, 3, 3, 3]\n",
    "discretization_perfect_df.loc['Melb'] = [5, 5, 4, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\centering\n",
      "\\caption{POI Features Discretization Parameters: Dataset with all trajectories}\n",
      "\\label{table:discretize:all}\n",
      "\\small\n",
      "\\begin{tabular}{lcccc} \\hline\n",
      "\\textbf{City} & \\textbf{Popularity} & \\textbf{\\#Visits} & \\textbf{Duration} & \\textbf{Neighbourhood} \\\\ \\hline\n",
      "Osaka & 2 & 2 & 3 & 4 \\\\ \n",
      "Glasgow & 4 & 4 & 3 & 3 \\\\ \n",
      "Edinburgh & 4 & 3 & 3 & 3 \\\\ \n",
      "Toronto & 3 & 3 & 3 & 3 \\\\ \n",
      "Melbourne & 5 & 4 & 3 & 5 \\\\ \n",
      "\\hline\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n",
      "\\begin{table}\n",
      "\\centering\n",
      "\\caption{POI Features Discretization Parameters: Dataset without short trajectories}\n",
      "\\label{table:discretize:noshort}\n",
      "\\small\n",
      "\\begin{tabular}{lcccc} \\hline\n",
      "\\textbf{City} & \\textbf{Popularity} & \\textbf{\\#Visits} & \\textbf{Duration} & \\textbf{Neighbourhood} \\\\ \\hline\n",
      "Osaka & 3 & 3 & 5 & 4 \\\\ \n",
      "Glasgow & 3 & 4 & 5 & 4 \\\\ \n",
      "Edinburgh & 4 & 4 & 3 & 3 \\\\ \n",
      "Toronto & 2 & 4 & 3 & 3 \\\\ \n",
      "Melbourne & 3 & 2 & 5 & 3 \\\\ \n",
      "\\hline\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n",
      "\\begin{table}\n",
      "\\centering\n",
      "\\caption{POI Features Discretization Parameters: Dataset without trajectories that are short or with sub-tours}\n",
      "\\label{table:discretize:perfect}\n",
      "\\small\n",
      "\\begin{tabular}{lcccc} \\hline\n",
      "\\textbf{City} & \\textbf{Popularity} & \\textbf{\\#Visits} & \\textbf{Duration} & \\textbf{Neighbourhood} \\\\ \\hline\n",
      "Osaka & 2 & 2 & 3 & 4 \\\\ \n",
      "Glasgow & 2 & 2 & 3 & 4 \\\\ \n",
      "Edinburgh & 4 & 2 & 3 & 4 \\\\ \n",
      "Toronto & 3 & 3 & 3 & 3 \\\\ \n",
      "Melbourne & 5 & 5 & 4 & 3 \\\\ \n",
      "\\hline\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "strs = []\n",
    "for dset in ['all', 'noshort', 'perfect']:\n",
    "    if dset == 'all':     title = 'with all trajectories'\n",
    "    if dset == 'noshort': title = 'without short trajectories'\n",
    "    if dset == 'perfect': title = 'without trajectories that are short or with sub-tours'\n",
    "    strs.append('\\\\begin{table}\\n')\n",
    "    strs.append('\\\\centering\\n')\n",
    "    strs.append('\\\\caption{POI Features Discretization Parameters: Dataset ' + title + '}\\n')\n",
    "    strs.append('\\\\label{table:discretize:' + dset + '}\\n')\n",
    "    strs.append('\\\\scriptsize\\n')\n",
    "    strs.append('\\\\begin{tabular}{' + 'l' + 4*'c' + '} \\\\hline\\n')\n",
    "    strs.append('\\\\textbf{City} & \\\\textbf{Popularity} & \\\\textbf{\\\\#Visits} & ')\n",
    "    strs.append('\\\\textbf{Duration} & \\\\textbf{Neighbourhood} \\\\\\\\ \\\\hline\\n')\n",
    "    if dset == 'all':     param_df = discretization_all_df\n",
    "    if dset == 'noshort': param_df = discretization_noshort_df\n",
    "    if dset == 'perfect': param_df = discretization_perfect_df\n",
    "    for dat_ix in range(len(datnames)):\n",
    "        strs.append(datnames[dat_ix])\n",
    "        strs.append(' & ' + str(param_df.loc[suffix[dat_ix], 'Pop']))\n",
    "        strs.append(' & ' + str(param_df.loc[suffix[dat_ix], 'Visit']))\n",
    "        strs.append(' & ' + str(param_df.loc[suffix[dat_ix], 'Duration']))\n",
    "        strs.append(' & ' + str(param_df.loc[suffix[dat_ix], 'Cluster']))\n",
    "        strs.append(' \\\\\\\\ \\n')\n",
    "    strs.append('\\\\hline\\n')\n",
    "    strs.append('\\\\end{tabular}\\n')\n",
    "    strs.append('\\\\end{table}\\n\\n')\n",
    "print(''.join(strs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
