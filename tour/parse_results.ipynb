{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse Experimental Results & Generate Latex Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, pickle\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = 'data/data-recsys16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "suffix = ['Osak', 'Glas', 'Edin', 'Toro', 'Melb']\n",
    "datnames = ['Osaka', 'Glasgow', 'Edinburgh', 'Toronto', 'Melbourne']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noshort = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "KX = 100  # 100 folds in user specific setting\n",
    "kxstr = str(KX) + 'X-'\n",
    "ALPHA = 0.5\n",
    "alphastr = str(ALPHA).replace('.', '_') + '-'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the F1 score for recommended trajectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_F1(seq_act, seq_rec):\n",
    "    '''Compute recall, precision and F1 when trajectories contain sub-tours'''\n",
    "    assert(len(seq_act) > 0)\n",
    "    assert(len(seq_rec) > 0)\n",
    "    match_tags = np.zeros(len(seq_act), dtype=np.bool)\n",
    "    for poi in seq_rec:\n",
    "        for j in range(len(seq_act)):\n",
    "            if match_tags[j] == False and poi == seq_act[j]:\n",
    "                match_tags[j] = True\n",
    "                break\n",
    "    intersize = np.nonzero(match_tags)[0].shape[0]\n",
    "    recall = intersize / len(seq_act)\n",
    "    precision = intersize / len(seq_rec)\n",
    "    F1 = 2 * precision * recall / (precision + recall)\n",
    "    return F1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load results data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_results(datnames, suffix, dat_ix, noshort, kxstr, alphastr):\n",
    "    assert(0 <= dat_ix <= len(suffix))\n",
    "    assert(len(datnames) == len(suffix))\n",
    "    \n",
    "    if noshort == True:\n",
    "        # user specific results\n",
    "        frecdict_rank_spec = os.path.join(data_dir, 'rank-noshort-specific-' + kxstr + suffix[dat_ix] + '.pkl')\n",
    "        frecdict_tran_spec = os.path.join(data_dir, 'tran-noshort-specific-' + kxstr + suffix[dat_ix] + '.pkl')\n",
    "        frecdict_comb_spec = os.path.join(data_dir, 'comb-noshort-specific-' + alphastr + kxstr + suffix[dat_ix]+'.pkl')\n",
    "\n",
    "        # user agnostic results\n",
    "        frecdict_rank_agno = os.path.join(data_dir, 'rank-noshort-agnostic-' + suffix[dat_ix] + '.pkl')\n",
    "        frecdict_tran_agno = os.path.join(data_dir, 'tran-noshort-agnostic-' + suffix[dat_ix] + '.pkl')\n",
    "        frecdict_comb_agno = os.path.join(data_dir, 'comb-noshort-agnostic-' + alphastr + suffix[dat_ix] + '.pkl')\n",
    "    else:\n",
    "        # user specific results\n",
    "        frecdict_rank_spec = os.path.join(data_dir, 'rank-all-specific-' + kxstr + suffix[dat_ix] + '.pkl')\n",
    "        frecdict_tran_spec = os.path.join(data_dir, 'tran-all-specific-' + kxstr + suffix[dat_ix] + '.pkl')\n",
    "        frecdict_comb_spec = os.path.join(data_dir, 'comb-all-specific-' + alphastr + kxstr + suffix[dat_ix] + '.pkl')\n",
    "\n",
    "        # user agnostic results\n",
    "        frecdict_rank_agno = os.path.join(data_dir, 'rank-all-agnostic-' + suffix[dat_ix] + '.pkl')\n",
    "        frecdict_tran_agno = os.path.join(data_dir, 'tran-all-agnostic-' + suffix[dat_ix] + '.pkl')\n",
    "        frecdict_comb_agno = os.path.join(data_dir, 'comb-all-agnostic-' + alphastr + suffix[dat_ix] + '.pkl')\n",
    "    \n",
    "    # load results data\n",
    "    recdict_rank_spec = pickle.load(open(frecdict_rank_spec, 'rb'))\n",
    "    recdict_rank_agno = pickle.load(open(frecdict_rank_agno, 'rb'))\n",
    "    recdict_tran_spec = pickle.load(open(frecdict_tran_spec, 'rb'))\n",
    "    recdict_tran_agno = pickle.load(open(frecdict_tran_agno, 'rb'))\n",
    "    recdict_comb_spec = pickle.load(open(frecdict_comb_spec, 'rb'))\n",
    "    recdict_comb_agno = pickle.load(open(frecdict_comb_agno, 'rb'))\n",
    "    \n",
    "    # compute F1\n",
    "    F1_rank1_spec = []  # rank pop\n",
    "    F1_rank1_agno = []  # rank pop\n",
    "    F1_rank2_spec = []  # rank feature\n",
    "    F1_rank2_agno = []  # rank feature\n",
    "    for key in sorted(recdict_rank_spec.keys()):\n",
    "        F1_rank1_spec.append(calc_F1(recdict_rank_spec[key]['REAL'], recdict_rank_spec[key]['REC_POP']))\n",
    "        F1_rank2_spec.append(calc_F1(recdict_rank_spec[key]['REAL'], recdict_rank_spec[key]['REC_FEATURE']))\n",
    "    for key in sorted(recdict_rank_agno.keys()):\n",
    "        F1_rank1_agno.append(calc_F1(recdict_rank_agno[key]['REAL'], recdict_rank_agno[key]['REC_POP']))\n",
    "        F1_rank2_agno.append(calc_F1(recdict_rank_agno[key]['REAL'], recdict_rank_agno[key]['REC_FEATURE']))\n",
    "        \n",
    "    F1_tran1_spec = []  # transition DP\n",
    "    F1_tran1_agno = []  # transition DP\n",
    "    F1_tran2_spec = []  # transition ILP\n",
    "    F1_tran2_agno = []  # transition ILP\n",
    "    for key in sorted(recdict_tran_spec.keys()):\n",
    "        F1_tran1_spec.append(calc_F1(recdict_tran_spec[key]['REAL'], recdict_tran_spec[key]['REC_DP']))\n",
    "        F1_tran2_spec.append(calc_F1(recdict_tran_spec[key]['REAL'], recdict_tran_spec[key]['REC_ILP']))\n",
    "    for key in sorted(recdict_tran_agno.keys()):\n",
    "        F1_tran1_agno.append(calc_F1(recdict_tran_agno[key]['REAL'], recdict_tran_agno[key]['REC_DP']))\n",
    "        F1_tran2_agno.append(calc_F1(recdict_tran_agno[key]['REAL'], recdict_tran_agno[key]['REC_ILP']))\n",
    "\n",
    "    F1_comb1_spec = []  # combine rank and transition DP\n",
    "    F1_comb1_agno = []  # combine rank and transition DP\n",
    "    F1_comb2_spec = []  # combine rank and transition ILP\n",
    "    F1_comb2_agno = []  # combine rank and transition ILP\n",
    "    for key in sorted(recdict_comb_spec.keys()):\n",
    "        F1_comb1_spec.append(calc_F1(recdict_comb_spec[key]['REAL'], recdict_comb_spec[key]['REC_DP']))\n",
    "        F1_comb2_spec.append(calc_F1(recdict_comb_spec[key]['REAL'], recdict_comb_spec[key]['REC_ILP']))\n",
    "    for key in sorted(recdict_comb_agno.keys()):\n",
    "        F1_comb1_agno.append(calc_F1(recdict_comb_agno[key]['REAL'], recdict_comb_agno[key]['REC_DP']))\n",
    "        F1_comb2_agno.append(calc_F1(recdict_comb_agno[key]['REAL'], recdict_comb_agno[key]['REC_ILP']))\n",
    "    \n",
    "    # compute mean and std of F1\n",
    "    F1dat = [F1_rank1_agno, F1_rank2_agno, F1_tran1_agno, F1_tran2_agno, F1_comb1_agno, F1_comb2_agno, \\\n",
    "             F1_rank1_spec, F1_rank2_spec, F1_tran1_spec, F1_tran2_spec, F1_comb1_spec, F1_comb2_spec]\n",
    "    F1mean = [np.mean(x) for x in F1dat]\n",
    "    F1std  = [np.std(x) for x in F1dat]\n",
    "    \n",
    "    return F1mean, F1std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "strs = []\n",
    "strs.append('\\\\begin{table*}\\n')\n",
    "strs.append('\\\\centering\\n')\n",
    "strs.append('\\\\caption{Experimental Results}\\n')\n",
    "strs.append('\\\\small\\n')\n",
    "strs.append('\\\\begin{tabular}{l|' + 2*'c' + '|' + 2*'c' + '} \\\\hline\\n')\n",
    "strs.append('\\\\multirow{2}{*}{Method} ')\n",
    "strs.append('& \\\\multicolumn{' + str(2) + '}{|c|}{User agnostic} ')\n",
    "strs.append('& \\\\multicolumn{' + str(2) + '}{|c}{User specific} \\\\\\\\ \\\\cline{2-' + str(1+2+2) + '}\\n')\n",
    "strs.append('& Osaka & Glasgow & Osaka & Glasgow \\\\\\\\ \\\\hline\\n')\n",
    "    \n",
    "dat_ix = 0\n",
    "F1mean0, F1std0 = load_results(datnames, suffix, dat_ix, noshort, kxstr, alphastr)\n",
    "maxix0 = np.argmax(F1mean0)\n",
    "\n",
    "dat_ix = 1\n",
    "F1mean1, F1std1 = load_results(datnames, suffix, dat_ix, noshort, kxstr, alphastr)\n",
    "maxix1 = np.argmax(F1mean1)\n",
    "\n",
    "methods = ['RankP', 'RankF', 'MC-DP', 'MC-ILP', 'Prop-DP', 'Prop-ILP']\n",
    "\n",
    "assert(len(F1mean0) == len(F1mean1))\n",
    "assert(len(F1mean0) == 2*len(methods))\n",
    "\n",
    "for j in range(len(methods)):\n",
    "    strs.append(methods[j] + ' ')\n",
    "    strs.append('& $')\n",
    "    if j == maxix0: strs.append('\\\\mathbf{')\n",
    "    strs.append('%.3f' % F1mean0[j]); strs.append('\\\\pm'); strs.append('%.3f' % F1std0[j])\n",
    "    if j == maxix0: strs.append('}')\n",
    "    strs.append('$ ')\n",
    "    \n",
    "    strs.append('& $')\n",
    "    if j == maxix1: strs.append('\\\\mathbf{')\n",
    "    strs.append('%.3f' % F1mean1[j]); strs.append('\\\\pm'); strs.append('%.3f' % F1std1[j])\n",
    "    if j == maxix1: strs.append('}')\n",
    "    strs.append('$ ') \n",
    "    \n",
    "    strs.append('& $')\n",
    "    if j+len(methods) == maxix0: strs.append('\\\\mathbf{')\n",
    "    strs.append('%.3f' % F1mean0[j+len(methods)]); strs.append('\\\\pm'); strs.append('%.3f' % F1std0[j+len(methods)])\n",
    "    if j+len(methods) == maxix0: strs.append('}')\n",
    "    strs.append('$ ')\n",
    "    \n",
    "    strs.append('& $')\n",
    "    if j+len(methods) == maxix1: strs.append('\\\\mathbf{')\n",
    "    strs.append('%.3f' % F1mean1[j+len(methods)]); strs.append('\\\\pm'); strs.append('%.3f' % F1std1[j+len(methods)])\n",
    "    if j+len(methods) == maxix1: strs.append('}')\n",
    "    strs.append('$ ')    \n",
    "    strs.append('\\\\\\\\\\n')\n",
    "\n",
    "strs.append('\\\\hline\\n')\n",
    "strs.append('\\\\end{tabular}\\n')\n",
    "strs.append('\\\\end{table*}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table*}\n",
      "\\centering\n",
      "\\caption{Experimental Results}\n",
      "\\small\n",
      "\\begin{tabular}{l|cc|cc} \\hline\n",
      "\\multirow{2}{*}{Method} & \\multicolumn{2}{|c|}{User agnostic} & \\multicolumn{2}{|c}{User specific} \\\\ \\cline{2-5}\n",
      "& Osaka & Glasgow & Osaka & Glasgow \\\\ \\hline\n",
      "RankP & $0.611\\pm0.163$ & $0.706\\pm0.169$ & $0.611\\pm0.163$ & $0.706\\pm0.169$ \\\\\n",
      "RankF & $0.633\\pm0.153$ & $\\mathbf{0.758\\pm0.182}$ & $0.647\\pm0.170$ & $0.754\\pm0.179$ \\\\\n",
      "MC-DP & $0.707\\pm0.229$ & $0.708\\pm0.184$ & $0.706\\pm0.218$ & $0.695\\pm0.182$ \\\\\n",
      "MC-ILP & $0.670\\pm0.209$ & $0.705\\pm0.168$ & $0.656\\pm0.198$ & $0.691\\pm0.177$ \\\\\n",
      "Prop-DP & $\\mathbf{0.709\\pm0.202}$ & $0.745\\pm0.180$ & $0.658\\pm0.192$ & $0.714\\pm0.183$ \\\\\n",
      "Prop-ILP & $0.660\\pm0.206$ & $0.743\\pm0.179$ & $0.635\\pm0.190$ & $0.724\\pm0.167$ \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "\\end{table*}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(''.join(strs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "strs = []\n",
    "strs.append('\\\\begin{table*}\\n')\n",
    "strs.append('\\\\centering\\n')\n",
    "strs.append('\\\\caption{Experimental Results}\\n')\n",
    "strs.append('\\\\small\\n')\n",
    "strs.append('\\\\begin{tabular}{c|' + 6*'c' + '|' + 6*'c' + '} \\\\hline\\n')\n",
    "strs.append('\\\\multirow{2}{*}{Dataset} ')\n",
    "strs.append('& \\\\multicolumn{' + str(6) + '}{|c|}{User agnostic} ')\n",
    "strs.append('& \\\\multicolumn{' + str(6) + '}{|c}{User specific} \\\\\\\\ \\\\cline{2-' + str(1+6+6) + '}\\n')\n",
    "strs.append('& RankP & RankF & MC-DP & MC-ILP & Prop-DP & Prop-ILP\\n')\n",
    "strs.append('& RankP & RankF & MC-DP & MC-ILP & Prop-DP & Prop-ILP \\\\\\\\ \\\\hline\\n')\n",
    "    \n",
    "for dat_ix in range(len(suffix)-3):\n",
    "    F1mean, F1std = load_results(datnames, suffix, dat_ix, noshort, kxstr, alphastr)\n",
    "    maxix = np.argmax(F1mean)\n",
    "    strs.append(datnames[dat_ix] + ' ')\n",
    "    for j in range(len(F1mean)):\n",
    "        strs.append('& $')\n",
    "        if j == maxix:\n",
    "            strs.append('\\\\mathbf{')\n",
    "        strs.append('%.2f' % F1mean[j]); strs.append('\\\\pm'); strs.append('%.2f' % F1std[j])\n",
    "        if j == maxix: \n",
    "            strs.append('}')\n",
    "        strs.append('$ ')\n",
    "    strs.append('\\\\\\\\\\n')\n",
    "\n",
    "strs.append('\\\\hline\\n')\n",
    "strs.append('\\\\end{tabular}\\n')\n",
    "strs.append('\\\\end{table*}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table*}\n",
      "\\centering\n",
      "\\caption{Experimental Results}\n",
      "\\small\n",
      "\\begin{tabular}{c|cccccc|cccccc} \\hline\n",
      "\\multirow{2}{*}{Dataset} & \\multicolumn{6}{|c|}{User agnostic} & \\multicolumn{6}{|c}{User specific} \\\\ \\cline{2-13}\n",
      "& RankP & RankF & MC-DP & MC-ILP & Prop-DP & Prop-ILP\n",
      "& RankP & RankF & MC-DP & MC-ILP & Prop-DP & Prop-ILP \\\\ \\hline\n",
      "Osaka & $0.61\\pm0.16$ & $0.63\\pm0.15$ & $0.71\\pm0.23$ & $0.67\\pm0.21$ & $\\mathbf{0.71\\pm0.20}$ & $0.66\\pm0.21$ & $0.61\\pm0.16$ & $0.65\\pm0.17$ & $0.71\\pm0.22$ & $0.66\\pm0.20$ & $0.66\\pm0.19$ & $0.63\\pm0.19$ \\\\\n",
      "Glasgow & $0.71\\pm0.17$ & $\\mathbf{0.76\\pm0.18}$ & $0.71\\pm0.18$ & $0.70\\pm0.17$ & $0.75\\pm0.18$ & $0.74\\pm0.18$ & $0.71\\pm0.17$ & $0.75\\pm0.18$ & $0.70\\pm0.18$ & $0.69\\pm0.18$ & $0.71\\pm0.18$ & $0.72\\pm0.17$ \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "\\end{table*}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(''.join(strs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
