{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse Experimental Results & Generate Latex Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import os, pickle, types\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_ijcai = 'data/data-ijcai15'\n",
    "data_recsys = 'data/data-recsys16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dat_suffix = ['Edin', 'Glas', 'Osak', 'Toro']#, 'Melb']\n",
    "dat_names = ['Edinburgh', 'Glasgow', 'Osaka', 'Toronto']#, 'Melbourne']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dat_types = ['all']#, 'nofew']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "methods_all = ['\\\\textsc{Random}', '\\\\textsc{PersTour}\\cite{ijcai15}', '\\\\textsc{PersTour-L}', \\\n",
    "               '\\\\textsc{PoiPopularity}', '\\\\textsc{PoiRank}', '\\\\textsc{Markov}', '\\\\textsc{MarkovPath}', \\\n",
    "               '\\\\textsc{Rank+Markov}', '\\\\textsc{Rank+MarkovPath}', '\\\\textsc{StructuredSVM}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_photos = [82060, 29019, 392420, 157505]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#F1_rand_mean = [0.624, 0.627, 0.579, 0.613, 0.537]\n",
    "#F1_rand_std  = [0.085, 0.083, 0.102, 0.093, 0.142]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#F1_ijcai05_mean = [0.686, 0.801, 0.656, 0.720, 0]\n",
    "#F1_ijcai05_std  = [0.233, 0.214, 0.223, 0.215, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#F1_ijcai10_mean = [0.639, 0.719, 0.611, 0.709, 0]\n",
    "#F1_ijcai10_std  = [0.202, 0.211, 0.201, 0.219, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#F1_ijcai05L_mean = [0.686, 0.660, 0.651, 0.643, 0]\n",
    "#F1_ijcai05L_std  = [0.138, 0.102, 0.143, 0.114, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#F1_ijcai10L_mean = [0.654, 0.641, 0.595, 0.611, 0]\n",
    "#F1_ijcai10L_std  = [0.140, 0.114, 0.138, 0.115, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latex Table for Dataset Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table*}\n",
      "\\centering\n",
      "\\begin{tabular}{lrrrrr} \\hline\n",
      "\\textbf{Dataset} & \\textbf{\\#Photos} & \\textbf{\\#POI Visits} & \\textbf{\\#Trajectories} & \\textbf{\\#Users} \\\\ \\hline\n",
      "Edinburgh & 82,060 & 33,944 & 5,028 & 1,454 \\\\ \n",
      "Glasgow & 29,019 & 11,434 & 2,227 & 601 \\\\ \n",
      "Osaka & 392,420 & 7,747 & 1,115 & 450 \\\\ \n",
      "Toronto & 157,505 & 39,419 & 6,057 & 1,395 \\\\ \n",
      "\\hline\n",
      "\\end{tabular}\n",
      "\\caption{Statistics of trajectory dataset}\n",
      "\\label{table:data}\n",
      "\\end{table*}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "strs = []\n",
    "for dset in dat_types:\n",
    "    if dset == 'all':     \n",
    "        title = 'of all trajectories without loops'\n",
    "        noloop = True\n",
    "    if dset == 'nofew':   \n",
    "        title = 'of users with more than 5 (including 5) trajectories with loops'\n",
    "        noloop = False\n",
    "    strs.append('\\\\begin{table*}\\n')\n",
    "    strs.append('\\\\centering\\n')\n",
    "    #strs.append('\\\\caption{Dataset ' + title + '}\\n')\n",
    "    #strs.append('\\\\small\\n')\n",
    "    strs.append('\\\\begin{tabular}{' + 'l' + 5*'r' + '} \\\\hline\\n')\n",
    "    #strs.append('\\\\textbf{City} & \\\\textbf{\\\\#POIs} & \\\\textbf{\\\\#Users} & ')\n",
    "    #strs.append('\\\\textbf{\\\\#POI Visits} & \\\\textbf{\\\\#Trajectories} & \\\\textbf{\\\\#TotalNodes} \\\\\\\\ \\\\hline\\n')\n",
    "    strs.append('\\\\textbf{Dataset} & \\\\textbf{\\\\#Photos} & \\\\textbf{\\\\#POI Visits} & \\\\textbf{\\\\#Trajectories} & ')\n",
    "    strs.append('\\\\textbf{\\\\#Users} \\\\\\\\ \\\\hline\\n')\n",
    "    \n",
    "    for dat_ix in range(len(dat_names)):\n",
    "        if noloop == True:\n",
    "            ftraj = os.path.join(data_recsys, 'traj-noloop-' + dset + '-' + dat_suffix[dat_ix] + '.csv')\n",
    "        else:\n",
    "            ftraj = os.path.join(data_recsys, 'traj-' + dset + '-' + dat_suffix[dat_ix] + '.csv')\n",
    "        traj_df = pd.read_csv(ftraj)\n",
    "        total_nodes = traj_df[['trajID', 'trajLen']].copy().groupby('trajID').first().sum().values[0]\n",
    "        strs.append(dat_names[dat_ix])\n",
    "        #strs.append(' & ' + '{:,}'.format(traj_df['poiID'].unique().shape[0]))\n",
    "        strs.append(' & ' + '{:,}'.format(num_photos[dat_ix]))\n",
    "        strs.append(' & ' + '{:,}'.format(traj_df['#photo'].sum()))\n",
    "        strs.append(' & ' + '{:,}'.format(traj_df['trajID'].unique().shape[0]))\n",
    "        strs.append(' & ' + '{:,}'.format(traj_df['userID'].unique().shape[0]))\n",
    "        #strs.append(' & ' + '{:,}'.format(total_nodes))\n",
    "        strs.append(' \\\\\\\\ \\n')\n",
    "    strs.append('\\\\hline\\n')\n",
    "    strs.append('\\\\end{tabular}\\n')\n",
    "    strs.append('\\\\caption{Statistics of trajectory dataset}\\n')\n",
    "    strs.append('\\\\label{table:data}\\n')\n",
    "    strs.append('\\\\end{table*}\\n\\n')\n",
    "print(''.join(strs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latex Table for Recommendation Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate results filenames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_fname(dat_ix, type_ix, noloop, uspecific, alpha, C, KX):\n",
    "    assert(0 <= dat_ix < len(dat_suffix))\n",
    "    assert(0 <= type_ix < len(dat_types))\n",
    "    assert(isinstance(noloop, bool))\n",
    "    assert(isinstance(uspecific, bool))\n",
    "    assert(0 < alpha < 1)\n",
    "    alpha_str = str(alpha).replace('.', '_') + '-'\n",
    "    C_str = 'C' + str(C) + '-'\n",
    "    KX_str = str(KX) + 'X-'\n",
    "    \n",
    "    if noloop == True:\n",
    "        loop_str = 'noloop-'\n",
    "    else:\n",
    "        loop_str = ''\n",
    "    \n",
    "    type_str = dat_types[type_ix] + '-'\n",
    "    \n",
    "    if uspecific == True:\n",
    "        user_str = 'specific-'\n",
    "        suffix = KX_str + dat_suffix[dat_ix] + '.pkl'\n",
    "    else:\n",
    "        user_str = 'agnostic-'\n",
    "        suffix = dat_suffix[dat_ix] + '.pkl'\n",
    "    \n",
    "    fname = loop_str + type_str + user_str\n",
    "    frank = os.path.join(data_recsys, 'rank-' + fname + suffix)\n",
    "    ftran = os.path.join(data_recsys, 'tran-' + fname + suffix)\n",
    "    fcomb = os.path.join(data_recsys, 'comb-' + fname + alpha_str + suffix)\n",
    "    fcrf2  = os.path.join(data_recsys, 'crf2-' + fname + C_str + suffix)\n",
    "    frand  = os.path.join(data_recsys, 'rand-' + fname + suffix)\n",
    "    fijcai = os.path.join(data_ijcai, 'ijcai-' + dat_suffix[dat_ix] + '.pkl')\n",
    "    return frank, ftran, fcomb, fcrf2, frand, fijcai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('data/data-recsys16/rank-noloop-all-agnostic-Glas.pkl',\n",
       " 'data/data-recsys16/tran-noloop-all-agnostic-Glas.pkl',\n",
       " 'data/data-recsys16/comb-noloop-all-agnostic-0_5-Glas.pkl',\n",
       " 'data/data-recsys16/crf2-noloop-all-agnostic-C1-Glas.pkl',\n",
       " 'data/data-recsys16/rand-noloop-all-agnostic-Glas.pkl',\n",
       " 'data/data-ijcai15/ijcai-Glas.pkl')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_fname(1, 0, True, False, 0.5, 1, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the F1 score for recommended trajectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_F1(seq_act, seq_rec):\n",
    "    '''Compute recall, precision and F1 when trajectories contain sub-tours'''\n",
    "    assert(len(seq_act) > 0)\n",
    "    assert(len(seq_rec) > 0)\n",
    "    match_tags = np.zeros(len(seq_act), dtype=np.bool)\n",
    "    for poi in seq_rec:\n",
    "        for j in range(len(seq_act)):\n",
    "            if match_tags[j] == False and poi == seq_act[j]:\n",
    "                match_tags[j] = True\n",
    "                break\n",
    "    intersize = np.nonzero(match_tags)[0].shape[0]\n",
    "    recall = intersize / len(seq_act)\n",
    "    precision = intersize / len(seq_rec)\n",
    "    F1 = 2 * precision * recall / (precision + recall)\n",
    "    return F1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple method to evaluate POI visiting order by adapting [Kendau's tau](https://en.wikipedia.org/wiki/Kendall_rank_correlation_coefficient)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calc_Tau(seq_act, seq_rec):\n",
    "    \"\"\"\n",
    "    NOTE: tau-a version seems to be more reasonable for evaluating visiting order of POIs.\n",
    "    An adaptation of Kendall's tau-b: https://en.wikipedia.org/wiki/Kendall_rank_correlation_coefficient#Tau-b\n",
    "    tau = (nc - nd - nn) / sqrt((n0 - n1)*(n0 - n2))\n",
    "    where:\n",
    "    nc: #concordant pairs (pair order is defined by the order of POIs in seq_act)\n",
    "    nd: #discordant pairs, for POIs in seq_rec, counting only those that also in seq_act\n",
    "    nn: #non-existent combination, i.e., combinations didn't appear in seq_act\n",
    "    n0: n(n-1)/2, n = len(seq_act)\n",
    "    n1: #ties in the first group  (i.e., seq_act), 0 here as seq_act didn't contain loops\n",
    "    n2: #ties in the second group (i.e., seq_rec), only counting those appeared in seq_act\n",
    "    after simplification,\n",
    "    tau = (nc - nd1) / sqrt(n0*(n0 - n2))\n",
    "    where nd1 = nd + nn\n",
    "    \"\"\"\n",
    "    assert(len(seq_act) == len(seq_rec))\n",
    "    assert(len(seq_act) > 0)\n",
    "    assert(len(seq_act) == len(set(seq_act))) # no loops in seq_act\n",
    "    n = len(seq_act)\n",
    "    n0 = n*(n-1) / 2\n",
    "    \n",
    "    # seq_act determines the correct visiting order\n",
    "    order_df = pd.DataFrame(data=np.zeros((n, n), dtype=np.bool), columns=seq_act, index=seq_act)\n",
    "    for i in range(n):\n",
    "        poi1 = seq_act[i]\n",
    "        for j in range(i+1, n):\n",
    "            poi2 = seq_act[j]\n",
    "            order_df.loc[poi1, poi2] = True\n",
    "            \n",
    "    nc, nd1, n2 = 0, 0, 0\n",
    "    for i in range(n):\n",
    "        poi1 = seq_rec[i]\n",
    "        for j in range(i+1, n):\n",
    "            poi2 = seq_rec[j]\n",
    "            if poi1 in seq_act and poi2 in seq_act:\n",
    "                if poi1 != poi2:\n",
    "                    if order_df.loc[poi1, poi2] == True: nc += 1\n",
    "                    else: nd1 += 1\n",
    "                #else: n2 += 1\n",
    "            #else: nd1 += 1 # combinations didn't appear in seq_act\n",
    "    #return (nc - nd1) / np.sqrt(n0*(n0 - n2))\n",
    "    return (nc - nd1) / n0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check: function `calc_Tau` should give the same result as `scipy.stats.kendalltau` if the first argument is an array of number in *descending* order and all numbers in the second argument appear in the first argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import kendalltau\n",
    "x = [3, 2, 1]\n",
    "#y = [3, 2, 1]\n",
    "#y = [1, 2, 3]\n",
    "#y = [3, 1, 2]\n",
    "#y = [1, 1, 2]\n",
    "#y = [1, 2, 1]\n",
    "#y = [9, 8, 7]\n",
    "tau = calc_Tau(x, y)\n",
    "ret = kendalltau(x, y)\n",
    "print(tau)\n",
    "print(ret[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_Tau([5, 3, 9], [5, 1, 9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [19, 3, 5, 6]\n",
    "#y = [19, 3, 5, 6]\n",
    "#y = [19, 3, 1, 6]\n",
    "y = [19, 1, 5, 6]\n",
    "#y = [19, 3, 3, 6]\n",
    "#y = [19, 5, 5, 6]\n",
    "#y = [19, 19, 5, 6]\n",
    "#y = [19, 3, 6, 6]\n",
    "#y = [19, 6, 6, 6]\n",
    "#y = [19, 1, 2, 6]\n",
    "#y = [19, 5, 3, 6]\n",
    "calc_Tau(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dict1 = pickle.load(open('data/data-ijcai15/ijcai-Edin.pkl', 'rb'))\n",
    "#metrics = [calc_Tau(dict1[x]['REAL'], dict1[x]['REC10L']) for x in dict1.keys()]\n",
    "metrics = [calc_Tau(dict1[x]['REAL'], dict1[x]['REC05L']) for x in dict1.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35010102772 0.205541078499\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(metrics), np.std(metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load results data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_results(dat_ix, type_ix, alpha, C, KX, uspecific):\n",
    "    assert(0 <= dat_ix < len(dat_suffix))\n",
    "    assert(0 <= type_ix < len(dat_types))\n",
    "    assert(0 < alpha < 1)\n",
    "    assert(isinstance(uspecific, bool))\n",
    "    \n",
    "    if uspecific == True:\n",
    "        noloop = False\n",
    "    else:\n",
    "        noloop = True\n",
    "    \n",
    "    frank, ftran, fcomb, fcrf2, frand, fijcai = gen_fname(dat_ix, type_ix, noloop, uspecific, alpha, C, KX)\n",
    "    #print(frank)\n",
    "    assert(os.path.exists(frank))\n",
    "    #print(ftran)\n",
    "    assert(os.path.exists(ftran))\n",
    "    #print(fcomb)\n",
    "    assert(os.path.exists(fcomb))\n",
    "    #print(fcrf)\n",
    "    #assert(os.path.exists(fcrf))\n",
    "    #print(fcrf1)\n",
    "    assert(os.path.exists(fcrf2))\n",
    "    #print(frand)\n",
    "    assert(os.path.exists(frand))\n",
    "    #print(fijcai)\n",
    "    assert(os.path.exists(fijcai))\n",
    "\n",
    "\n",
    "    # load results data\n",
    "    recdict_rank = pickle.load(open(frank, 'rb'))\n",
    "    recdict_tran = pickle.load(open(ftran, 'rb'))\n",
    "    recdict_comb = pickle.load(open(fcomb, 'rb'))\n",
    "    #recdict_crf  = pickle.load(open(fcrf,  'rb'))\n",
    "    recdict_crf2 = pickle.load(open(fcrf2, 'rb'))\n",
    "    recdict_rand = pickle.load(open(frand, 'rb'))\n",
    "    recdict_ijcai = pickle.load(open(fijcai, 'rb'))\n",
    "    \n",
    "    return recdict_rank, recdict_tran, recdict_comb, recdict_crf2, recdict_rand, recdict_ijcai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate F1-scores from loaded results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_metrics(recdict_rank, recdict_tran, recdict_comb, recdict_crf2, recdict_rand, recdict_ijcai, func):\n",
    "    assert(isinstance(func, types.FunctionType))\n",
    "    \n",
    "    # deal with missing values: \n",
    "    # get rid of recommendation that not all method are successful, \n",
    "    # due to ILP timeout, <start, end> of test doesn't exist in training set,\n",
    "    # and training set always constains all POIs.\n",
    "    assert(np.all(sorted(recdict_rank.keys()) == sorted(recdict_tran.keys())))\n",
    "    assert(np.all(sorted(recdict_rank.keys()) == sorted(recdict_comb.keys())))\n",
    "    assert(np.all(sorted(recdict_ijcai.keys()) == sorted(set(recdict_ijcai.keys()) & set(recdict_rank.keys()))))\n",
    "    \n",
    "    keys_all = sorted(recdict_ijcai.keys() & recdict_crf2.keys())\n",
    "    #print(len(recdict_ijcai.keys()), len(recdict_crf1.keys()), len(keys_all))\n",
    "    \n",
    "    # compute F1\n",
    "    rank1 = []  # rank pop\n",
    "    rank2 = []  # rank feature\n",
    "    #for key in sorted(recdict_rank.keys()):\n",
    "    for key in keys_all:\n",
    "        rank1.append(func(recdict_rank[key]['REAL'], recdict_rank[key]['REC_POP']))\n",
    "        rank2.append(func(recdict_rank[key]['REAL'], recdict_rank[key]['REC_FEATURE']))\n",
    "    \n",
    "    tran1 = []  # transition DP\n",
    "    tran2 = []  # transition ILP\n",
    "    #for key in sorted(recdict_tran.keys()):\n",
    "    for key in keys_all:\n",
    "        tran1.append(func(recdict_tran[key]['REAL'], recdict_tran[key]['REC_DP']))\n",
    "        tran2.append(func(recdict_tran[key]['REAL'], recdict_tran[key]['REC_ILP']))\n",
    "\n",
    "    comb1 = []  # combine rank and transition DP\n",
    "    comb2 = []  # combine rank and transition ILP\n",
    "    #for key in sorted(recdict_comb.keys()):\n",
    "    for key in keys_all:\n",
    "        comb1.append(func(recdict_comb[key]['REAL'], recdict_comb[key]['REC_DP']))\n",
    "        comb2.append(func(recdict_comb[key]['REAL'], recdict_comb[key]['REC_ILP']))\n",
    "        \n",
    "    #crf = []   # structured prediction\n",
    "    #for key in sorted(recdict_crf.keys()):\n",
    "    #for key in keys_all:\n",
    "    #    crf.append(func(recdict_crf[key]['REAL'], recdict_crf[key]['REC_CRF']))\n",
    "    \n",
    "    crf2 = []   # structured prediction\n",
    "    #for key in sorted(recdict_crf1.keys()):\n",
    "    for key in keys_all:\n",
    "        crf2.append(func(recdict_crf2[key]['REAL'], recdict_crf2[key]['REC_CRF']))\n",
    "        \n",
    "    rand = []   # structured prediction\n",
    "    #for key in sorted(recdict_rand.keys()):\n",
    "    for key in keys_all:\n",
    "        rand.append(func(recdict_rand[key]['REAL'], recdict_rand[key]['REC_RAND']))\n",
    "    \n",
    "    ijcai05T = []   # IJCAI method\n",
    "    #ijcai10T = []   # IJCAI method\n",
    "    ijcai05L = []   # IJCAI method\n",
    "    #ijcai10L = []   # IJCAI method\n",
    "    #for key in sorted(recdict_ijcai.keys()):\n",
    "    for key in keys_all:\n",
    "        if func == calc_F1:\n",
    "            ijcai05T.append(func(recdict_ijcai[key]['REAL'], recdict_ijcai[key]['REC05T']))\n",
    "            #ijcai10T.append(func(recdict_ijcai[key]['REAL'], recdict_ijcai[key]['REC10T']))\n",
    "        ijcai05L.append(func(recdict_ijcai[key]['REAL'], recdict_ijcai[key]['REC05L']))\n",
    "        #ijcai10L.append(func(recdict_ijcai[key]['REAL'], recdict_ijcai[key]['REC10L']))        \n",
    "    \n",
    "    # compute mean and std of F1\n",
    "    metrics = [rand]\n",
    "    if func == calc_F1:\n",
    "        metrics = metrics + [ijcai05T]\n",
    "    metrics = metrics + [ijcai05L, rank1, rank2, tran1, tran2, comb1, comb2, crf2]\n",
    "    means = [np.mean(x) for x in metrics]\n",
    "    stds  = [np.std(x)  for x in metrics]\n",
    "    \n",
    "    return means, stds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Latex tables from calculated metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_latex_table(mean_df, std_df, ismax_df, ismax2nd_df, type_ix, uspecific, title, label):\n",
    "    assert(isinstance(uspecific, bool))\n",
    "    if dat_types[type_ix] == 'all': \n",
    "        dstr = 'of all trajectories without loops'\n",
    "        ustr = 'user agnostic setting'\n",
    "    if dat_types[type_ix] == 'nofew': \n",
    "        dstr = 'of users with more than 5 (including 5) trajectories with loops'\n",
    "        ustr = 'user specific setting'\n",
    "\n",
    "    strs = []\n",
    "    strs.append('\\\\begin{table*}\\n')\n",
    "    strs.append('\\\\centering\\n')\n",
    "    #strs.append('\\\\caption{Experimental Results: ' + ustr + ' ' + dstr + '}\\n')\n",
    "    #strs.append('\\\\small\\n')\n",
    "    strs.append('\\\\begin{tabular}{l|' + (mean_df.shape[1])*'c' + '} \\\\hline\\n')\n",
    "    for col in mean_df.columns:\n",
    "        strs.append(' & ' + col)\n",
    "    strs.append(' \\\\\\\\ \\\\hline\\n')\n",
    "    for ix in mean_df.index:\n",
    "        for j in range(mean_df.shape[1]):\n",
    "            if j == 0: strs.append(ix + ' ')\n",
    "            jx = mean_df.columns[j]\n",
    "            strs.append('& $')\n",
    "            if ismax_df.loc[ix, jx] == True: strs.append('\\\\mathbf{')\n",
    "            if ismax2nd_df.loc[ix, jx] == True: strs.append('\\\\mathit{')\n",
    "            strs.append('%.3f' % mean_df.loc[ix, jx] + '\\\\pm' + '%.3f' % std_df.loc[ix, jx])\n",
    "            if ismax_df.loc[ix, jx] == True or ismax2nd_df.loc[ix, jx] == True: strs.append('}')\n",
    "            strs.append('$ ')\n",
    "        strs.append('\\\\\\\\\\n')\n",
    "    strs.append('\\\\hline\\n')\n",
    "    strs.append('\\\\end{tabular}\\n')\n",
    "    strs.append('\\\\caption{' + title + '}\\n')\n",
    "    strs.append('\\\\label{' + label + '}\\n')\n",
    "    strs.append('\\\\end{table*}\\n')\n",
    "    return ''.join(strs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate evaluation data tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "KX = 100  # 100 folds in user specific setting\n",
    "alpha = 0.5\n",
    "C = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#func = calc_F1\n",
    "func = calc_Tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table*}\n",
      "\\centering\n",
      "\\begin{tabular}{l|cccc} \\hline\n",
      " & Edinburgh & Glasgow & Osaka & Toronto \\\\ \\hline\n",
      "\\textsc{Random} & $0.259\\pm0.155$ & $0.318\\pm0.165$ & $0.305\\pm0.145$ & $0.309\\pm0.166$ \\\\\n",
      "\\textsc{PersTour-L} & $0.350\\pm0.206$ & $0.349\\pm0.163$ & $0.415\\pm0.243$ & $0.329\\pm0.158$ \\\\\n",
      "\\textsc{PoiPopularity} & $\\mathit{0.421\\pm0.257}$ & $0.503\\pm0.296$ & $0.361\\pm0.194$ & $0.378\\pm0.203$ \\\\\n",
      "\\textsc{PoiRank} & $0.410\\pm0.246$ & $\\mathbf{0.557\\pm0.311}$ & $0.367\\pm0.162$ & $\\mathit{0.501\\pm0.294}$ \\\\\n",
      "\\textsc{Markov} & $0.404\\pm0.229$ & $0.472\\pm0.282$ & $0.442\\pm0.259$ & $0.406\\pm0.231$ \\\\\n",
      "\\textsc{MarkovPath} & $0.390\\pm0.235$ & $0.479\\pm0.292$ & $0.445\\pm0.268$ & $0.401\\pm0.235$ \\\\\n",
      "\\textsc{Rank+Markov} & $0.411\\pm0.237$ & $0.522\\pm0.293$ & $\\mathit{0.475\\pm0.278}$ & $0.449\\pm0.263$ \\\\\n",
      "\\textsc{Rank+MarkovPath} & $0.395\\pm0.238$ & $\\mathit{0.523\\pm0.303}$ & $0.470\\pm0.284$ & $0.455\\pm0.268$ \\\\\n",
      "\\textsc{StructuredSVM} & $\\mathbf{0.423\\pm0.264}$ & $0.505\\pm0.282$ & $\\mathbf{0.499\\pm0.293}$ & $\\mathbf{0.511\\pm0.312}$ \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "\\caption{Performance comparison on four datasets in terms of $\\tau$}\n",
      "\\label{table:tau}\n",
      "\\end{table*}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if func == calc_Tau: \n",
    "    methods = [methods_all[0]] + methods_all[2:]\n",
    "else:\n",
    "    methods = methods_all.copy()\n",
    "    \n",
    "\n",
    "for type_ix in range(len(dat_types)):\n",
    "    mean_df = pd.DataFrame(data=np.zeros((len(methods), len(dat_names)), dtype=np.float), \\\n",
    "                           columns=dat_names, index=methods)\n",
    "    std_df  = pd.DataFrame(data=np.zeros((len(methods), len(dat_names)), dtype=np.float), \\\n",
    "                           columns=dat_names, index=methods)\n",
    "    \n",
    "    if dat_types[type_ix] == 'all':\n",
    "        uspecific = False\n",
    "    if dat_types[type_ix] == 'nofew':\n",
    "        uspecific = True\n",
    "        \n",
    "    for dat_ix in range(len(dat_suffix)):\n",
    "        recdict_rank, recdict_tran, recdict_comb, recdict_crf2, recdict_rand, recdict_ijcai = load_results\\\n",
    "        (dat_ix, type_ix, alpha, C, KX, uspecific)\n",
    "        means, stds = calc_metrics(recdict_rank, recdict_tran, recdict_comb, recdict_crf2, \\\n",
    "                                   recdict_rand, recdict_ijcai, func)\n",
    "        #print(len(means), len(stds), len(methods))\n",
    "        assert(len(means) == len(stds) == len(methods))\n",
    "        mean_df[dat_names[dat_ix]] = means\n",
    "        std_df[dat_names[dat_ix]]  = stds\n",
    "        \n",
    "    ismax_df  = pd.DataFrame(data=np.zeros(mean_df.shape, dtype=np.bool), \\\n",
    "                             columns=mean_df.columns, index=mean_df.index)\n",
    "    ismax2nd_df = ismax_df.copy()\n",
    "    for col in ismax_df.columns:\n",
    "        #maxix = mean_df[col].argmax()\n",
    "        #ismax_df.loc[maxix, col] = True\n",
    "        indices = (-mean_df[col]).argsort().values[:2]\n",
    "        ismax_df.iloc[indices[0]][col] = True\n",
    "        ismax2nd_df.iloc[indices[1]][col] = True\n",
    "    \n",
    "    if func == calc_F1:\n",
    "        title = 'Performance comparison on four datasets in terms of trajectory F$_1$-score'\n",
    "        label = 'table:f1'\n",
    "    else:\n",
    "        title = 'Performance comparison on four datasets in terms of $\\\\tau$'\n",
    "        label = 'table:tau'\n",
    "    strs = gen_latex_table(mean_df, std_df, ismax_df, ismax2nd_df, type_ix, uspecific, title, label)\n",
    "    \n",
    "    print(strs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
