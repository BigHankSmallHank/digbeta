{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse Experimental Results & Generate Latex Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import os, pickle, types\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_ijcai = 'data/data-ijcai15'\n",
    "data_recsys = 'data/data-recsys16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dat_suffix = ['Osak', 'Glas', 'Edin', 'Toro', 'Melb']\n",
    "dat_names = ['Osaka', 'Glasgow', 'Edinburgh', 'Toronto', 'Melbourne']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dat_types = ['all', 'nofew']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "methods = ['Random', 'PersTour-T.5', 'PersTour-T1', 'PersTour-L.5', 'PersTour-L1', 'RankP', 'RankF', 'MC-DP', 'MC-ILP', \\\n",
    "           'Prop-DP', 'Prop-ILP', 'CRF', 'CRF1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "F1_rand_mean = [0.624, 0.627, 0.579, 0.613, 0.537]\n",
    "F1_rand_std  = [0.085, 0.083, 0.102, 0.093, 0.142]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "F1_ijcai05_mean = [0.686, 0.801, 0.656, 0.720, 0]\n",
    "F1_ijcai05_std  = [0.233, 0.214, 0.223, 0.215, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "F1_ijcai10_mean = [0.639, 0.719, 0.611, 0.709, 0]\n",
    "F1_ijcai10_std  = [0.202, 0.211, 0.201, 0.219, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "F1_ijcai05L_mean = [0.686, 0.660, 0.651, 0.643, 0]\n",
    "F1_ijcai05L_std  = [0.138, 0.102, 0.143, 0.114, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "F1_ijcai10L_mean = [0.654, 0.641, 0.595, 0.611, 0]\n",
    "F1_ijcai10L_std  = [0.140, 0.114, 0.138, 0.115, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latex Table for Dataset Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "strs = []\n",
    "for dset in dat_types:\n",
    "    if dset == 'all':     \n",
    "        title = 'of all trajectories without loops'\n",
    "        noloop = True\n",
    "    if dset == 'nofew':   \n",
    "        title = 'of users with more than 5 (including 5) trajectories with loops'\n",
    "        noloop = False\n",
    "    strs.append('\\\\begin{table*}\\n')\n",
    "    strs.append('\\\\centering\\n')\n",
    "    strs.append('\\\\caption{Dataset ' + title + '}\\n')\n",
    "    strs.append('\\\\label{table:data:' + dset + '}\\n')\n",
    "    #strs.append('\\\\small\\n')\n",
    "    strs.append('\\\\begin{tabular}{' + 'l' + 5*'r' + '} \\\\hline\\n')\n",
    "    strs.append('\\\\textbf{City} & \\\\textbf{\\\\#POIs} & \\\\textbf{\\\\#Users} & ')\n",
    "    strs.append('\\\\textbf{\\\\#POI Visits} & \\\\textbf{\\\\#Trajectories} & \\\\textbf{\\\\#TotalNodes} \\\\\\\\ \\\\hline\\n')\n",
    "    \n",
    "    for dat_ix in range(len(dat_names)):\n",
    "        if noloop == True:\n",
    "            ftraj = os.path.join(data_dir, 'traj-noloop-' + dset + '-' + dat_suffix[dat_ix] + '.csv')\n",
    "        else:\n",
    "            ftraj = os.path.join(data_dir, 'traj-' + dset + '-' + dat_suffix[dat_ix] + '.csv')\n",
    "        traj_df = pd.read_csv(ftraj)\n",
    "        total_nodes = traj_df[['trajID', 'trajLen']].copy().groupby('trajID').first().sum().values[0]\n",
    "        strs.append(dat_names[dat_ix])\n",
    "        strs.append(' & ' + '{:,}'.format(traj_df['poiID'].unique().shape[0]))\n",
    "        strs.append(' & ' + '{:,}'.format(traj_df['userID'].unique().shape[0]))\n",
    "        strs.append(' & ' + '{:,}'.format(traj_df['#photo'].sum()))\n",
    "        strs.append(' & ' + '{:,}'.format(traj_df['trajID'].unique().shape[0]))\n",
    "        strs.append(' & ' + '{:,}'.format(total_nodes))\n",
    "        strs.append(' \\\\\\\\ \\n')\n",
    "    strs.append('\\\\hline\\n')\n",
    "    strs.append('\\\\end{tabular}\\n')\n",
    "    strs.append('\\\\end{table*}\\n\\n')\n",
    "print(''.join(strs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latex Table for Recommendation Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate results filenames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_fname(dat_ix, type_ix, noloop, uspecific, alpha, C, KX):\n",
    "    assert(0 <= dat_ix < len(dat_suffix))\n",
    "    assert(0 <= type_ix < len(dat_types))\n",
    "    assert(isinstance(noloop, bool))\n",
    "    assert(isinstance(uspecific, bool))\n",
    "    assert(0 < alpha < 1)\n",
    "    alpha_str = str(alpha).replace('.', '_') + '-'\n",
    "    C_str = 'C' + str(C) + '-'\n",
    "    KX_str = str(KX) + 'X-'\n",
    "    \n",
    "    if noloop == True:\n",
    "        loop_str = 'noloop-'\n",
    "    else:\n",
    "        loop_str = ''\n",
    "    \n",
    "    type_str = dat_types[type_ix] + '-'\n",
    "    \n",
    "    if uspecific == True:\n",
    "        user_str = 'specific-'\n",
    "        suffix = KX_str + dat_suffix[dat_ix] + '.pkl'\n",
    "    else:\n",
    "        user_str = 'agnostic-'\n",
    "        suffix = dat_suffix[dat_ix] + '.pkl'\n",
    "    \n",
    "    fname = loop_str + type_str + user_str\n",
    "    frank = os.path.join(data_recsys, 'rank-' + fname + suffix)\n",
    "    ftran = os.path.join(data_recsys, 'tran-' + fname + suffix)\n",
    "    fcomb = os.path.join(data_recsys, 'comb-' + fname + alpha_str + suffix)\n",
    "    fcrf  = os.path.join(data_recsys, 'crf-' + fname + C_str + suffix)\n",
    "    fcrf1  = os.path.join(data_recsys, 'crf1-' + fname + C_str + suffix)\n",
    "    frand  = os.path.join(data_recsys, 'rand-' + fname + C_str + suffix)\n",
    "    fijcai = os.path.join(data_ijcai, 'ijcai-' + dat_suffix[dat_ix] + '.pkl')\n",
    "    return frank, ftran, fcomb, fcrf, fcrf1, frand, fijcai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gen_fname(1, 0, True, False, 0.5, 1, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the F1 score for recommended trajectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_F1(seq_act, seq_rec):\n",
    "    '''Compute recall, precision and F1 when trajectories contain sub-tours'''\n",
    "    assert(len(seq_act) > 0)\n",
    "    assert(len(seq_rec) > 0)\n",
    "    match_tags = np.zeros(len(seq_act), dtype=np.bool)\n",
    "    for poi in seq_rec:\n",
    "        for j in range(len(seq_act)):\n",
    "            if match_tags[j] == False and poi == seq_act[j]:\n",
    "                match_tags[j] = True\n",
    "                break\n",
    "    intersize = np.nonzero(match_tags)[0].shape[0]\n",
    "    recall = intersize / len(seq_act)\n",
    "    precision = intersize / len(seq_rec)\n",
    "    F1 = 2 * precision * recall / (precision + recall)\n",
    "    return F1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load results data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_results(dat_ix, type_ix, alpha, C, KX, uspecific):\n",
    "    assert(0 <= dat_ix < len(dat_suffix))\n",
    "    assert(0 <= type_ix < len(dat_types))\n",
    "    assert(0 < alpha < 1)\n",
    "    assert(isinstance(uspecific, bool))\n",
    "    \n",
    "    if uspecific == True:\n",
    "        noloop = False\n",
    "    else:\n",
    "        noloop = True\n",
    "    \n",
    "    frank, ftran, fcomb, fcrf, fcrf1, frand, fijcai = gen_fname(dat_ix, type_ix, noloop, uspecific, alpha, C, KX)\n",
    "    #print(frank)\n",
    "    assert(os.path.exists(frank))\n",
    "    #print(ftran)\n",
    "    assert(os.path.exists(ftran))\n",
    "    #print(fcomb)\n",
    "    assert(os.path.exists(fcomb))\n",
    "    #print(fcrf)\n",
    "    assert(os.path.exists(fcrf))\n",
    "    #print(fcrf1)\n",
    "    assert(os.path.exists(fcrf1))\n",
    "    #print(frand)\n",
    "    assert(os.path.exists(frand))\n",
    "    #print(fijcai)\n",
    "    assert(os.path.exists(fijcai))\n",
    "\n",
    "\n",
    "    # load results data\n",
    "    recdict_rank = pickle.load(open(frank, 'rb'))\n",
    "    recdict_tran = pickle.load(open(ftran, 'rb'))\n",
    "    recdict_comb = pickle.load(open(fcomb, 'rb'))\n",
    "    recdict_crf  = pickle.load(open(fcrf,  'rb'))\n",
    "    recdict_crf1 = pickle.load(open(fcrf1, 'rb'))\n",
    "    recdict_rand = pickle.load(open(frand, 'rb'))\n",
    "    recdict_ijcai = pickle.load(open(fijcai, 'rb'))\n",
    "    \n",
    "    return recdict_rank, recdict_tran, recdict_comb, recdict_crf, recdict_crf1, recdict_rand, recdict_ijcai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate F1-scores from loaded results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_metrics(recdict_rank, recdict_tran, recdict_comb, recdict_crf, recdict_crf1, recdict_ijcai, func):\n",
    "    assert(isinstance(func, types.FunctionType))\n",
    "    \n",
    "    # compute F1\n",
    "    rank1 = []  # rank pop\n",
    "    rank2 = []  # rank feature\n",
    "    for key in sorted(recdict_rank.keys()):\n",
    "        rank1.append(func(recdict_rank[key]['REAL'], recdict_rank[key]['REC_POP']))\n",
    "        rank2.append(func(recdict_rank[key]['REAL'], recdict_rank[key]['REC_FEATURE']))\n",
    "    \n",
    "    tran1 = []  # transition DP\n",
    "    tran2 = []  # transition ILP\n",
    "    for key in sorted(recdict_tran.keys()):\n",
    "        tran1.append(func(recdict_tran[key]['REAL'], recdict_tran[key]['REC_DP']))\n",
    "        tran2.append(func(recdict_tran[key]['REAL'], recdict_tran[key]['REC_ILP']))\n",
    "\n",
    "    comb1 = []  # combine rank and transition DP\n",
    "    comb2 = []  # combine rank and transition ILP\n",
    "    for key in sorted(recdict_comb.keys()):\n",
    "        comb1.append(func(recdict_comb[key]['REAL'], recdict_comb[key]['REC_DP']))\n",
    "        comb2.append(func(recdict_comb[key]['REAL'], recdict_comb[key]['REC_ILP']))\n",
    "        \n",
    "    crf = []   # structured prediction\n",
    "    for key in sorted(recdict_crf.keys()):\n",
    "        crf.append(func(recdict_crf[key]['REAL'], recdict_crf[key]['REC_CRF']))\n",
    "    \n",
    "    crf1 = []   # structured prediction\n",
    "    for key in sorted(recdict_crf1.keys()):\n",
    "        crf1.append(func(recdict_crf1[key]['REAL'], recdict_crf1[key]['REC_CRF']))\n",
    "        \n",
    "    rand = []   # structured prediction\n",
    "    for key in sorted(recdict_rand.keys()):\n",
    "        rand.append(func(recdict_rand[key]['REAL'], recdict_rand[key]['REC_RAND']))\n",
    "    \n",
    "    ijcai05T = []   # IJCAI method\n",
    "    ijcai10T = []   # IJCAI method\n",
    "    ijcai05L = []   # IJCAI method\n",
    "    ijcai10L = []   # IJCAI method\n",
    "    for key in sorted(recdict_ijcai.keys()):\n",
    "        ijcai05T.append(func(recdict_ijcai[key]['REAL'], recdict_crf1[key]['REC05T']))\n",
    "        ijcai10T.append(func(recdict_ijcai[key]['REAL'], recdict_crf1[key]['REC10T']))\n",
    "        ijcai05L.append(func(recdict_ijcai[key]['REAL'], recdict_crf1[key]['REC05L']))\n",
    "        ijcai10L.append(func(recdict_ijcai[key]['REAL'], recdict_crf1[key]['REC10L']))        \n",
    "    \n",
    "    # compute mean and std of F1\n",
    "    metrics = [rand, ijcai05T, ijcai10T, ijcai05L, ijcai10L, rank1, rank2, tran1, tran2, comb1, comb2, crf, crf1]\n",
    "    means = [np.mean(x) for x in metrics]\n",
    "    stds  = [np.std(x)  for x in metrics]\n",
    "    \n",
    "    return means, stds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Latex tables from calculated metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_latex_table(mean_df, std_df, ismax_df, type_ix, uspecific):\n",
    "    assert(isinstance(uspecific, bool))\n",
    "    if dat_types[type_ix] == 'all': \n",
    "        dstr = 'of all trajectories without loops'\n",
    "        ustr = 'user agnostic setting'\n",
    "    if dat_types[type_ix] == 'nofew': \n",
    "        dstr = 'of users with more than 5 (including 5) trajectories with loops'\n",
    "        ustr = 'user specific setting'\n",
    "\n",
    "    strs = []\n",
    "    strs.append('\\\\begin{table*}\\n')\n",
    "    strs.append('\\\\centering\\n')\n",
    "    strs.append('\\\\caption{Experimental Results: ' + ustr + ' ' + dstr + '}\\n')\n",
    "    #strs.append('\\\\small\\n')\n",
    "    strs.append('\\\\begin{tabular}{l|' + (F1mean_df.shape[1])*'c' + '} \\\\hline\\n')\n",
    "    for col in F1mean_df.columns:\n",
    "        strs.append(' & ' + col)\n",
    "    strs.append(' \\\\\\\\ \\\\hline\\n')\n",
    "    for ix in F1mean_df.index:\n",
    "        for j in range(F1mean_df.shape[1]):\n",
    "            if j == 0: strs.append(ix + ' ')\n",
    "            jx = F1mean_df.columns[j]\n",
    "            strs.append('& $')\n",
    "            if ismax_df.loc[ix, jx] == True: strs.append('\\\\mathbf{')\n",
    "            strs.append('%.3f' % F1mean_df.loc[ix, jx] + '\\\\pm' + '%.3f' % F1std_df.loc[ix, jx])\n",
    "            if ismax_df.loc[ix, jx] == True: strs.append('}')\n",
    "            strs.append('$ ')\n",
    "        strs.append('\\\\\\\\\\n')\n",
    "    strs.append('\\\\hline\\n')\n",
    "    strs.append('\\\\end{tabular}\\n')\n",
    "    strs.append('\\\\end{table*}\\n')\n",
    "    return ''.join(strs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple method to evaluate POI visiting order by adapting [Kendau's tau](https://en.wikipedia.org/wiki/Kendall_rank_correlation_coefficient)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calc_Tau(seq_act, seq_rec):\n",
    "    \"\"\"\n",
    "    NOTE: tau-a version seems to be more reasonable for evaluating visiting order of POIs.\n",
    "    An adaptation of Kendall's tau-b: https://en.wikipedia.org/wiki/Kendall_rank_correlation_coefficient#Tau-b\n",
    "    tau = (nc - nd - nn) / sqrt((n0 - n1)*(n0 - n2))\n",
    "    where:\n",
    "    nc: #concordant pairs (pair order is defined by the order of POIs in seq_act)\n",
    "    nd: #discordant pairs, for POIs in seq_rec, counting only those that also in seq_act\n",
    "    nn: #non-existent combination, i.e., combinations didn't appear in seq_act\n",
    "    n0: n(n-1)/2, n = len(seq_act)\n",
    "    n1: #ties in the first group  (i.e., seq_act), 0 here as seq_act didn't contain loops\n",
    "    n2: #ties in the second group (i.e., seq_rec), only counting those appeared in seq_act\n",
    "    after simplification,\n",
    "    tau = (nc - nd1) / sqrt(n0*(n0 - n2))\n",
    "    where nd1 = nd + nn\n",
    "    \"\"\"\n",
    "    assert(len(seq_act) == len(seq_rec))\n",
    "    assert(len(seq_act) > 0)\n",
    "    assert(len(seq_act) == len(set(seq_act))) # no loops in seq_act\n",
    "    n = len(seq_act)\n",
    "    n0 = n*(n-1) / 2\n",
    "    \n",
    "    # seq_act determines the correct visiting order\n",
    "    order_df = pd.DataFrame(data=np.zeros((n, n), dtype=np.bool), columns=seq_act, index=seq_act)\n",
    "    for i in range(n):\n",
    "        poi1 = seq_act[i]\n",
    "        for j in range(i+1, n):\n",
    "            poi2 = seq_act[j]\n",
    "            order_df.loc[poi1, poi2] = True\n",
    "            \n",
    "    nc, nd1, n2 = 0, 0, 0\n",
    "    for i in range(n):\n",
    "        poi1 = seq_rec[i]\n",
    "        for j in range(i+1, n):\n",
    "            poi2 = seq_rec[j]\n",
    "            if poi1 in seq_act and poi2 in seq_act:\n",
    "                if poi1 != poi2:\n",
    "                    if order_df.loc[poi1, poi2] == True: nc += 1\n",
    "                    else: nd1 += 1\n",
    "                #else: n2 += 1\n",
    "            #else: nd1 += 1 # combinations didn't appear in seq_act\n",
    "    #return (nc - nd1) / np.sqrt(n0*(n0 - n2))\n",
    "    return (nc - nd1) / n0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check: function `calc_Tau` should give the same result as `scipy.stats.kendalltau` if the first argument is an array of number in *descending* order and all numbers in the second argument appear in the first argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import kendalltau\n",
    "x = [3, 2, 1]\n",
    "#y = [3, 2, 1]\n",
    "#y = [1, 2, 3]\n",
    "y = [3, 1, 2]\n",
    "#y = [1, 1, 2]\n",
    "#y = [1, 2, 1]\n",
    "tau = calc_Tau(x, y)\n",
    "ret = kendalltau(x, y)\n",
    "print(tau)\n",
    "print(ret[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = [19, 3, 5, 6]\n",
    "#y = [19, 3, 5, 6]\n",
    "#y = [19, 3, 1, 6]\n",
    "y = [19, 1, 5, 6]\n",
    "#y = [19, 3, 3, 6]\n",
    "#y = [19, 5, 5, 6]\n",
    "#y = [19, 19, 5, 6]\n",
    "#y = [19, 3, 6, 6]\n",
    "#y = [19, 6, 6, 6]\n",
    "#y = [19, 1, 2, 6]\n",
    "#y = [19, 5, 3, 6]\n",
    "calc_Tau(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "calc_Tau([5, 3, 9], [5, 1, 9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dict1 = pickle.load(open('data/data-ijcai15/ijcai-Edin.pkl', 'rb'))\n",
    "metrics = [calc_Tau(dict1[x]['REAL'], dict1[x]['REC10L']) for x in dict1.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(np.mean(metrics), np.std(metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate evaluation data tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "KX = 100  # 100 folds in user specific setting\n",
    "alpha = 0.5\n",
    "C = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "func = calc_F1\n",
    "#func = calc_Tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if func == calc_Tau: methods = [methods[0]] + methods[3:]\n",
    "\n",
    "for type_ix in range(len(dat_types)):\n",
    "    mean_df = pd.DataFrame(data=np.zeros((len(methods), len(dat_names)), dtype=np.float), \\\n",
    "                           columns=dat_names, index=methods)\n",
    "    std_df  = pd.DataFrame(data=np.zeros((len(methods), len(dat_names)), dtype=np.float), \\\n",
    "                           columns=dat_names, index=methods)\n",
    "    \n",
    "    if dat_types[type_ix] == 'all':\n",
    "        uspecific = False\n",
    "    if dat_types[type_ix] == 'nofew':\n",
    "        uspecific = True\n",
    "        \n",
    "    for dat_ix in range(len(dat_suffix)):\n",
    "        recdict_rank, recdict_tran, recdict_comb, recdict_crf, recdict_crf1, recdict_ijcai = \\\n",
    "        load_results(dat_ix, type_ix, alpha, C, KX, uspecific)\n",
    "        means, stds = calc_metrics(recdict_rank, recdict_tran, recdict_comb, recdict_crf, recdict_crf1, recdict_ijcai, \\\n",
    "                                   func)\n",
    "        \n",
    "        assert(len(means) == len(stds) == len(methods))\n",
    "        mean_df[dat_names[dat_ix]] = means\n",
    "        std_df[dat_names[dat_ix]]  = stds\n",
    "        \n",
    "    ismax_df  = pd.DataFrame(data=np.zeros(mean_df.shape, dtype=np.bool), \\\n",
    "                             columns=mean_df.columns, index=mean_df.index)\n",
    "    for col in ismax_df.columns:\n",
    "        maxix = mean_df[col].argmax()\n",
    "        ismax_df.loc[maxix, col] = True\n",
    "        \n",
    "    strs = gen_latex_table(mean_df, std_df, ismax_df, type_ix, uspecific)\n",
    "    \n",
    "    print(strs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters Tuning Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: **POI popularity** used here is defined as *the number of distinct users* that visited the POI, which is not affected by user specific upsampling of trajectories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dstype = dat_types[2]\n",
    "dat_ix = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "KXs = [1, 2, 4, 8, 10, 20, 50, 100]\n",
    "ALPHAs = [.1, .2, .3, .4, .5, .6, .7, .8, .9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Methods based on ranking and transition matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "methods_F1mean = np.zeros((4, len(KXs)), dtype=np.float)\n",
    "methods_F1std = np.zeros((4, len(KXs)), dtype=np.float)\n",
    "alphastr = str(0.5).replace('.', '_') + '-'\n",
    "for j in range(len(KXs)):\n",
    "    kx = KXs[j]\n",
    "    kxstr = str(kx) + 'X-'\n",
    "    recdict_rank, recdict_tran, recdict_comb = load_results(dstype, dat_ix, kxstr, alphastr, uspecific=True)\n",
    "    F1mean, F1std = calc_metrics(recdict_rank, recdict_tran, recdict_comb)\n",
    "    for method_ix in [0, 1, 2, 3]:\n",
    "        methods_F1mean[method_ix, j] = F1mean[method_ix]\n",
    "        methods_F1std[method_ix, j] = F1std[method_ix]\n",
    "\n",
    "plt.figure(figsize=[8, 6])\n",
    "plt.suptitle('Dataset: %s' % datnames[dat_ix], y=0.95, fontsize=12)\n",
    "for k in [0, 1, 2, 3]:\n",
    "    ax = plt.subplot(2, 2, k+1)\n",
    "    plt.errorbar(KXs, methods_F1mean[k], yerr=methods_F1std[k])\n",
    "    maxix = np.argmax(methods_F1mean[k])\n",
    "    plt.plot(KXs[maxix], methods_F1mean[k, maxix], marker='o', markersize=10, markerfacecolor='m', markeredgewidth=0)\n",
    "    plt.xlim([0.9, 109])\n",
    "    plt.ylim([0, 1.0])\n",
    "    plt.title('%s, Best_F1: %.3f' % (methods[k], methods_F1mean[k, maxix]), y=0.1)\n",
    "    plt.xscale('log')\n",
    "    if k > 1: plt.xlabel('Folds')\n",
    "    if k % 2 == 0: plt.ylabel('F1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Methods combine ranking with transition matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for method_ix in [4, 5]:\n",
    "    method_F1mean = np.zeros((len(ALPHAs), len(KXs)), dtype=np.float)\n",
    "    method_F1std = np.zeros((len(ALPHAs), len(KXs)), dtype=np.float)\n",
    "    for i in range(len(ALPHAs)):\n",
    "        alpha = ALPHAs[i]\n",
    "        alphastr = str(alpha).replace('.', '_') + '-'\n",
    "        for j in range(len(KXs)):\n",
    "            kx = KXs[j]\n",
    "            kxstr = str(kx) + 'X-'\n",
    "            recdict_rank, recdict_tran, recdict_comb = load_results(dstype, dat_ix, kxstr, alphastr, uspecific=True)\n",
    "            F1mean, F1std = calc_metrics(recdict_rank, recdict_tran, recdict_comb)\n",
    "            method_F1mean[i, j] = F1mean[method_ix]\n",
    "            method_F1std[i, j] = F1std[method_ix]\n",
    "\n",
    "    plt.figure(figsize=[12, 9])\n",
    "    plt.suptitle('Dataset: %s, Method: %s' % (datnames[dat_ix], methods[method_ix]), y=0.95, fontsize=12)\n",
    "    for k in range(len(ALPHAs)):\n",
    "        ax = plt.subplot(3, 3, k+1)\n",
    "        plt.errorbar(KXs, method_F1mean[k], yerr=method_F1std[k])\n",
    "        maxix = np.argmax(method_F1mean[k])\n",
    "        plt.plot(KXs[maxix], method_F1mean[k, maxix], marker='o', markersize=10, markerfacecolor='m', markeredgewidth=0)\n",
    "        plt.xlim([0.9, 109])\n",
    "        plt.ylim([0, 1.0])\n",
    "        plt.title('$\\\\alpha$ = %.1f, Best_F1: %.3f' % (ALPHAs[k], method_F1mean[k, maxix]), y=0.1)\n",
    "        plt.xscale('log')\n",
    "        if k > 5: plt.xlabel('Folds')\n",
    "        if k % 3 == 0: plt.ylabel('F1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
