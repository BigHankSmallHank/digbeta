{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse Experimental Results & Generate Latex Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import os, pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = 'data/data-recsys16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dat_suffix = ['Osak', 'Glas', 'Edin', 'Toro', 'Melb']\n",
    "dat_names = ['Osaka', 'Glasgow', 'Edinburgh', 'Toronto', 'Melbourne']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dat_types = ['all', 'nofew']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "methods = ['PersTour', 'RankP', 'RankF', 'MC-DP', 'MC-ILP', 'Prop-DP', 'Prop-ILP', 'CRF', 'CRF1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "F1_ijcai_mean = [0.686, 0.801, 0.656, 0.720, 0]\n",
    "F1_ijcai_std  = [0.233, 0.214, 0.223, 0.215, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latex Table for Dataset Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table*}\n",
      "\\centering\n",
      "\\caption{Dataset of all trajectories without loops}\n",
      "\\label{table:data:all}\n",
      "\\begin{tabular}{lrrrrr} \\hline\n",
      "\\textbf{City} & \\textbf{\\#POIs} & \\textbf{\\#Users} & \\textbf{\\#POI Visits} & \\textbf{\\#Trajectories} & \\textbf{\\#TotalNodes} \\\\ \\hline\n",
      "Osaka & 27 & 450 & 7,747 & 1,115 & 1,372 \\\\ \n",
      "Glasgow & 27 & 601 & 11,434 & 2,227 & 2,749 \\\\ \n",
      "Edinburgh & 28 & 1,454 & 33,944 & 5,028 & 7,853 \\\\ \n",
      "Toronto & 29 & 1,395 & 39,419 & 6,057 & 7,607 \\\\ \n",
      "Melbourne & 85 & 1,000 & 23,995 & 5,106 & 7,246 \\\\ \n",
      "\\hline\n",
      "\\end{tabular}\n",
      "\\end{table*}\n",
      "\n",
      "\\begin{table*}\n",
      "\\centering\n",
      "\\caption{Dataset of users with more than 5 (including 5) trajectories with loops}\n",
      "\\label{table:data:nofew}\n",
      "\\begin{tabular}{lrrrrr} \\hline\n",
      "\\textbf{City} & \\textbf{\\#POIs} & \\textbf{\\#Users} & \\textbf{\\#POI Visits} & \\textbf{\\#Trajectories} & \\textbf{\\#TotalNodes} \\\\ \\hline\n",
      "Osaka & 24 & 40 & 2,471 & 473 & 577 \\\\ \n",
      "Glasgow & 25 & 94 & 7,116 & 1,433 & 1,711 \\\\ \n",
      "Edinburgh & 28 & 192 & 19,149 & 2,901 & 4,420 \\\\ \n",
      "Toronto & 29 & 248 & 27,105 & 4,113 & 5,185 \\\\ \n",
      "Melbourne & 85 & 242 & 15,833 & 3,759 & 5,223 \\\\ \n",
      "\\hline\n",
      "\\end{tabular}\n",
      "\\end{table*}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "strs = []\n",
    "for dset in dat_types:\n",
    "    if dset == 'all':     \n",
    "        title = 'of all trajectories without loops'\n",
    "        noloop = True\n",
    "    if dset == 'nofew':   \n",
    "        title = 'of users with more than 5 (including 5) trajectories with loops'\n",
    "        noloop = False\n",
    "    strs.append('\\\\begin{table*}\\n')\n",
    "    strs.append('\\\\centering\\n')\n",
    "    strs.append('\\\\caption{Dataset ' + title + '}\\n')\n",
    "    strs.append('\\\\label{table:data:' + dset + '}\\n')\n",
    "    #strs.append('\\\\small\\n')\n",
    "    strs.append('\\\\begin{tabular}{' + 'l' + 5*'r' + '} \\\\hline\\n')\n",
    "    strs.append('\\\\textbf{City} & \\\\textbf{\\\\#POIs} & \\\\textbf{\\\\#Users} & ')\n",
    "    strs.append('\\\\textbf{\\\\#POI Visits} & \\\\textbf{\\\\#Trajectories} & \\\\textbf{\\\\#TotalNodes} \\\\\\\\ \\\\hline\\n')\n",
    "    \n",
    "    for dat_ix in range(len(dat_names)):\n",
    "        if noloop == True:\n",
    "            ftraj = os.path.join(data_dir, 'traj-noloop-' + dset + '-' + dat_suffix[dat_ix] + '.csv')\n",
    "        else:\n",
    "            ftraj = os.path.join(data_dir, 'traj-' + dset + '-' + dat_suffix[dat_ix] + '.csv')\n",
    "        traj_df = pd.read_csv(ftraj)\n",
    "        total_nodes = traj_df[['trajID', 'trajLen']].copy().groupby('trajID').first().sum().values[0]\n",
    "        strs.append(dat_names[dat_ix])\n",
    "        strs.append(' & ' + '{:,}'.format(traj_df['poiID'].unique().shape[0]))\n",
    "        strs.append(' & ' + '{:,}'.format(traj_df['userID'].unique().shape[0]))\n",
    "        strs.append(' & ' + '{:,}'.format(traj_df['#photo'].sum()))\n",
    "        strs.append(' & ' + '{:,}'.format(traj_df['trajID'].unique().shape[0]))\n",
    "        strs.append(' & ' + '{:,}'.format(total_nodes))\n",
    "        strs.append(' \\\\\\\\ \\n')\n",
    "    strs.append('\\\\hline\\n')\n",
    "    strs.append('\\\\end{tabular}\\n')\n",
    "    strs.append('\\\\end{table*}\\n\\n')\n",
    "print(''.join(strs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latex Table for Recommendation Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate results filenames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_fname(data_dir, dat_suffix, dat_ix, dat_types, type_ix, noloop, uspecific, alpha, C, KX):\n",
    "    assert(0 <= dat_ix < len(dat_suffix))\n",
    "    assert(0 <= type_ix < len(dat_types))\n",
    "    assert(isinstance(noloop, bool))\n",
    "    assert(isinstance(uspecific, bool))\n",
    "    assert(0 < alpha < 1)\n",
    "    alpha_str = str(alpha).replace('.', '_') + '-'\n",
    "    C_str = 'C' + str(C) + '-'\n",
    "    KX_str = str(KX) + 'X-'\n",
    "    \n",
    "    if noloop == True:\n",
    "        loop_str = 'noloop-'\n",
    "    else:\n",
    "        loop_str = ''\n",
    "    \n",
    "    type_str = dat_types[type_ix] + '-'\n",
    "    \n",
    "    if uspecific == True:\n",
    "        user_str = 'specific-'\n",
    "        suffix = KX_str + dat_suffix[dat_ix] + '.pkl'\n",
    "    else:\n",
    "        user_str = 'agnostic-'\n",
    "        suffix = dat_suffix[dat_ix] + '.pkl'\n",
    "    \n",
    "    fname = loop_str + type_str + user_str\n",
    "    frank = os.path.join(data_dir, 'rank-' + fname + suffix)\n",
    "    ftran = os.path.join(data_dir, 'tran-' + fname + suffix)\n",
    "    fcomb = os.path.join(data_dir, 'comb-' + fname + alpha_str + suffix)\n",
    "    fcrf  = os.path.join(data_dir, 'crf-' + fname + C_str + suffix)\n",
    "    fcrf1  = os.path.join(data_dir, 'crf1-' + fname + C_str + suffix)\n",
    "    return frank, ftran, fcomb, fcrf, fcrf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('data/data-recsys16/rank-nofew-agnostic-Glas.pkl',\n",
       " 'data/data-recsys16/tran-nofew-agnostic-Glas.pkl',\n",
       " 'data/data-recsys16/comb-nofew-agnostic-0_5-Glas.pkl',\n",
       " 'data/data-recsys16/crf-nofew-agnostic-C1-Glas.pkl',\n",
       " 'data/data-recsys16/crf1-nofew-agnostic-C1-Glas.pkl')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_fname(data_dir, dat_suffix, 1, dat_types, 1, False, False, 0.5, 1, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the F1 score for recommended trajectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_F1(seq_act, seq_rec):\n",
    "    '''Compute recall, precision and F1 when trajectories contain sub-tours'''\n",
    "    assert(len(seq_act) > 0)\n",
    "    assert(len(seq_rec) > 0)\n",
    "    match_tags = np.zeros(len(seq_act), dtype=np.bool)\n",
    "    for poi in seq_rec:\n",
    "        for j in range(len(seq_act)):\n",
    "            if match_tags[j] == False and poi == seq_act[j]:\n",
    "                match_tags[j] = True\n",
    "                break\n",
    "    intersize = np.nonzero(match_tags)[0].shape[0]\n",
    "    recall = intersize / len(seq_act)\n",
    "    precision = intersize / len(seq_rec)\n",
    "    F1 = 2 * precision * recall / (precision + recall)\n",
    "    return F1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load results data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_results(dat_ix, type_ix, alpha, C, KX, uspecific):\n",
    "    assert(0 <= dat_ix < len(dat_suffix))\n",
    "    assert(0 <= type_ix < len(dat_types))\n",
    "    assert(0 < alpha < 1)\n",
    "    assert(isinstance(uspecific, bool))\n",
    "    \n",
    "    if uspecific == True:\n",
    "        noloop = False\n",
    "    else:\n",
    "        noloop = True\n",
    "    \n",
    "    frank, ftran, fcomb, fcrf, fcrf1 = gen_fname(data_dir, dat_suffix, dat_ix, dat_types, type_ix, \\\n",
    "                                                 noloop, uspecific, alpha, C, KX)\n",
    "    #print(frank)\n",
    "    assert(os.path.exists(frank))\n",
    "    #print(ftran)\n",
    "    assert(os.path.exists(ftran))\n",
    "    #print(fcomb)\n",
    "    assert(os.path.exists(fcomb))\n",
    "    #print(fcrf)\n",
    "    assert(os.path.exists(fcrf))\n",
    "    #print(fcrf1)\n",
    "    assert(os.path.exists(fcrf1))\n",
    "\n",
    "    # load results data\n",
    "    recdict_rank = pickle.load(open(frank, 'rb'))\n",
    "    recdict_tran = pickle.load(open(ftran, 'rb'))\n",
    "    recdict_comb = pickle.load(open(fcomb, 'rb'))\n",
    "    recdict_crf  = pickle.load(open(fcrf,  'rb'))\n",
    "    recdict_crf1 = pickle.load(open(fcrf1, 'rb'))\n",
    "    \n",
    "    return recdict_rank, recdict_tran, recdict_comb, recdict_crf, recdict_crf1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate F1-scores from loaded results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_metrics(recdict_rank, recdict_tran, recdict_comb, recdict_crf, recdict_crf1):\n",
    "    # compute F1\n",
    "    F1_rank1 = []  # rank pop\n",
    "    F1_rank2 = []  # rank feature\n",
    "    for key in sorted(recdict_rank.keys()):\n",
    "        F1_rank1.append(calc_F1(recdict_rank[key]['REAL'], recdict_rank[key]['REC_POP']))\n",
    "        F1_rank2.append(calc_F1(recdict_rank[key]['REAL'], recdict_rank[key]['REC_FEATURE']))\n",
    "    \n",
    "    F1_tran1 = []  # transition DP\n",
    "    F1_tran2 = []  # transition ILP\n",
    "    for key in sorted(recdict_tran.keys()):\n",
    "        F1_tran1.append(calc_F1(recdict_tran[key]['REAL'], recdict_tran[key]['REC_DP']))\n",
    "        F1_tran2.append(calc_F1(recdict_tran[key]['REAL'], recdict_tran[key]['REC_ILP']))\n",
    "\n",
    "    F1_comb1 = []  # combine rank and transition DP\n",
    "    F1_comb2 = []  # combine rank and transition ILP\n",
    "    for key in sorted(recdict_comb.keys()):\n",
    "        F1_comb1.append(calc_F1(recdict_comb[key]['REAL'], recdict_comb[key]['REC_DP']))\n",
    "        F1_comb2.append(calc_F1(recdict_comb[key]['REAL'], recdict_comb[key]['REC_ILP']))\n",
    "        \n",
    "    F1_crf = []   # structured prediction\n",
    "    for key in sorted(recdict_crf.keys()):\n",
    "        F1_crf.append(calc_F1(recdict_crf[key]['REAL'], recdict_crf[key]['REC_CRF']))\n",
    "    \n",
    "    F1_crf1 = []   # structured prediction\n",
    "    for key in sorted(recdict_crf1.keys()):\n",
    "        F1_crf1.append(calc_F1(recdict_crf1[key]['REAL'], recdict_crf1[key]['REC_CRF']))\n",
    "    \n",
    "    # compute mean and std of F1\n",
    "    F1_mean = [np.mean(x) for x in [F1_rank1, F1_rank2, F1_tran1, F1_tran2, F1_comb1, F1_comb2, F1_crf, F1_crf1]]\n",
    "    F1_std  = [np.std(x)  for x in [F1_rank1, F1_rank2, F1_tran1, F1_tran2, F1_comb1, F1_comb2, F1_crf, F1_crf1]]\n",
    "    \n",
    "    return F1_mean, F1_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Latex tables from calculated metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_latex_table(F1mean_df, F1std_df, ismax_df, type_ix, uspecific):\n",
    "    assert(isinstance(uspecific, bool))\n",
    "    if dat_types[type_ix] == 'all': \n",
    "        dstr = 'of all trajectories without loops'\n",
    "        ustr = 'user agnostic setting'\n",
    "    if dat_types[type_ix] == 'nofew': \n",
    "        dstr = 'of users with more than 5 (including 5) trajectories with loops'\n",
    "        ustr = 'user specific setting'\n",
    "\n",
    "    strs = []\n",
    "    strs.append('\\\\begin{table*}\\n')\n",
    "    strs.append('\\\\centering\\n')\n",
    "    strs.append('\\\\caption{Experimental Results: ' + ustr + ' ' + dstr + '}\\n')\n",
    "    #strs.append('\\\\small\\n')\n",
    "    strs.append('\\\\begin{tabular}{l|' + (F1mean_df.shape[1])*'c' + '} \\\\hline\\n')\n",
    "    for col in F1mean_df.columns:\n",
    "        strs.append(' & ' + col)\n",
    "    strs.append(' \\\\\\\\ \\\\hline\\n')\n",
    "    for ix in F1mean_df.index:\n",
    "        for j in range(F1mean_df.shape[1]):\n",
    "            if j == 0: strs.append(ix + ' ')\n",
    "            jx = F1mean_df.columns[j]\n",
    "            strs.append('& $')\n",
    "            if ismax_df.loc[ix, jx] == True: strs.append('\\\\mathbf{')\n",
    "            strs.append('%.3f' % F1mean_df.loc[ix, jx] + '\\\\pm' + '%.3f' % F1std_df.loc[ix, jx])\n",
    "            if ismax_df.loc[ix, jx] == True: strs.append('}')\n",
    "            strs.append('$ ')\n",
    "        strs.append('\\\\\\\\\\n')\n",
    "    strs.append('\\\\hline\\n')\n",
    "    strs.append('\\\\end{tabular}\\n')\n",
    "    strs.append('\\\\end{table*}\\n')\n",
    "    return ''.join(strs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "KX = 100  # 100 folds in user specific setting\n",
    "alpha = 0.5\n",
    "C = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table*}\n",
      "\\centering\n",
      "\\caption{Experimental Results: user agnostic setting of all trajectories without loops}\n",
      "\\begin{tabular}{l|ccccc} \\hline\n",
      " & Osaka & Glasgow & Edinburgh & Toronto & Melbourne \\\\ \\hline\n",
      "PersTour & $0.686\\pm0.233$ & $\\mathbf{0.801\\pm0.214}$ & $0.656\\pm0.223$ & $0.720\\pm0.215$ & $0.000\\pm0.000$ \\\\\n",
      "RankP & $0.663\\pm0.125$ & $0.744\\pm0.165$ & $0.701\\pm0.160$ & $0.678\\pm0.121$ & $0.607\\pm0.143$ \\\\\n",
      "RankF & $0.679\\pm0.113$ & $0.775\\pm0.168$ & $0.693\\pm0.154$ & $0.752\\pm0.167$ & $0.616\\pm0.142$ \\\\\n",
      "MC-DP & $0.680\\pm0.157$ & $0.716\\pm0.168$ & $0.628\\pm0.172$ & $0.661\\pm0.157$ & $0.558\\pm0.179$ \\\\\n",
      "MC-ILP & $0.706\\pm0.150$ & $0.734\\pm0.169$ & $0.678\\pm0.148$ & $0.688\\pm0.138$ & $0.582\\pm0.152$ \\\\\n",
      "Prop-DP & $0.699\\pm0.168$ & $0.738\\pm0.176$ & $0.646\\pm0.174$ & $0.690\\pm0.171$ & $0.690\\pm0.171$ \\\\\n",
      "Prop-ILP & $0.717\\pm0.158$ & $0.762\\pm0.170$ & $0.688\\pm0.153$ & $0.726\\pm0.152$ & $0.726\\pm0.152$ \\\\\n",
      "CRF & $0.686\\pm0.124$ & $0.721\\pm0.174$ & $0.645\\pm0.166$ & $0.711\\pm0.178$ & $0.571\\pm0.150$ \\\\\n",
      "CRF1 & $\\mathbf{0.762\\pm0.162}$ & $0.762\\pm0.162$ & $\\mathbf{0.762\\pm0.162}$ & $\\mathbf{0.762\\pm0.162}$ & $\\mathbf{0.762\\pm0.162}$ \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "\\end{table*}\n",
      "\n",
      "\\begin{table*}\n",
      "\\centering\n",
      "\\caption{Experimental Results: user specific setting of users with more than 5 (including 5) trajectories with loops}\n",
      "\\begin{tabular}{l|ccccc} \\hline\n",
      " & Osaka & Glasgow & Edinburgh & Toronto & Melbourne \\\\ \\hline\n",
      "PersTour & $0.686\\pm0.233$ & $\\mathbf{0.801\\pm0.214}$ & $0.656\\pm0.223$ & $0.720\\pm0.215$ & $0.000\\pm0.000$ \\\\\n",
      "RankP & $0.625\\pm0.136$ & $0.666\\pm0.158$ & $0.603\\pm0.130$ & $0.689\\pm0.150$ & $0.568\\pm0.145$ \\\\\n",
      "RankF & $0.679\\pm0.172$ & $0.772\\pm0.201$ & $0.647\\pm0.169$ & $0.737\\pm0.170$ & $0.576\\pm0.151$ \\\\\n",
      "MC-DP & $0.731\\pm0.195$ & $0.759\\pm0.172$ & $0.600\\pm0.175$ & $0.684\\pm0.156$ & $0.548\\pm0.178$ \\\\\n",
      "MC-ILP & $0.700\\pm0.189$ & $0.746\\pm0.197$ & $0.611\\pm0.154$ & $0.686\\pm0.142$ & $0.557\\pm0.156$ \\\\\n",
      "Prop-DP & $0.719\\pm0.171$ & $0.725\\pm0.177$ & $0.587\\pm0.176$ & $0.718\\pm0.160$ & $0.571\\pm0.185$ \\\\\n",
      "Prop-ILP & $0.700\\pm0.163$ & $0.744\\pm0.175$ & $0.614\\pm0.148$ & $0.714\\pm0.154$ & $0.583\\pm0.165$ \\\\\n",
      "CRF & $0.716\\pm0.110$ & $0.699\\pm0.159$ & $0.699\\pm0.159$ & $0.699\\pm0.159$ & $0.699\\pm0.159$ \\\\\n",
      "CRF1 & $\\mathbf{0.762\\pm0.162}$ & $0.762\\pm0.162$ & $\\mathbf{0.762\\pm0.162}$ & $\\mathbf{0.762\\pm0.162}$ & $\\mathbf{0.762\\pm0.162}$ \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "\\end{table*}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for type_ix in range(len(dat_types)):\n",
    "    F1mean_df = pd.DataFrame(data=np.zeros((len(methods), len(dat_names)), dtype=np.float), \\\n",
    "                                  columns=dat_names, index=methods)\n",
    "    F1std_df  = pd.DataFrame(data=np.zeros((len(methods), len(dat_names)), dtype=np.float), \\\n",
    "                                  columns=dat_names, index=methods)\n",
    "    \n",
    "    if dat_types[type_ix] == 'all':\n",
    "        uspecific = False\n",
    "    if dat_types[type_ix] == 'nofew':\n",
    "        uspecific = True\n",
    "        \n",
    "    for dat_ix in range(len(dat_suffix)):\n",
    "        recdict_rank, recdict_tran, recdict_comb, recdict_crf, recdict_crf1 = load_results(dat_ix, type_ix, \\\n",
    "                                                                                           alpha, C, KX, uspecific)\n",
    "        F1mean, F1std = calc_metrics(recdict_rank, recdict_tran, recdict_comb, recdict_crf, recdict_crf1)\n",
    "        \n",
    "        assert(len(F1mean) == len(F1std) == len(methods)-1)\n",
    "        F1mean_df[dat_names[dat_ix]] = [F1_ijcai_mean[dat_ix]] + F1mean\n",
    "        F1std_df[dat_names[dat_ix]] = [F1_ijcai_std[dat_ix]] + F1std\n",
    "        \n",
    "    ismax_df  = pd.DataFrame(data=np.zeros(F1mean_df.shape, dtype=np.bool), \\\n",
    "                             columns=F1mean_df.columns, index=F1mean_df.index)\n",
    "    for col in ismax_df.columns:\n",
    "        maxix = F1mean_df[col].argmax()\n",
    "        ismax_df.loc[maxix, col] = True\n",
    "        \n",
    "    strs = gen_latex_table(F1mean_df, F1std_df, ismax_df, type_ix, uspecific)\n",
    "    \n",
    "    print(strs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters Tuning Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: **POI popularity** used here is defined as *the number of distinct users* that visited the POI, which is not affected by user specific upsampling of trajectories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dstype = dat_types[2]\n",
    "dat_ix = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "KXs = [1, 2, 4, 8, 10, 20, 50, 100]\n",
    "ALPHAs = [.1, .2, .3, .4, .5, .6, .7, .8, .9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Methods based on ranking and transition matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "methods_F1mean = np.zeros((4, len(KXs)), dtype=np.float)\n",
    "methods_F1std = np.zeros((4, len(KXs)), dtype=np.float)\n",
    "alphastr = str(0.5).replace('.', '_') + '-'\n",
    "for j in range(len(KXs)):\n",
    "    kx = KXs[j]\n",
    "    kxstr = str(kx) + 'X-'\n",
    "    recdict_rank, recdict_tran, recdict_comb = load_results(dstype, dat_ix, kxstr, alphastr, uspecific=True)\n",
    "    F1mean, F1std = calc_metrics(recdict_rank, recdict_tran, recdict_comb)\n",
    "    for method_ix in [0, 1, 2, 3]:\n",
    "        methods_F1mean[method_ix, j] = F1mean[method_ix]\n",
    "        methods_F1std[method_ix, j] = F1std[method_ix]\n",
    "\n",
    "plt.figure(figsize=[8, 6])\n",
    "plt.suptitle('Dataset: %s' % datnames[dat_ix], y=0.95, fontsize=12)\n",
    "for k in [0, 1, 2, 3]:\n",
    "    ax = plt.subplot(2, 2, k+1)\n",
    "    plt.errorbar(KXs, methods_F1mean[k], yerr=methods_F1std[k])\n",
    "    maxix = np.argmax(methods_F1mean[k])\n",
    "    plt.plot(KXs[maxix], methods_F1mean[k, maxix], marker='o', markersize=10, markerfacecolor='m', markeredgewidth=0)\n",
    "    plt.xlim([0.9, 109])\n",
    "    plt.ylim([0, 1.0])\n",
    "    plt.title('%s, Best_F1: %.3f' % (methods[k], methods_F1mean[k, maxix]), y=0.1)\n",
    "    plt.xscale('log')\n",
    "    if k > 1: plt.xlabel('Folds')\n",
    "    if k % 2 == 0: plt.ylabel('F1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Methods combine ranking with transition matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for method_ix in [4, 5]:\n",
    "    method_F1mean = np.zeros((len(ALPHAs), len(KXs)), dtype=np.float)\n",
    "    method_F1std = np.zeros((len(ALPHAs), len(KXs)), dtype=np.float)\n",
    "    for i in range(len(ALPHAs)):\n",
    "        alpha = ALPHAs[i]\n",
    "        alphastr = str(alpha).replace('.', '_') + '-'\n",
    "        for j in range(len(KXs)):\n",
    "            kx = KXs[j]\n",
    "            kxstr = str(kx) + 'X-'\n",
    "            recdict_rank, recdict_tran, recdict_comb = load_results(dstype, dat_ix, kxstr, alphastr, uspecific=True)\n",
    "            F1mean, F1std = calc_metrics(recdict_rank, recdict_tran, recdict_comb)\n",
    "            method_F1mean[i, j] = F1mean[method_ix]\n",
    "            method_F1std[i, j] = F1std[method_ix]\n",
    "\n",
    "    plt.figure(figsize=[12, 9])\n",
    "    plt.suptitle('Dataset: %s, Method: %s' % (datnames[dat_ix], methods[method_ix]), y=0.95, fontsize=12)\n",
    "    for k in range(len(ALPHAs)):\n",
    "        ax = plt.subplot(3, 3, k+1)\n",
    "        plt.errorbar(KXs, method_F1mean[k], yerr=method_F1std[k])\n",
    "        maxix = np.argmax(method_F1mean[k])\n",
    "        plt.plot(KXs[maxix], method_F1mean[k, maxix], marker='o', markersize=10, markerfacecolor='m', markeredgewidth=0)\n",
    "        plt.xlim([0.9, 109])\n",
    "        plt.ylim([0, 1.0])\n",
    "        plt.title('$\\\\alpha$ = %.1f, Best_F1: %.3f' % (ALPHAs[k], method_F1mean[k, maxix]), y=0.1)\n",
    "        plt.xscale('log')\n",
    "        if k > 5: plt.xlabel('Folds')\n",
    "        if k % 3 == 0: plt.ylabel('F1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
