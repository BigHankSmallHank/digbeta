{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trajectory Recommendation with Active Learning\n",
    "==================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Problem Formulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Active Learning Formulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formulate trajectory recommendation as an active learning problem.\n",
    "- Example: a tuple (user, trajectory)\n",
    "- Label of example: binary\n",
    "   - Observed tuples (user, trajectory) (i.e. those we extracted from data) are labelled as positive\n",
    "   - Unobserved tuples (e.g. trajectories generated on the fly such as synthesize trajectories by enumeration) are unlabelled\n",
    "   - Tuples chosen to query a user will be labelled as positive/negative if the feedback from the user is positive/negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query strategies: \n",
    "given (start, end) and trajectory length $l$ for a specific user $u$, we'll select an example for user $u$ to label.\n",
    "- Compute the likelihood of trajectories that satisfy the (start, end) and length constraint, \n",
    "  sort these trajectories by likelihood\n",
    "- Choose a trajectory from the top $K$ (e.g. 5) trajectories with probability proportional to its likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: utilise user-specific features when selecting trajectory for user $u$ to label if there are trajectories of user $u$ in our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Bandit Formulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formulate trajectory recommendation as a contextual multi-armed bandit problem, the trade-off is recommendation with available POI/user features vs. query user preference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Arm: transition from current POI$_i$ to another POI$_j$, (allow sub-tours?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Context: transition features including POI category transition probabilities, POI popularity transition probabilities, distance of POI pair transition probabilities and user specific features (visit duration/frequency), available in [this notebook ](./traj_feature.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Reward: \n",
    "- [F1-scored](./ijcai15.ipynb#sec2.1) based metric, e.g. let the trajectory up to time $t$ (after choosing a certain arm) is `[p1, p2, p3]`, ground truth trajectories `[p1, p2, p3]` and `[p1, p2, p4]`, the reward is computed as \n",
    "\\begin{equation}\n",
    "max\\{F1([p1, p2, p3], [p1, p2, p3]), F1([p1, p2, p3], [p1, p2, p4])\\} = max\\{1.0, 0.667\\} = 1.0\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Visiting order based metric, e.g. let the trajectory up to time $t$ (after choosing a certain arm) is `[p1, p3, p2]`, ground truth trajectories `[p1, p2, p3]` and `[p1, p2, p4]`, \n",
    "with respect to trajectory `[p1, p2, p3]`, pair `(p1, p3)` in `[p1, p3, p2]` count because `p3` is visited after `p1`,\n",
    "similarly, pair `(p1, p2)` count but pair `(p3, p2)` does not count because `p3` is not visited before `p2` in trajectory `[p1, p2, p3]`, so the total number of pairs that counts is `2` and there are `3` pairs in total, the metric here is `2/3`. Similarly, the metric with respect to trajectory `[p1, p2, p4]` is `1/3` because there is only one pair, i.e. `(p1, p2)` among the `3` pairs count. The reward is computed as \n",
    "\\begin{equation}\n",
    "max\\{\\frac{2}{3}, \\frac{1}{3}\\} = \\frac{2}{3}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Metrics incorporating POI category, POI popularity, and the travel distance from the current POI, e.g. let the trajectory up to time $t$ (after choosing a certain arm) is `[p1, p3]`, and ground truth trajectory `[p1, p4]`, \n",
    "if `p3` and `p4` are of the same category as well as similar popularity (i.e. belong to the same popularity class after discretizing the POI popularity) and similar distance (i.e. same distance class after discretization) from the current POI, then the reward of arm `(p1, p3)` would be high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Regret: regret after $T$ trials is defined as \n",
    "\\begin{equation}\n",
    "R(T) = \\textbf{E}\\left[\\sum_t^T(\\text{optimal reward})_t\\right] - \\textbf{E}\\left[\\sum_t^T(\\text{actual reward})_t\\right]\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Sampling strategies: \n",
    "1. $\\epsilon$-greedy: choose arm (i.e. transition) of highest log likelihood with probability 1-$\\epsilon$, choose a random arm with probability $\\epsilon$.\n",
    "\n",
    "1. Thompson sampling: design a prior of arm's reward (uniform? gaussian? ...), compute likelihood like [this approach](./traj_MC.ipynb#sec4), an interesting [paper](http://www.research.rutgers.edu/~lihong/pub/Chapelle12Empirical.pdf).\n",
    "\n",
    "1. UCB-type strategies such as LinUCB introduced in [this paper](http://www.research.rutgers.edu/~lihong/pub/Li10Contextual.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Query: \n",
    "- query the user the selected arm, or\n",
    "- query users which POIs they prefer or what the characteristics (category/popularity/distance from current place) of POIs they prefer (show selected photos of these POIs?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given (start, end) and trajectory length $l$ for a specific user $u$, we'll select an example for user $u$ to label.\n",
    "- Compute the likelihood of trajectories that satisfy the (start, end) and length constraint, \n",
    "  sort these trajectories by likelihood\n",
    "- Recommend a trajectory from the top $K$ (e.g. 5) trajectories with probability proportional to its likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: utilise user-specific features when recommending trajectory for user $u$ if there are trajectories of user $u$ in our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Experiment for choosing formulation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
