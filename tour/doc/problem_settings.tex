\documentclass[11pt, a4paper]{article}
\usepackage{amsmath}
\usepackage{hyperref}
%\usepackage{mathpazo}
%\usepackage{libertine}
%\usepackage{newtxmath, newtxtext}
\usepackage{mathpazo, libertine}
\usepackage[a4paper, left=60pt, top=80pt, right=60pt, bottom=80pt]{geometry}

\title{Trajectory Recommendation with Active Learning}
\author{Dawei Chen}
\date{\today}

\begin{document}
\maketitle

\section{\textsc{Overview}}
Recommend trajectories for tourists using historical visiting traces (i.e. trajectories) extracted from geo-tagged Flickr photos 
as well as Place/Point of Interest (POI) extracted from Wikipedia articles.

\subsection{\textsc{Definition}}
For user $u$ and POI $p$, define $u$'s travel history and travel sequences, 
POI popularity, POI category and distance between POIs as follows\cite{lim15}:
\begin{itemize}
\item \textbf{Travel History}:
      \begin{equation*}
      S_u = \{(p_1, t_{p_1}^a, t_{p_1}^d), \dots, (p_n, t_{p_n}^a, t_{p_n}^d)\}
      \end{equation*}
      where $t_{p_i}^a$ is the arrival time and $t_{p_i}^d$ the departure time of user $u$ at POI $p_i$.
\item \textbf{Travel Sequences}: split $S_u$ if
      \begin{equation*}
      \lvert t_{p_i}^d - t_{p_{i+1}}^a \rvert > \tau ~(\text{e.g.}~ \tau = 8 ~\text{hours})
      \end{equation*}
\item \textbf{POI Popularity}:
      \begin{equation*}
      Pop(p) = \sum_{u \in U} \sum_{p_i \in S_u} \delta(p_i == p)
      \end{equation*}
\item \textbf{POI Category}: the categories (e.g. structures, entertainment and shopping) extracted from Wikipedia articles.
\item \textbf{POI Pair Distance}: distance between two POIs computed by
      \href{https://en.wikipedia.org/wiki/Great-circle\_distance#Computational\_formulas}{Haversine formula}
      given POI geographic coordinates.
\end{itemize}

\subsection{\textsc{Evaluation Metrics}} 
Let $P_r$ be the set of POIs of the recommended trajectory and $P_v$ be the set of POIs visited in real-life travel sequence,
define metrics\cite{lim15}
\begin{itemize}
\item \textbf{Tour Recall}
      \begin{equation*}
      \text{Recall} = \frac{\lvert P_r \cap P_v \rvert}{\lvert P_v \rvert}
      \end{equation*}
\item \textbf{Tour Precision}
      \begin{equation*}
      \text{Precision} = \frac{\lvert P_r \cap P_v \rvert}{\lvert P_r \rvert}
      \end{equation*}
\item \textbf{Tour F1-score}
      \begin{equation*}
      \text{F1-score} = \frac{2 \times \text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}
      \end{equation*}
\end{itemize}


\section{\textsc{Problem Formulation}}
\label{sec:formulation}
At first glance, trajectory recommendation seems not to be a supervised machine learning problem,
but it can be formulated as a supervised structured prediction problem so that 
active learning, which is designed to work in supervised learning settings, will work properly.
\begin{itemize}
\item \textbf{Input}: start POI $p_s$, end POI $p_e$, number of POIs $l$ in the expected trajectory.
\item \textbf{Output}: recommended trajectory $p_s, \dots, p_e$ with $l$ POIs in total.
\end{itemize}

It seems impossible to learning a function from the above input to output 
as the function space is too large while the available data are very limited.
However, we can add some processing steps before/after the input/output which could largely reduce 
the search space of possible functions and thus make this problem learnable.
\begin{itemize}
\item \textbf{Preprocess}: map $(p_s, p_e, l)$ to a number of synthesized trajectories $p_s, \dots, p_e$ with $l$ POIs.
\item \textbf{Input}: a synthesized trajectory
\item \textbf{Output}: a score of the input trajectory
\item \textbf{Postprocess}: recommend the trajectory with highest score among all corresponding synthesized trajectories (i.e. argmax).
\end{itemize}
With the above formulation, the input and output of query in active learning should be
\begin{itemize}
\item \textbf{Input}: a synthesized trajectory
\item \textbf{Output}: a score of the input trajectory
\end{itemize}
which implies that the oracle should implement a trajectory scoring function. 

As far as the labelling cost is concerned, it would be better to ask the oracle a YES/NO question,
in practice, given two trajectories $\text{Traj}_a$ and $\text{Traj}_b$, 
we would like to ask the oracle the following question: 

\textit{Is $\text{Traj}_a$ better than $\text{Traj}_b$?} \\
The expected answer is YES if the oracle thinks $\text{Traj}_a$ is better than $\text{Traj}_b$ and NO otherwise.

@TODO: what does \textbf{better} mean here?

@TODO: There will be too many trajectory pairs, how to choose/sample a pair to query?


\section{\textsc{Features}}
We use three transition features for each trajectory, namely,
\begin{enumerate}
\item POI category transition probabilities: 
      $P(\text{Cat}_{p_j} \vert \text{Cat}_{p_i})$, 
      the transition probability from POI $p_i$ to POI $p_j$.
\item POI popularity transition probabilities: 
      $P(\text{Pop}_{p_j} \vert \text{Pop}_{p_i})$, 
      the transition probability from POI $p_i$ to POI $p_j$.
      Discretize POI popularity first, 
      @TODO binning method?
\item POI pair distance transition probabilities: 
      $P(\text{Dist}_{p_j \to p_k} \vert \text{Dist}_{p_i \to p_j})$,
      the transition probability from POI pair ($p_i$, $p_j$) to pair ($p_j$, $p_k$).
      Discretize POI pair distance first,
      @TODO binning method?
\end{enumerate}


\section{\textsc{Probabilistic Model}}
For each transition feature, there is a Markov Chain (MC), thus three MCs in total.
The states of the MCs are POI categories, discretized POI popularities and discretized POI pair distances, respectively.

\subsection{\textsc{Parameter Estimation}}
Transition probabilities of the three MCs are estimated using maximum likelihood estimator (MLE).

\subsection{\textsc{Prediction}}
Given a trajectory, we compute a probability of the trajectory with each of the three MCs and 
define the sum of the three probabilities as the score the given trajectory.

For each input $(p_s, p_e, l)$ described in section \ref{sec:formulation}, 
we compute scores for all possible trajectories $p_s, \dots, p_e$ with $l$ POIs and
recommend the trajectory with highest score.

\subsection{\textsc{Learning}}
Start from an empty training set, after each query, 
we update parameters/transition probabilities of the three MCs using Bayes' rule
\begin{equation*}
P(\Theta \vert X) \propto P(X \vert \Theta) P(\Theta)
\end{equation*}

@TODO: concretely, how to update parameters after receiving a YES/NO answer from oracle?


\section{\textsc{Query Strategies}}
Three nontrivial query strategies are used to compare with the random baseline (i.e. passive learning) in the active learning process.
Let \textbf{x} denote an example in the pool and \textbf{y} denote the label of an example,
the query strategies are
\begin{itemize}
\item \textbf{Random Baseline}: this is the passive learning baseline,
      it queries an example choosen uniformly at random from the pool.
\item \textbf{Least Confident}\cite{settles08}: 
      \begin{equation*}
      \phi^{LC}(\textbf{x}) = 1 - P(\textbf{y}^* \vert \textbf{x}; \Theta)
      \end{equation*}
      where $\textbf{y}^*$ is the most likely label of example $\textbf{x}$ with respect to a probabilistic model 
      of which the parameters are denoted by $\Theta$.  
      This strategy queries the example $\textbf{x}$ of maximum $\phi^{LC}$ among all unlabelled examples in a pool.
\item \textbf{Sequence Entropy}\cite{settles08}:
      \begin{equation*}
      \phi^{SE}(\textbf{x}) = - \sum_{\hat{\textbf{y}}} P(\hat{\textbf{y}} \vert \textbf{x}; \Theta) 
                                \log(P(\hat{\textbf{y}} \vert \textbf{x}; \Theta))
      \end{equation*}
      where $\hat{\textbf{y}}$ ranges over all possible labels for example $\textbf{x}$.  
      Note that the number of possible labels grows exponentially with the number of POIs in $\textbf{x}$, 
      to make computation feasible, one can use the $N$-best possible labels to approximate,
      concretely, define \textit{N-best Sequence Entropy}\cite{kim06}
      \begin{equation*}
      \phi^{NSE}(\textbf{x}) = - \sum_{\hat{\textbf{y}} \in \mathcal{N}} P(\hat{\textbf{y}} \vert \textbf{x}; \Theta) 
                                 \log(P(\hat{\textbf{y}} \vert \textbf{x}; \Theta))
      \end{equation*}
      where $\mathcal{N} = \{\textbf{y}_1^*, \dots, \textbf{y}_N^*\}$ is the set of the $N$ most likely labels of example $\textbf{x}$.  
      This strategy queries the example $\textbf{x}$ of maximum $\phi^{SE}$ or $\phi^{NSE}$ among all unlabelled examples in a pool.
\item \textbf{Information Density}\cite{settles08}:
      \begin{equation*}
      \phi^{ID}(\textbf{x}) = \phi^{SE}(\textbf{x}) \times 
        \left(
        \frac{1}{U} \sum_{u=1}^U \text{sim}(\textbf{x}, \textbf{x}^u)
        \right)^\beta
      \end{equation*}
      where $\text{sim}(\textbf{x}^{(i)}, \textbf{x}^{(j)})$ is the similarity between example $\textbf{x}^{(i)}$ and $\textbf{x}^{(j)}$.
      The informativeness of example $\textbf{x}$ is weighted by its average similarity 
      to all other unlabelled examples (denoted by $\mathcal{U})$ in the pool, subject to parameter $\beta$.
      Sequence entropy $\phi^{SE}$ measures the "base" informativeness and could be replaced by $\phi^{NSE}$ for efficient computation.
      This strategy queries the example $\textbf{x}$ of maximum $\phi^{ID}$ among all unlabelled examples in a pool.
\end{itemize}
@TODO: define example and its label concretely.

\section{\textsc{Experimental Dataset}}
Trajectories are extracted from YFCC100M dataset in several well-known cities, e.g. Melbourne, Toronto, Edinburgh etc. \\
POIs (i.e. POI name, category, geographic coordinates) are extracted from Wikipedia articles.


\bibliographystyle{plain}
\bibliography{problem_settings}
\end{document}
