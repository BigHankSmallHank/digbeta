\documentclass[11pt, a4paper]{article}
\usepackage{amsmath}
\usepackage{hyperref}
%\usepackage{mathpazo}
%\usepackage{libertine}
%\usepackage{newtxmath, newtxtext}
\usepackage{mathpazo, libertine}
\usepackage[a4paper, left=60pt, top=80pt, right=60pt, bottom=80pt]{geometry}

\title{Trajectory Recommendation with Active Learning}
\author{Dawei Chen}
\date{\today}

\begin{document}
\maketitle

\section{\textsc{Overview}}
Recommend trajectories for tourists using historical visiting traces (i.e. trajectories) extracted from geo-tagged Flickr photos 
as well as Place/Point of Interest (POI) extracted from Wikipedia articles.

\subsection{\textsc{Definition}}
For user $u$ and POI $p$, define $u$'s travel history and travel sequences, 
POI popularity, POI category, distance between POIs and average POI visit duration as follows\cite{lim15}:
\begin{itemize}
\item \textbf{Travel History}:
      \begin{equation*}
      S_u = \{(p_1, t_{p_1}^a, t_{p_1}^d), \dots, (p_n, t_{p_n}^a, t_{p_n}^d)\}
      \end{equation*}
      where $t_{p_i}^a$ is the arrival time and $t_{p_i}^d$ the departure time of user $u$ at POI $p_i$.
\item \textbf{Travel Sequences}: split $S_u$ if
      \begin{equation*}
      \lvert t_{p_i}^d - t_{p_{i+1}}^a \rvert > \tau ~(\text{e.g.}~ \tau = 8 ~\text{hours})
      \end{equation*}
\item \textbf{POI Popularity}:
      \begin{equation*}
      Pop(p) = \sum_{u \in U} \sum_{p_i \in S_u} \delta(p_i == p)
      \end{equation*}
      where $U$ is the set of all users.
\item \textbf{POI Category}: the categories (e.g. structures, entertainment and shopping) extracted from Wikipedia articles.
\item \textbf{POI Pair Distance}: distance between two POIs computed by
      \href{https://en.wikipedia.org/wiki/Great-circle\_distance#Computational\_formulas}{Haversine formula}
      given POI geographic coordinates.
\item \textbf{Average POI Visit Duration}:
      \begin{equation}
      \bar{V}(p) = \frac{1}{N} \sum_{u \in U} \sum_{p_i \in S_u} (t_{p_i}^d - t_{p_i}^a) \delta(p_i == p)
      \end{equation}
      where $N$ is the number of visits of POI $p$ by all users.
\end{itemize}

\subsection{\textsc{Evaluation Metrics}} 
Let $P_r$ be the set of POIs of the recommended trajectory and $P_v$ be the set of POIs visited in real-life travel sequence,
define metrics\cite{lim15}
\begin{itemize}
\item \textbf{Tour Recall}
      \begin{equation*}
      \text{Recall} = \frac{\lvert P_r \cap P_v \rvert}{\lvert P_v \rvert}
      \end{equation*}
\item \textbf{Tour Precision}
      \begin{equation*}
      \text{Precision} = \frac{\lvert P_r \cap P_v \rvert}{\lvert P_r \rvert}
      \end{equation*}
\item \textbf{Tour F1-score}
      \begin{equation*}
      \text{F1-score} = \frac{2 \times \text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}
      \end{equation*}
\end{itemize}

\subsection{\textsc{Problem Formulation}}
\label{sec:formulation}
The input/output of the recommendation algorithm:
\begin{description}
\item \textbf{Input/Constraints}: start POI $p_s$, end POI $p_e$, number of POIs $l$ in the expected trajectory.
\item \textbf{Output}: recommended trajectory $p_s, \dots, p_e$ with $l$ POIs in total.
\end{description}


\section{\textsc{User Agnostic Modeling}}
\subsection{\textsc{Features}}
Two POI features are used here, namely,
\begin{enumerate}
\item POI popularity
\item Average POI visit duration
\end{enumerate}
We use an user agnostic model to recommend trajectory with given constraints and the above features.

\subsection{\textsc{Learning}}
We use rankSVM\cite{herbrich99} to rank the set of POIs.
To learn the parameters of rankSVM,
training data are generated as follows:
\begin{enumerate}
\item Each user ID form a \textit{query} (in Information Retrieval (IR) terminology). 
\item The label of a POI is the number of presence of that POI in a specific \textit{query} 
      (It would simply be POI popularity if \textit{query} is not considered.)
\item Absence POIs are unobserved (i.e. missing data) in a specific \textit{query} (in IR terminology).
\item Use the two features described above (after scaling).
\end{enumerate}

\subsection{\textsc{Prediction}}
A trained rankSVM could generate a ranking of POIs, we predict a trajectory with respect to constraints
$(p_s, p_e, l)$ by choose the top $l-2$ POIs without considering 
$p_s$ and $p_e$ to form a trajectory (the visit order is not considered here).


\section{\textsc{Personalised Modeling}}
Factors that could affect a visiting trajectory:
\begin{itemize}
\item traveller/user preference
\item travel history of user (merge with the first one $\to$ a changing preference)
\item travel season
\item travel method: drive/ride/walk/public transport
\item total time allocated for travelling?
\end{itemize}
Factors that could affect the visit duration at a POI:
\begin{itemize}
\item traveller/user preference
\item travel history of user (merge with the first one $\to$ a changing preference)
\item travel season
\item travel method: drive/ride/walk/public transport
\item total time allocated for travelling
\item travel pattern, e.g. POI$_i$ $\to$ POI$_j$ $\to$ POI$_k$, 
      the visit duration at POI$_j$ is related to that at POI$_j$ and POI$_k$.
\end{itemize}
@TODO: build a Bayesian network that reflects the interaction of these factors.


\section{\textsc{Active Learning Setting}}
The active learning setting for trajectory recommendation is a bit different from that in supervised learning.
\begin{enumerate}
\item Each query is corresponding to a set of constraints of recommendation, 
      e.g. start POI, end POI, number of POIs, travel time, visit duration etc.
      According to the input of recommendation algorithm described above, 
      the current constraints are start POI, end POI and number of POIs.
\item Generate a probability distribution of all trajectories that satisfy the constraints.
\item Choose a set of constraints based on the probability distribution of possible trajectories that satisfy the constraints
      according to a query strategy.
\item Query the oracle "What is the best trajectory to recommend given this set of constraints?"
\end{enumerate}
Currently, for the user agnostic model, to generate a probability distribution of all possible trajectories, 
we first scale the scores of POIs (for ranking) to range $[-1, 1]$, then shift all scores $1$ unit to the right,
the score of a trajectory is defined as the summation of the scores of its POIs, 
generate the distribution by normalising scores of all possible trajectories.

\subsection{\textsc{Query Strategies}}
Three nontrivial query strategies are used to compare with the random baseline (i.e. passive learning) in the active learning process.
Let \textbf{x} denote an example (i.e. the set of constraints of recommendation) in the pool and 
\textbf{y} denote the label of an example (i.e. the best trajectory to recommend given a set of constraints),
the query strategies are
\begin{itemize}
\item \textbf{Random Baseline}: this is the passive learning baseline,
      it queries an example choosen uniformly at random from the pool.
\item \textbf{Least Confident}\cite{settles08}: 
      \begin{equation*}
      \phi^{LC}(\textbf{x}) = 1 - P(\textbf{y}^* \vert \textbf{x}; \Theta)
      \end{equation*}
      where $\textbf{y}^*$ is the most likely label of example $\textbf{x}$ with respect to a probabilistic model 
      of which the parameters are denoted by $\Theta$.  
      This strategy queries the example $\textbf{x}$ of maximum $\phi^{LC}$ among all unlabelled examples in a pool.
\item \textbf{Sequence Entropy}\cite{settles08}:
      \begin{equation*}
      \phi^{SE}(\textbf{x}) = - \sum_{\hat{\textbf{y}}} P(\hat{\textbf{y}} \vert \textbf{x}; \Theta) 
                                \log(P(\hat{\textbf{y}} \vert \textbf{x}; \Theta))
      \end{equation*}
      where $\hat{\textbf{y}}$ ranges over all possible labels for example $\textbf{x}$.  
      Note that the number of possible labels grows exponentially with the number of POIs in $\textbf{x}$, 
      to make computation feasible, one can use the $N$-best possible labels to approximate,
      concretely, define \textit{N-best Sequence Entropy}\cite{kim06}
      \begin{equation*}
      \phi^{NSE}(\textbf{x}) = - \sum_{\hat{\textbf{y}} \in \mathcal{N}} P(\hat{\textbf{y}} \vert \textbf{x}; \Theta) 
                                 \log(P(\hat{\textbf{y}} \vert \textbf{x}; \Theta))
      \end{equation*}
      where $\mathcal{N} = \{\textbf{y}_1^*, \dots, \textbf{y}_N^*\}$ is the set of the $N$ most likely labels of example $\textbf{x}$.  
      This strategy queries the example $\textbf{x}$ of maximum $\phi^{SE}$ or $\phi^{NSE}$ among all unlabelled examples in a pool.
\item \textbf{Information Density}\cite{settles08}:
      \begin{equation*}
      \phi^{ID}(\textbf{x}) = \phi^{SE}(\textbf{x}) \times 
        \left(
        \frac{1}{U} \sum_{u=1}^U \text{sim}(\textbf{x}, \textbf{x}^u)
        \right)^\beta
      \end{equation*}
      where $\text{sim}(\textbf{x}^{(i)}, \textbf{x}^{(j)})$ is the similarity between example $\textbf{x}^{(i)}$ and $\textbf{x}^{(j)}$.
      The informativeness of example $\textbf{x}$ is weighted by its average similarity 
      to all other unlabelled examples (denoted by $\mathcal{U})$ in the pool, subject to parameter $\beta$.
      Sequence entropy $\phi^{SE}$ measures the "base" informativeness and could be replaced by $\phi^{NSE}$ for efficient computation.
      This strategy queries the example $\textbf{x}$ of maximum $\phi^{ID}$ among all unlabelled examples in a pool.
\end{itemize}

\section{\textsc{Experimental Dataset}}
Trajectories are extracted from YFCC100M dataset in several well-known cities, e.g. Melbourne, Toronto, Edinburgh etc. \\
POIs (i.e. POI name, category, geographic coordinates) are extracted from Wikipedia articles.


\bibliographystyle{plain}
\bibliography{problem_settings}
\end{document}
