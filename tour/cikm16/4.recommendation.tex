\section{Tour Recommendation}
\label{sec:recommendation}

\begin{table}[b]
\caption{Summary of information captured by different trajectory recommendation algorithms}
\label{tab:algsummary}
\centering
%\small
\setlength{\tabcolsep}{3pt} % tweak the space between columns
\begin{tabular}{l|*{5}{c}} \hline
                                & Query    & POI      & Trans.     & No sub-      & Joint    \\
                                &          &          &            & tours        &          \\ \hline
\textsc{Random}                 & $\times$ & $\times$ & $\times$   & $\times$     & $\times$ \\
\textsc{PersTour}\cite{ijcai15} & $\times$ & $\surd$  & $\times$   & $\surd$      & $\times$ \\
\textsc{PersTour-L}             & $\times$ & $\surd$  & $\times$   & $\surd$      & $\times$ \\
\textsc{PoiPopularity}          & $\times$ & $\surd$  & $\times$   & $\times$     & $\times$ \\
\textsc{PoiRank}                & $\surd$  & $\surd$  & $\times$   & $\times$     & $\times$ \\
\textsc{Markov}                 & $\times$ & $\surd$  & $\surd$    & $\times$     & $\times$ \\
\textsc{MarkovPath}             & $\times$ & $\surd$  & $\surd$    & $\surd$      & $\times$ \\
\textsc{Rank+Markov}            & $\surd$  & $\surd$  & $\surd$    & $\times$     & $\times$ \\
\textsc{Rank+MarkovPath}        & $\surd$  & $\surd$  & $\surd$    & $\surd$      & $\times$ \\
\textsc{StructuredSVM}          & $\surd$  & $\surd$  & $\surd$    & $\times$     & $\surd$  \\ \hline
\end{tabular}
\end{table}


Recall that in section \ref{sec:ranksvm} we described how to recommend trajectories by ranking points,
i.e., the \textsc{PoiRank} algorithm and its simplified variant \textsc{PoiPopularity}.
While algorithms based on points ranking utilise POI and/or query features, 
the transitions between POIs are never considered.
On the other hand, \textsc{Markov} and its variant \textsc{MarkovPath}
only use POI-POI transitions but ignoring the point ranks.
We summary the characteristics of the various approaches to recommend trajectories in table \ref{tab:algsummary}.

We are now in a position to jointly optimise POI preferences and route plans.
We want to leverage both POI ranking and POI-POI transitions when recommending trajectories.


\subsection{POI ranking and transitions}
\label{sec:rank+markov}
To recommend the \textit{most likely} trajectory with respect to query $(p_s, p_e, L)$,
we want to combine the ranking of POIs with the transition probabilities,
i.e., we want to find a trajectory that maximise the product of ranking probabilities of its POIs
as well as its likelihood at the same time.

Firstly, we transform the ranking scores of POIs with respect to query $(p_s, p_e, L)$
to a probability distribution using softmax function~\cite{bishop2006},
\begin{equation}
  \label{eq:poi-probability}
  P_R(p_j | x) = \frac{e^{R(p_j)}}{\sum_j e^{R(p_j)}}
\end{equation}
where $x = (p_s, p_e, L)$ is the query and $R(p_j)$ is the ranking score of POI $p_j$ with respect to the query.

\eat{
The logarithm of product of ranking probabilities of POIs in a trajectory
$y = (p_{j_1}, \dots, p_{j_L})$ is
\begin{displaymath}
    \ell_R(y) = \prod_{k=1}^L P_R(p_{j_k} | (p_{j_1}, p_{j_L}, L))
\end{displaymath}
and its log likelihood is
\begin{displaymath}
    \ell(y) = \prod_{k=1}^{L-1} P(p_{j_{k+1}} | p_{j_k})
\end{displaymath}
is maximising the following objective:
\begin{displaymath}
    \alpha \ell_R(y) + (1-\alpha) \ell(y)
\end{displaymath}
}

%  \item Heuristics: \textsc{Rank+Markov}, \textsc{Rank+MarkovPath}
One heuristic to find a trajectory that simultaneously maximise the product of ranking probabilities
of its POIs (with respect to query $(p_s, p_e, L)$) and its likelihood is optimising the following objective:
\begin{equation*}
    \argmax_{y \in \mathcal{P}^L} ~\alpha \prod_{k=1}^{L} P_R(p_{j_k} | x) +
                                    (1-\alpha) \prod_{k=1}^{L-1} P(p_{j_{k+1}} | p_{j_k})
%   =& \argmax_{y \in \mathcal{P}^L} ~\alpha \sum_{k=1}^{L} \log P_R(p_{j_k} | x) +
%                                    (1-\alpha) \sum_{k=1}^{L-1} \log P(p_{j_{k+1}} | p_{j_k})
\end{equation*}
such that
$p_{j_1} = p_s, ~ p_{j_L} = p_e$ and
$p_{j_k} \in \mathcal{P}, 1 \le k \le L$,
where $y = (p_{j_1}, \dots, p_{j_L})$ is any possible trajectory and
$0 \le \alpha \le 1$ is a parameter to trade-off the importance between the ranking of POIs
and the POI-POI transitions in the recommended trajectory.
The objective can be optimised by adapting the Viterbi algorithm using recursions
\begin{equation}
    \label{eq:max}
    A[l+1, p] = \max_{p' \in \mathcal{P}} \{ A[l, p'] + \alpha \log P_R(p|x) + (1-\alpha) \log P(p|p') \}
\end{equation}
and
\begin{equation}
    \label{eq:argmax}
    B[l+1, p] = \argmax_{p' \in \mathcal{P}} \{ A[l, p'] + \alpha \log P_R(p|x) + (1-\alpha) \log P(p|p') \}
\end{equation}
where $A[l, p]$ stores the maximum value that associated with the (partial) trajectory
that starts at $p_s$ and ends at $p$ with exactly $l$ POIs,
$B[l, p]$ stores the predecessor of $p$ in the (partial) trajectory.

The maximum objective value is $A[L, p_e]$,
and the corresponding trajectory can be found by tracing back from $B[L, p_e]$.
We call this approach that uses both the ranking of POIs and the POI-POI transition probabilities
\textsc{Rank+Markov}, with the pseudo code described in algorithm \ref{alg:rank+markov}.

\begin{algorithm}[t]
\caption{\textsc{Rank+Markov}: recommend trajectory by utilising both POI ranking and transition}
\label{alg:rank+markov}
\begin{algorithmic}[1]
\STATE \textbf{Input}: $\mathcal{P}, p_s, p_e, L$
\STATE Produce a rank $<_{p_i, p_j} \subset \mathcal{P}^2$ w.r.t. query $(p_s, p_e, L)$
\STATE Compute POI-to-POI transition matrix
\FOR{$p \in \mathcal{P}$}
    \STATE $A[2, p] = \alpha ( \log P_R(p_s|x) + \log P_R(p|x) )$ $+$ \\ \hfill $(1-\alpha) \log P(p|p_s)$
    \STATE $B[2, p] = p_s$
\ENDFOR
\FOR{$l=2$ to $L-1$}
    \FOR{$p \in \mathcal{P}$}
        \STATE Compute $A[l+1, p]$ using equation (\ref{eq:max})
        \STATE Compute $B[l+1, p]$ using equation (\ref{eq:argmax})
    \ENDFOR
\ENDFOR
% //trace back to find the actual path
\STATE $\mathcal{T}= \{p_e\}$, $l = L$, $p = \mathcal{T}.first$
\REPEAT
    \STATE Prepend $B[l, p]$ to $\mathcal{T}$
    \STATE $l = l - 1$, $p = \mathcal{T}.first$
\UNTIL{$l < 2$}
\RETURN $\mathcal{T}$
\end{algorithmic}
\end{algorithm}

Similar to the \textsc{Markov} algorithm,
sub-tours (e.g., tottering) may appear in trajectories recommended by \textsc{Rank+Markov}.
We can apply sub-tour elimination constraints described in section \ref{sec:walkpath} and
optimise the following objective using integer linear programming
with the same constraints as the \textsc{MarkovPath} algorithm.
\begin{displaymath}
    \text{Maximize}  \sum_{i=1}^{N-1} \sum_{j=2}^N x_{ij} (\alpha \log P_R(p_j | x) + (1-\alpha) \log P(p_j | p_i))
\end{displaymath}
We denote this algorithm as \textsc{Rank+MarkovPath}.

\subsection{Structured SVM}
\label{sec:ssvm}

As trajectory is a sequence of POI visits,
it is natural to model the recommended trajectory $y$ with respect to query $x = (p_s, p_e, L)$
as a chain of $L$ variables, where each discrete variable has $|\mathcal{P}|$ states.
Structured prediction incorporates both the features of variables (unary features) and
the features of interactions between neighbouring variables (pairwise features) to make a
prediction,
\begin{displaymath}
    y^* = \argmax_{y \in \mathcal{P}^L} \sum_{j=1}^L \mathbf{w_u}^T \phi_j(x, y_j) +
                                        \sum_{j=1}^{L-1} \mathbf{w_p}^T \phi_{j, j+1}(x, y_j, y_{j+1})
\end{displaymath}
where $\phi_j$ is the unary features of the $j$-th variable and $\phi_{j, j+1}$ is the pairwise features between
the $j$-th and $(j+1)$-th variables, $\mathbf{w_u}$ and $\mathbf{w_p}$ are the
parameters of unary and pairwise features respectively.
The unary and binary features above are constructed from the POI ranking and POI-POI transitions
respectively.
This method is called \textsc{StructuredSVM} in the experiments.

The unary features are defined as ranking probabilities (Equation~\ref{eq:poi-probability}).
Recall that we have a query consisting of start ($p_s$) and end ($p_e$) locations, which
we model as a 1-of-$K$ encoding in the unary features.
The pairwise features are defined from the transition probabilities $P(p_j | p_i)$ defined in
Section~\ref{sec:transition}.

\eat{
In the settings of trajectory recommendation, the ranking probabilities of POIs
with respect to constraint $x = (p_s, p_e, L)$ were used to capture the unary features of individual variables
and the transition probabilities between POIs were utilized to capture the pairwise features
between the neighboring variables, in particular,
the unary features of the first and last variables are binary vectors
with true values at the corresponding POIs and false values anywhere else,
the unary features of the other $L-2$ variables are the ranking probabilities of POIs in $\mathcal{P}$, i.e.,
\begin{displaymath}
    \phi_j(x, y_j) = P_R(y_j | x), y_j \in \mathcal{P}
\end{displaymath}

Pairwise features between the $j$-th variable and the $(j+1)$-th variable $\phi_{j, j+1}$ was defined as
\begin{align*}
    \phi_{j, j+1}(x, y_j, y_{j+1}) &= \phi_{j-1, j}(x, y_{j-1}, y_j) \times M \\
                                 j &=2, \dots, L-2
\end{align*}
where $\phi_{j-1, j}$ is the pairwise features between the $(j-1)$-th and $j$-th variables,
and $M$ is the transition matrix between POIs described in section \ref{sec:transition} and
$M_{ij} = P(p_j | p_i)$.
In particular, the pairwise features between the first and the second variables is the
outgoing transition probabilities of the first variable,
and the pairwise features between the second-last and the last variables are a probability distribution
over all POIs in $\mathcal{P}$ where the probability mass is dominated by the variable corresponding to POI $p_e$,
all other POIs in $\mathcal{P} \setminus p_e$ are simply uniformly distributed.
}

% describe unary/pairwise potentials?

% describe SSVM training (1-slack formulation)
To estimate the parameters $\mathbf{w_u}$ and $\mathbf{w_p}$, we train a structured Support Vector Machine
using the 1-slack formulation~\cite{ssvm09},
\begin{align*}
    \min_{\mathbf{w}, \xi \ge 0} ~~& \frac{1}{2} \mathbf{w}^T \mathbf{w} + C \xi \\
    s.t. ~~& \frac{1}{N} \mathbf{w}^T \sum_{i=1}^N \delta(\hat{y^{(i)}}) \ge
                  \frac{1}{N} \sum_{i=1}^N \Delta(y^{(i)}, \hat{y^{(i)}}) - \xi \\
         ~~& \forall \hat{y^{(i)}} \in \mathcal{P}^{|y^{(i)}|}, i = 1, \cdots, N
\end{align*}
where $\mathbf{w} = [\mathbf{w_u}^T, \mathbf{w_p}^T]^T$ is the parameter vector,
$N$ is the total number of trajectories in training set, $C$ is the regularisation parameter,
$\xi$ is the slack variable, and
\begin{displaymath}
    \delta(\hat{y^{(i)}}) = \Psi(x^{(i)}, y^{(i)}) - \Psi(x^{(i)}, \hat{y^{(i)}})
\end{displaymath}
where $\Psi(x, y)$ is the joint feature vector which is a composite of unary and pairwise features of the
$i$-th example in training set,
$\Delta(y^{(i)}, \hat{y^{(i)}})$ is the loss associated with the $i$-th trajectory in training set and
its corresponding recommendation trajectory, and Hamming loss was used in this work.
