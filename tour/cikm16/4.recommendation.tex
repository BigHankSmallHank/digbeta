%!TEX root = main.tex

\section{Tour Recommendation}
\label{sec:recommendation}
\secmoveup

Recall that in Section~\ref{sec:ranksvm} we described how to recommend trajectories by ranking points,
i.e., \textsc{PoiRank} % and its simplified variant \textsc{PoiPopularity}.
%While algorithms based on points ranking utilise POI and/or query features, 
%the transitions between POIs are never considered.
and ones that consider transitions between POIs, i.e., \textsc{Markov} and \textsc{MarkovPath}
%only use POI-POI transitions but ignoring the point ranks.
This section propose three approaches to %now in a position to 
jointly optimise the recommendation with both POI preferences and route plans.
%We want to leverage both POI ranking and POI-POI transitions when recommending trajectories.
A summary of the various trajectory recommendation approaches can be found in Table~\ref{tab:algsummary}.


\subsection{POI ranking and transitions}
\label{sec:rank+markov}
\secmoveup


To recommend the \textit{most likely} trajectory with respect to a query,
we want to combine the ranking of POIs with the transition probabilities,
i.e., we want to find a trajectory that maximise the points ranking of its POIs
as well as its likelihood at the same time.

Firstly, we transform the ranking scores of POIs with respect to query $q = (p_s, p_e, L)$
to a probability distribution using the softmax function~\cite{bishop2006},
\begin{equation}
  \label{eq:poi-probability}
  P_R(p_j | q) = \frac{e^{R(p_j)}}{\sum_j e^{R(p_j)}}
\end{equation}
where $R(p_j)$ is the ranking score of POI $p_j$ with respect to query $q$.

\eat{
The logarithm of product of ranking probabilities of POIs in a trajectory
$y = (p_{j_1}, \dots, p_{j_L})$ is
\begin{displaymath}
    \ell_R(y) = \prod_{k=1}^L P_R(p_{j_k} | (p_{j_1}, p_{j_L}, L))
\end{displaymath}
and its log likelihood is
\begin{displaymath}
    \ell(y) = \prod_{k=1}^{L-1} P(p_{j_{k+1}} | p_{j_k})
\end{displaymath}
is maximising the following objective:
\begin{displaymath}
    \alpha \ell_R(y) + (1-\alpha) \ell(y)
\end{displaymath}
}

%  \item Heuristics: \textsc{Rank+Markov}, \textsc{Rank+MarkovPath}
One heuristic to find a trajectory that simultaneously maximise the product of ranking probabilities
of its POIs (with respect to query $q$) and its likelihood is optimising the following objective:
\begin{equation*}
    \argmax_{\mathcal{T} \in \mathcal{P}^L} ~\alpha \prod_{k=1}^{L} P_R(p_{j_k} | q) +
                                     (1-\alpha) \prod_{k=1}^{L-1} P(p_{j_{k+1}} | p_{j_k})
%   =& \argmax_{y \in \mathcal{P}^L} ~\alpha \sum_{k=1}^{L} \log P_R(p_{j_k} | x) +
%                                    (1-\alpha) \sum_{k=1}^{L-1} \log P(p_{j_{k+1}} | p_{j_k})
\end{equation*}
such that
$p_{j_1} = p_s, ~ p_{j_L} = p_e$ and
$p_{j_k} \in \mathcal{P}, 1 \le k \le L$.
$\mathcal{T} = (p_{j_1}, \dots, p_{j_L})$ is any possible trajectory and
$0 \le \alpha \le 1$ is a parameter to trade-off the importance between the ranking of POIs
and the POI-POI transitions in the recommended trajectory.
Similar to \textsc{Markov} algorithm above, the best path can be found using the Viterbi algorithm with both node and transition scores. 
%The objective can be optimised by adapting the Viterbi algorithm and using the two recursions below,
\begin{multline}
    \label{eq:max}
    A[l+1, p] = \max_{p' \in \mathcal{P}} \{ A[l, p'] + \alpha \log P_R(p|q) + \\ (1-\alpha) \log P(p|p') \}
\end{multline}
\begin{multline}
    \label{eq:argmax}
    B[l+1, p] = \argmax_{p' \in \mathcal{P}} \{ A[l, p'] + \alpha \log P_R(p|q) + \\ (1-\alpha) \log P(p|p') \}
\end{multline}
where $A$ the score matrix and entry $A[l, p]$ stores the maximum value that associated with the (partial) trajectory, 
that starts at $p_s$ and ends at $p$ with $l$ POI visits,
$B$ is the backtracking-point matrix and entry $B[l, p]$ stores the predecessor of $p$ in that (partial) trajectory.

The maximum objective value is $A[L, p_e]$,
and the corresponding trajectory can be found by tracing back from $B[L, p_e]$.
We call this approach that uses both the ranking of POIs and POI-POI transitions \textsc{Rank+Markov},
with the pseudo code shown in Algorithm~\ref{alg:rank+markov}.

\begin{algorithm}[t]
\caption{\textsc{Rank+Markov}: recommend trajectory with both POI ranking and transition}
\label{alg:rank+markov}
\begin{algorithmic}[1]
\STATE \textbf{Input}: $\mathcal{P}, p_s, p_e, L$
\STATE \textbf{Output}: Trajectory $\mathcal{T} = (p_s, \cdots, p_e)$ with $L$ POIs
\STATE Compute a rank $<_{p_i, p_j} \subset \mathcal{P}^2$ w.r.t. query $q = (p_s, p_e, L)$
\STATE Compute POI-POI transition matrix
\STATE Initialise score matrix $A$ and backtracking pointers $B$
\FOR{$p \in \mathcal{P}$}
    \STATE $A[2, p] = \alpha ( \log P_R(p_s|q) + \log P_R(p|q) )$ $+$ \\ \hfill $(1-\alpha) \log P(p|p_s)$
    \STATE $B[2, p] = p_s$
\ENDFOR
\FOR{$l=2$ to $L-1$}
    \FOR{$p \in \mathcal{P}$}
        \STATE Compute $A[l+1, p]$ using Equation~(\ref{eq:max})
        \STATE Compute $B[l+1, p]$ using Equation~(\ref{eq:argmax})
    \ENDFOR
\ENDFOR
% //trace back to find the actual path
\STATE $\mathcal{T}= \{p_e\}$, $l = L$, $p = \mathcal{T}.first$
\REPEAT
    \STATE Prepend $B[l, p]$ to $\mathcal{T}$
    \STATE $l = l - 1$, $p = \mathcal{T}.first$
\UNTIL{$l < 2$}
\RETURN $\mathcal{T}$
\end{algorithmic}
\end{algorithm}

Similar to the \textsc{Markov} algorithm described in Section~\ref{sec:transition},
sub-tours (e.g., tottering) may appear in trajectories recommended by \textsc{Rank+Markov}.
To eliminate sub-tours, we can optimise the following objective using integer linear programming
with the same constraints as those in \textsc{MarkovPath} algorithm described in Section~\ref{sec:walkpath}.
\begin{displaymath}
    \max  \sum_{i=1}^{N-1} \sum_{j=2}^N x_{ij} (\alpha \log P_R(p_j | q) + (1-\alpha) \log P(p_j | p_i))
\end{displaymath}
We call this algorithm \textsc{Rank+MarkovPath} in experiments.
Hyperparameter $\alpha$ is tuned using cross validation for both \textsc{Rank+Markov} and \textsc{Rank+MarkovPath}. 

\subsection{Structured SVM}
\label{sec:ssvm}
\secmoveup

As trajectory is a sequence of POI visits,
it is natural to model the recommended trajectory $\mathcal{T}$ with respect to query $q = (p_s, p_e, L)$
as a chain of $L$ variables, where each discrete variable has $|\mathcal{P}|$ states.
Structured prediction incorporates both the features of variables (unary features) and
the features of interactions between neighbouring variables (pairwise features) to make a
prediction,
\begin{displaymath}
    \mathcal{T}^* = \argmax_{\mathcal{T} \in \mathcal{P}^L} 
                    \sum_{j=1}^L \mathbf{w_u}^T \mathbf{\phi}_j \left( q, \mathcal{T}_j \right) +
                    \sum_{j=1}^{L-1} \mathbf{w_p}^T \mathbf{\phi}_{j, j+1} \left( q, \mathcal{T}_j, \mathcal{T}_{j+1} \right)
\end{displaymath}
where $\mathbf{\phi}_j$ is the unary features of the $j$-th variable and $\mathbf{\phi}_{j, j+1}$ is the pairwise features between
the $j$-th and $(j+1)$-th variables, $\mathbf{w_u}$ and $\mathbf{w_p}$ are the
parameters of unary and pairwise features.

The unary and pairwise features are constructed from the POI ranking and POI-POI transitions respectively.
In particular, unary features are defined as ranking probabilities (Equation~\ref{eq:poi-probability}).
Recall that we have a query consisting of start ($p_s$) and end ($p_e$) locations, which
we model as a 1-of-$K$ encoding in the unary features.
The pairwise features are defined from the transition probabilities $P(p_j | p_i)$ defined in
Section~\ref{sec:transition}.
This method is called \textsc{StructuredSVM} in the experiments.

\eat{
In the settings of trajectory recommendation, the ranking probabilities of POIs
with respect to constraint $x = (p_s, p_e, L)$ were used to capture the unary features of individual variables
and the transition probabilities between POIs were utilized to capture the pairwise features
between the neighboring variables, in particular,
the unary features of the first and last variables are binary vectors
with true values at the corresponding POIs and false values anywhere else,
the unary features of the other $L-2$ variables are the ranking probabilities of POIs in $\mathcal{P}$, i.e.,
\begin{displaymath}
    \phi_j(x, y_j) = P_R(y_j | x), y_j \in \mathcal{P}
\end{displaymath}

Pairwise features between the $j$-th variable and the $(j+1)$-th variable $\phi_{j, j+1}$ was defined as
\begin{align*}
    \phi_{j, j+1}(x, y_j, y_{j+1}) &= \phi_{j-1, j}(x, y_{j-1}, y_j) \times M \\
                                 j &=2, \dots, L-2
\end{align*}
where $\phi_{j-1, j}$ is the pairwise features between the $(j-1)$-th and $j$-th variables,
and $M$ is the transition matrix between POIs described in Section~\ref{sec:transition} and
$M_{ij} = P(p_j | p_i)$.
In particular, the pairwise features between the first and the second variables is the
outgoing transition probabilities of the first variable,
and the pairwise features between the second-last and the last variables are a probability distribution
over all POIs in $\mathcal{P}$ where the probability mass is dominated by the variable corresponding to POI $p_e$,
all other POIs in $\mathcal{P} \setminus p_e$ are simply uniformly distributed.
}

% describe unary/pairwise potentials?

% describe SSVM training (1-slack formulation)
To estimate the parameters $\mathbf{w_u}$ and $\mathbf{w_p}$, we train a structured Support Vector Machine
using the 1-slack formulation~\cite{ssvm09},
\begin{align*}
    \min_{\mathbf{w}, \xi \ge 0} ~~& \frac{1}{2} \mathbf{w}^T \mathbf{w} + C \xi \\
    s.t. ~~& \forall \left( \hat{\mathcal{T}}^{(1)}, \cdots, \hat{\mathcal{T}}^{(N)} \right) \in \mathscr{T}^N: \\
         ~~& \frac{1}{N} \mathbf{w}^T \sum_{i=1}^N \delta \left( \hat{\mathcal{T}}^{(i)} \right) \ge
             \frac{1}{N} \sum_{i=1}^N \Delta \left( \mathcal{T}^{(i)}, \hat{\mathcal{T}}^{(i)} \right) - \xi \\
%         ~~& \forall \hat{\mathcal{T}}^{(i)} \in \mathcal{P}^{|\mathcal{T}^{(i)}|}, i = 1, \cdots, N
\end{align*}
where $\mathbf{w} = [\mathbf{w_u}^T, \mathbf{w_p}^T]^T$ is the parameter vector,
$\mathcal{T}^{(i)}$ and $\hat{\mathcal{T}}^{(i)}$ are the $i$-th trajectory in training set
and its corresponding recommended trajectory respectively.
$N$ is the training set size, $C$ is the regularisation parameter,
$\xi$ is the slack variable, and
\begin{displaymath}
    \delta \left( \hat{\mathcal{T}}^{(i)} \right) = \Psi \left( q^{(i)}, \mathcal{T}^{(i)} \right) - 
                                                    \Psi \left( q^{(i)}, \hat{\mathcal{T}}^{(i)} \right)
\end{displaymath}
where $q^{(i)}$ the query corresponds to the $i$-th trajectory in training set and
$\Psi \left( q^{(i)}, \mathcal{T}^{(i)} \right)$ is the joint feature vector which is a composite of unary and 
pairwise features of the $i$-th trajectory,
$\Delta \left( \mathcal{T}^{(i)}, \hat{\mathcal{T}}^{(i)} \right)$ is the loss associated with the $i$-th trajectory 
and its corresponding recommendation, and Hamming loss is used in this work.
