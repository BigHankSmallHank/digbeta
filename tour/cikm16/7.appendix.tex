\newpage

\appendix

\section{POI Categories}
We collected the POI categories in all of the five trajectory datasets,
their names with the corresponding icons are shown in figure \ref{fig:poicats}.

%\cheng{Report the proportion of recommended trajectories and actual trajectories with sub-tours, in the Appendix.}

\section{POIs sharing the same feature vector}
When a group of POIs sharing identical (discretised) features,
we distribute the probability uniformly among the POIs in the group as follows.

Firstly, the incoming (unnormalised) transition probability of the group computed by taking 
the Kronecker product is divided uniformly among POIs in the group,
which is equivalent to choose a POI in the group uniformly at random.

On the other hand, the outgoing (unnormalised) transition probability of each POI 
should be the same as that of the POI group, 
since in this case, the transition from any POI in the group to one outside the group 
represents an outgoing transition from the POI group.

Furthermore, the self-loop transition of the POI group represents transitions from any POI in the group
to any other POI in the same group, we distribute the self-loop transition probability uniformly 
among all these pairs.
In particular, suppose the (unnormalised) self-loop transition probability is $P_o$,
and the number of POIs in the group is $N_o$,
the transition probability from $p_i$ to $p_j$ in the same group is
\begin{displaymath}
    P(p_j | p_i) = \delta(i \ne j) \frac{P_o}{N_o - 1}, \forall 1 \le i, j \le N_o
\end{displaymath}
Where $\delta(i \ne j) = 1$ if $i \ne j$ and $0$ otherwise, which is the same constraint that no POI
self-loops are allowed, as described in Section~\ref{sec:transition}.

Lastly, we normalise each row of the (unnormalised) POI-POI transition matrix 
to form a valid (outgoing) probability distribution for each POI.


\section{Implementation details}
We use the rankSVM implementation in libsvmtools \url{https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/},
and the Structured SVM implementation in PyStruct \url{https://pystruct.github.io/}.
Integer linear programming are solved using both Gurobi Optimizer \url{http://www.gurobi.com/} 
and lp\_solve \url{http://lpsolve.sourceforge.net/}.


\section{Avoid Peeking}
When working with machine learning algorithms, to make sure the reported performance is a good approximation
of the generalisation performance, it is critical to prevent information in test set from leaking into
training set.
Many algorithms shown in Table~\ref{tab:algsummary} leveraging both learning to rank and 
factorised POI-POI transition matrix,
e.g., \textsc{Rank+Markov}, \textsc{Rank+MarkovPath} and \textsc{StructuredSVM},
both of them need to be trained or parameters be estimated before being utilised in other algorithms.
POI features such as popularity, the number of visits and average visit duration are
determined by not only the POI itself but also trajectories in training set, 
let's call them aggregated features, as they are computed by aggregating a set of trajectories.
To make sure the prediction performance is reliable, 
it is very important to exclude trajectories in test set when computing aggregated features.
Unfortunately, it is quite easy, especially when utilising multiple levels of machine learning models,
to use all data, including those in test set, to compute aggregated features, 
and many researchers and practitioners did not realise the fact that 
some bits of information in test set were leaked into training set via these aggregated features.

%One may argue that many of these features will not change much when computed with or without data in test set,
%but in certain areas, such as aerodynamics, some decisions are very sensitive to the quantity of certain features.
%Nevertheless, the exact impact still needs further investigation.


\section{Features}
Features used for ranking POIs in rankSVM are described in Table~\ref{tab:featurerank}.
POI features used to factorise the transition probabilities between POIs are described in Table~\ref{tab:featuretran}.


\begin{figure}[t]
	\centering
	\includegraphics[width=0.6\columnwidth]{fig/poi_cats.pdf}
	\caption{POI Categories}
	\label{fig:poicats}
\end{figure}


\begin{table}[t]
\caption{POI features used to factorise POI-POI transition probabilities}
\label{tab:featuretran}
\centering
\begin{tabular}{l|l} \hline
\textbf{Feature}     & \textbf{Description} \\ \hline
\texttt{category}    & category of POI \\
\texttt{position}    & the cluster that a POI resides in \\
\texttt{popularity}  & (discritised) popularity of POI \\
\texttt{nVisit}      & (discritised) total number of visit at POI \\
\texttt{avgDuration} & (discritised) average duration at POI \\ \hline
\end{tabular}
\end{table}


\begin{table*}[t]
\caption{Features of POI $p$ used in rankSVM given query $(p_s, p_e, L)$}
\label{tab:featurerank}
\centering
%\small
%\setlength{\tabcolsep}{2pt} % tweak the space between columns
%\begin{tabular}{l|p{0.7\columnwidth}} \hline
\begin{tabular}{l|l} \hline
\textbf{Feature}  & \textbf{Description} \\ \hline
\texttt{category}          & one-hot encoding of the category of $p$ \\
\texttt{position}          & one-hot encoding of the POI cluster that $p$ resides in \\
\texttt{popularity}        & logarithm of POI popularity of $p$ \\
\texttt{nVisit}            & logarithm of the total number of visit by all users at $p$ \\
\texttt{avgDuration}       & logarithm of the average duration at $p$ \\ \hline
\texttt{trajLen}           & trajectory length $L$, i.e., the number of POIs required \\
\texttt{sameCatStart}      & $1$ if the category of $p$ is the same as that of $p_s$, $-1$ otherwise \\
\texttt{sameCatEnd}        & $1$ if the category of $p$ is the same as that of $p_e$, $-1$ otherwise \\
\texttt{sameClusterStart}  & $1$ if $p$ resides in the same POI cluster as $p_s$, $-1$ otherwise \\
\texttt{sameClusterEnd}    & $1$ if $p$ resides in the same POI cluster as $p_e$, $-1$ otherwise \\
\texttt{distStart}         & distance between $p$ and $p_s$, calculated using the Haversine formula \\
\texttt{distEnd}           & distance between $p$ and $p_e$, calculated using the Haversine formula \\
\texttt{diffPopStart}      & real-valued difference in POI popularity of $p$ from that of $p_s$ \\
\texttt{diffPopEnd}        & real-valued difference in POI popularity of $p$ from that of $p_e$ \\
\texttt{diffNVisitStart}   & real-valued difference in the total number of visit at $p$ from that at $p_s$ \\
\texttt{diffNVisitEnd}     & real-valued difference in the total number of visit at $p$ from that at $p_e$ \\
\texttt{diffDurationStart} & real-valued difference in average duration at $p$ from that at $p_s$ \\
\texttt{diffDurationEnd}   & real-valued difference in average duration at $p$ from that at $p_e$ \\ \hline
\end{tabular}
\end{table*}
